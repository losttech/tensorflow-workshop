{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is walk-through to help getting started with tensorflow\n",
    "\n",
    "1) Simple Linear Regression with low-level TensorFlow  \n",
    "2) Simple Linear Regression with a canned estimator  \n",
    "3) Playing with real data: linear regressor and DNN  \n",
    "4) Building a custom estimator to classify handwritten digits (MNIST)\n",
    "\n",
    "### [What's next?](https://goo.gl/hZaLPA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f5f4225195fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected TensorFlow version is v1.3.0 or higher'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Your TensorFlow version:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named tensorflow"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "print('Expected TensorFlow version is v1.3.0 or higher')\n",
    "print('Your TensorFlow version:', tf.__version__)\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = [12,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Simple Linear Regression with low-level TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data\n",
    "\n",
    "This function creates a noisy dataset that's roughly linear, according to the equation y = mx + b + noise.\n",
    "\n",
    "Notice that the expected value for m is 0.1 and for b is 0.3. This is the values we expect the model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_noisy_data(m=0.1, b=0.3, n=100):\n",
    "    x = np.random.randn(n)\n",
    "    noise = np.random.normal(scale=0.01, size=len(x))\n",
    "    y = m * x + b + noise\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = make_noisy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5688247fd0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAHVCAYAAADywj0dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f56881daf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train, y_train, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input and output\n",
    "x = tf.placeholder(shape=[None], dtype=tf.float32, name='x')\n",
    "y_label = tf.placeholder(shape=[None], dtype=tf.float32, name='y_label')\n",
    "\n",
    "# variables\n",
    "W = tf.Variable(tf.random_normal([1], name=\"W\")) # weight\n",
    "b = tf.Variable(tf.random_normal([1], name=\"b\")) # bias\n",
    "\n",
    "# actual model\n",
    "y = W * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Loss and Optimizer\n",
    "\n",
    "Define a loss function (here, squared error) and an optimizer (here, gradient descent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y - y_label))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Loop and generating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init) # initialize variables\n",
    "  for i in range(100): # train for 100 steps\n",
    "    sess.run(train, feed_dict={x: x_train, y_label:y_train})\n",
    "\n",
    "  x_plot = np.linspace(-3, 3, 101) # return evenly spaced numbers over a specified interval\n",
    "  # using the trained model to predict values for the training data\n",
    "  y_plot = sess.run(y, feed_dict={x: x_plot})\n",
    "\n",
    "  # saving final weight and bias\n",
    "  final_W = sess.run(W)\n",
    "  final_b = sess.run(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f56434b8cd0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAHVCAYAAADywj0dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIuxJEmSBFiMJUmSJMBiLEmSJAHw/xPb5/+a8LgjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5641446ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(x_plot, y_plot, 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the final weight and bias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [ 0.0981679] expected: 0.1\n",
      "b: [ 0.29952455] expected: 0.3\n"
     ]
    }
   ],
   "source": [
    "print('W:', final_W, 'expected: 0.1')\n",
    "print('b:', final_b, 'expected: 0.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Simple Linear Regression with a canned estimator  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_dict = {'x': x_train}\n",
    "train_input = tf.estimator.inputs.numpy_input_fn(x_dict, y_train,\n",
    "                                                 shuffle=True,\n",
    "                                                 num_epochs=None) # repeat forever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe input feature usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [tf.feature_column.numeric_column('x')] # because x is a real number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_eQRnF\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_model_dir': '/tmp/tmp_eQRnF', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp_eQRnF/model.ckpt.\n",
      "INFO:tensorflow:loss = 13.0993, step = 1\n",
      "INFO:tensorflow:global_step/sec: 863.991\n",
      "INFO:tensorflow:loss = 0.0107502, step = 101 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 1104.09\n",
      "INFO:tensorflow:loss = 0.0100529, step = 201 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1063.31\n",
      "INFO:tensorflow:loss = 0.00941867, step = 301 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1115.05\n",
      "INFO:tensorflow:loss = 0.0109864, step = 401 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1212.36\n",
      "INFO:tensorflow:loss = 0.0092965, step = 501 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1358.07\n",
      "INFO:tensorflow:loss = 0.00972837, step = 601 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1190.93\n",
      "INFO:tensorflow:loss = 0.011544, step = 701 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1304.62\n",
      "INFO:tensorflow:loss = 0.0101492, step = 801 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1471.58\n",
      "INFO:tensorflow:loss = 0.0100709, step = 901 (0.068 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp_eQRnF/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0116731.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f56412b5e10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = tf.estimator.LinearRegressor(features)\n",
    "estimator.train(train_input, steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating and visualizing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_eQRnF/model.ckpt-1000\n",
      "[-0.19218418]\n",
      "[-0.0937537]\n",
      "[ 0.00467679]\n",
      "[ 0.10310729]\n",
      "[ 0.20153779]\n",
      "[ 0.29996827]\n",
      "[ 0.39839876]\n",
      "[ 0.49682927]\n",
      "[ 0.59525979]\n",
      "[ 0.69369024]\n",
      "[ 0.7921207]\n"
     ]
    }
   ],
   "source": [
    "x_test_dict = {'x': np.linspace(-5, 5, 11)}\n",
    "data_source = tf.estimator.inputs.numpy_input_fn(x_test_dict, shuffle=False)\n",
    "\n",
    "predictions = list(estimator.predict(data_source))\n",
    "preds = [p['predictions'][0] for p in predictions]\n",
    "\n",
    "for y in predictions:\n",
    "    print(y['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f563c4b1fd0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs4AAAHVCAYAAADhFX3pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f563c4c7ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(x_test_dict['x'], preds, 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Playing with real data: linear regressor and DNN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "\n",
    "The Adult dataset is from the Census bureau and the task is to predict whether a given adult makes more than $50,000 a year based attributes such as education, hours of work per week, etc.\n",
    "\n",
    "But the code here presented can be easilly aplicable to any csv dataset that fits in memory.\n",
    "\n",
    "More about the data [here](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/old.adult.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census_train_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "census_train_path = tf.contrib.keras.utils.get_file('census.train', census_train_url)\n",
    "\n",
    "census_test_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
    "census_test_path = tf.contrib.keras.utils.get_file('census.test', census_test_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names = [\n",
    "  'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "  'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "  'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "  'income'\n",
    "]\n",
    "\n",
    "census_train = pd.read_csv(census_train_path, index_col=False, names=column_names) \n",
    "census_test = pd.read_csv(census_train_path, index_col=False, names=column_names) \n",
    "\n",
    "census_train_label = census_train.pop('income') == \" >50K\" \n",
    "census_test_label = census_test.pop('income') == \" >50K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>160187</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Jamaica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>209642</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>45781</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>14084</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>159449</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "5   37            Private  284582     Masters             14   \n",
       "6   49            Private  160187         9th              5   \n",
       "7   52   Self-emp-not-inc  209642     HS-grad              9   \n",
       "8   31            Private   45781     Masters             14   \n",
       "9   42            Private  159449   Bachelors             13   \n",
       "\n",
       "           marital-status          occupation    relationship    race  \\\n",
       "0           Never-married        Adm-clerical   Not-in-family   White   \n",
       "1      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3      Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4      Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "5      Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "6   Married-spouse-absent       Other-service   Not-in-family   Black   \n",
       "7      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "8           Never-married      Prof-specialty   Not-in-family   White   \n",
       "9      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0     Male          2174             0              40   United-States  \n",
       "1     Male             0             0              13   United-States  \n",
       "2     Male             0             0              40   United-States  \n",
       "3     Male             0             0              40   United-States  \n",
       "4   Female             0             0              40            Cuba  \n",
       "5   Female             0             0              40   United-States  \n",
       "6   Female             0             0              16         Jamaica  \n",
       "7     Male             0             0              45   United-States  \n",
       "8   Female         14084             0              50   United-States  \n",
       "9     Male          5178             0              40   United-States  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7      True\n",
       "8      True\n",
       "9      True\n",
       "10     True\n",
       "11     True\n",
       "12    False\n",
       "13    False\n",
       "14     True\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "18    False\n",
       "19     True\n",
       "Name: income, dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_train_label[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = tf.estimator.inputs.pandas_input_fn(\n",
    "    census_train, \n",
    "    census_train_label,\n",
    "    shuffle=True, \n",
    "    batch_size = 32, # process 32 examples at a time\n",
    "    num_epochs=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input = tf.estimator.inputs.pandas_input_fn(\n",
    "    census_test, \n",
    "    census_test_label, \n",
    "    shuffle=True, \n",
    "    num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': <tf.Tensor 'random_shuffle_queue_DequeueMany:1' shape=(32,) dtype=int64>,\n",
       " 'capital-gain': <tf.Tensor 'random_shuffle_queue_DequeueMany:11' shape=(32,) dtype=int64>,\n",
       " 'capital-loss': <tf.Tensor 'random_shuffle_queue_DequeueMany:12' shape=(32,) dtype=int64>,\n",
       " 'education': <tf.Tensor 'random_shuffle_queue_DequeueMany:4' shape=(32,) dtype=string>,\n",
       " 'education-num': <tf.Tensor 'random_shuffle_queue_DequeueMany:5' shape=(32,) dtype=int64>,\n",
       " 'fnlwgt': <tf.Tensor 'random_shuffle_queue_DequeueMany:3' shape=(32,) dtype=int64>,\n",
       " 'hours-per-week': <tf.Tensor 'random_shuffle_queue_DequeueMany:13' shape=(32,) dtype=int64>,\n",
       " 'marital-status': <tf.Tensor 'random_shuffle_queue_DequeueMany:6' shape=(32,) dtype=string>,\n",
       " 'native-country': <tf.Tensor 'random_shuffle_queue_DequeueMany:14' shape=(32,) dtype=string>,\n",
       " 'occupation': <tf.Tensor 'random_shuffle_queue_DequeueMany:7' shape=(32,) dtype=string>,\n",
       " 'race': <tf.Tensor 'random_shuffle_queue_DequeueMany:9' shape=(32,) dtype=string>,\n",
       " 'relationship': <tf.Tensor 'random_shuffle_queue_DequeueMany:8' shape=(32,) dtype=string>,\n",
       " 'sex': <tf.Tensor 'random_shuffle_queue_DequeueMany:10' shape=(32,) dtype=string>,\n",
       " 'workclass': <tf.Tensor 'random_shuffle_queue_DequeueMany:2' shape=(32,) dtype=string>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels = train_input()\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    tf.feature_column.numeric_column('hours-per-week'),\n",
    "    tf.feature_column.bucketized_column(tf.feature_column.numeric_column('education-num'), list(range(25))),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('sex', ['male','female']),\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('native-country', 1000),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_model_dir': 'census/linear', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.LinearClassifier(features, model_dir='census/linear',n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from census/linear/model.ckpt-7000\n",
      "INFO:tensorflow:Saving checkpoints for 7001 into census/linear/model.ckpt.\n",
      "INFO:tensorflow:loss = 20.1149, step = 7001\n",
      "INFO:tensorflow:global_step/sec: 302.798\n",
      "INFO:tensorflow:loss = 15.1638, step = 7101 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.31\n",
      "INFO:tensorflow:loss = 12.2227, step = 7201 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.354\n",
      "INFO:tensorflow:loss = 12.9704, step = 7301 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.844\n",
      "INFO:tensorflow:loss = 14.7049, step = 7401 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.504\n",
      "INFO:tensorflow:loss = 14.1362, step = 7501 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.45\n",
      "INFO:tensorflow:loss = 16.6804, step = 7601 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.844\n",
      "INFO:tensorflow:loss = 17.2591, step = 7701 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.789\n",
      "INFO:tensorflow:loss = 10.5894, step = 7801 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.84\n",
      "INFO:tensorflow:loss = 14.1496, step = 7901 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.363\n",
      "INFO:tensorflow:loss = 18.9057, step = 8001 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.182\n",
      "INFO:tensorflow:loss = 16.6861, step = 8101 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.778\n",
      "INFO:tensorflow:loss = 14.0005, step = 8201 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.671\n",
      "INFO:tensorflow:loss = 13.6911, step = 8301 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.847\n",
      "INFO:tensorflow:loss = 10.3378, step = 8401 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.961\n",
      "INFO:tensorflow:loss = 17.6118, step = 8501 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.454\n",
      "INFO:tensorflow:loss = 12.2244, step = 8601 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.319\n",
      "INFO:tensorflow:loss = 10.8648, step = 8701 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.034\n",
      "INFO:tensorflow:loss = 16.2914, step = 8801 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.44\n",
      "INFO:tensorflow:loss = 14.7425, step = 8901 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.848\n",
      "INFO:tensorflow:loss = 11.8193, step = 9001 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.59\n",
      "INFO:tensorflow:loss = 16.7798, step = 9101 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.162\n",
      "INFO:tensorflow:loss = 17.5526, step = 9201 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.361\n",
      "INFO:tensorflow:loss = 10.628, step = 9301 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.849\n",
      "INFO:tensorflow:loss = 12.6898, step = 9401 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.188\n",
      "INFO:tensorflow:loss = 10.5932, step = 9501 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.66\n",
      "INFO:tensorflow:loss = 10.6305, step = 9601 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.752\n",
      "INFO:tensorflow:loss = 13.6256, step = 9701 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.302\n",
      "INFO:tensorflow:loss = 9.97006, step = 9801 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.122\n",
      "INFO:tensorflow:loss = 13.9974, step = 9901 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.418\n",
      "INFO:tensorflow:loss = 14.3685, step = 10001 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.078\n",
      "INFO:tensorflow:loss = 14.1978, step = 10101 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.52\n",
      "INFO:tensorflow:loss = 12.6536, step = 10201 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.358\n",
      "INFO:tensorflow:loss = 15.9127, step = 10301 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.282\n",
      "INFO:tensorflow:loss = 11.331, step = 10401 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.805\n",
      "INFO:tensorflow:loss = 19.0658, step = 10501 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.546\n",
      "INFO:tensorflow:loss = 11.7981, step = 10601 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.274\n",
      "INFO:tensorflow:loss = 15.4947, step = 10701 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.697\n",
      "INFO:tensorflow:loss = 11.6418, step = 10801 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.696\n",
      "INFO:tensorflow:loss = 25.1157, step = 10901 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.349\n",
      "INFO:tensorflow:loss = 11.2369, step = 11001 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.395\n",
      "INFO:tensorflow:loss = 10.4846, step = 11101 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.265\n",
      "INFO:tensorflow:loss = 13.5304, step = 11201 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.223\n",
      "INFO:tensorflow:loss = 15.1315, step = 11301 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.125\n",
      "INFO:tensorflow:loss = 18.8153, step = 11401 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.062\n",
      "INFO:tensorflow:loss = 12.4665, step = 11501 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.686\n",
      "INFO:tensorflow:loss = 13.5067, step = 11601 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.359\n",
      "INFO:tensorflow:loss = 10.8848, step = 11701 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.061\n",
      "INFO:tensorflow:loss = 14.718, step = 11801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.814\n",
      "INFO:tensorflow:loss = 12.1113, step = 11901 (0.262 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into census/linear/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 16.0353.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7f567a0c1110>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(train_input, steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-13-18:04:05\n",
      "INFO:tensorflow:Restoring parameters from census/linear/model.ckpt-12000\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-13-18:04:06\n",
      "INFO:tensorflow:Saving dict for global step 12000: accuracy = 0.784036, accuracy_baseline = 0.75919, auc = 0.764093, auc_precision_recall = 0.511886, average_loss = 0.468169, global_step = 12000, label/mean = 0.24081, loss = 59.7806, prediction/mean = 0.228052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7840361,\n",
       " 'accuracy_baseline': 0.75919044,\n",
       " 'auc': 0.7640928,\n",
       " 'auc_precision_recall': 0.51188624,\n",
       " 'average_loss': 0.46816874,\n",
       " 'global_step': 12000,\n",
       " 'label/mean': 0.24080956,\n",
       " 'loss': 59.780556,\n",
       " 'prediction/mean': 0.22805227}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update input pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    tf.feature_column.numeric_column('education-num'),\n",
    "    tf.feature_column.numeric_column('hours-per-week'),\n",
    "    tf.feature_column.numeric_column('age'),\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list('sex',['male','female'])),\n",
    "    tf.feature_column.embedding_column(  # now using embedding!\n",
    "        tf.feature_column.categorical_column_with_hash_bucket('native-country', 1000), 10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_model_dir': 'census/dnn', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.DNNClassifier(hidden_units=[20,20], \n",
    "                                       feature_columns=features, \n",
    "                                       n_classes=2, \n",
    "                                       model_dir='census/dnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from census/dnn/model.ckpt-6001\n",
      "INFO:tensorflow:Saving checkpoints for 6002 into census/dnn/model.ckpt.\n",
      "INFO:tensorflow:loss = 15.0321, step = 6002\n",
      "INFO:tensorflow:global_step/sec: 286.769\n",
      "INFO:tensorflow:loss = 13.2672, step = 6102 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.447\n",
      "INFO:tensorflow:loss = 7.71313, step = 6202 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.693\n",
      "INFO:tensorflow:loss = 15.6592, step = 6302 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.398\n",
      "INFO:tensorflow:loss = 13.5664, step = 6402 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.684\n",
      "INFO:tensorflow:loss = 13.1125, step = 6502 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.251\n",
      "INFO:tensorflow:loss = 11.5031, step = 6602 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.475\n",
      "INFO:tensorflow:loss = 14.8688, step = 6702 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.932\n",
      "INFO:tensorflow:loss = 9.32517, step = 6802 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.437\n",
      "INFO:tensorflow:loss = 17.5457, step = 6902 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.156\n",
      "INFO:tensorflow:loss = 8.52557, step = 7002 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.236\n",
      "INFO:tensorflow:loss = 15.1226, step = 7102 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.21\n",
      "INFO:tensorflow:loss = 14.6417, step = 7202 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.594\n",
      "INFO:tensorflow:loss = 13.5937, step = 7302 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.742\n",
      "INFO:tensorflow:loss = 13.2192, step = 7402 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.425\n",
      "INFO:tensorflow:loss = 13.1118, step = 7502 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.087\n",
      "INFO:tensorflow:loss = 10.8074, step = 7602 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.461\n",
      "INFO:tensorflow:loss = 11.1998, step = 7702 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.83\n",
      "INFO:tensorflow:loss = 18.4475, step = 7802 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.535\n",
      "INFO:tensorflow:loss = 13.4742, step = 7902 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.877\n",
      "INFO:tensorflow:loss = 14.0382, step = 8002 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.827\n",
      "INFO:tensorflow:loss = 10.0719, step = 8102 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.481\n",
      "INFO:tensorflow:loss = 12.1592, step = 8202 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.163\n",
      "INFO:tensorflow:loss = 10.9708, step = 8302 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.572\n",
      "INFO:tensorflow:loss = 15.3756, step = 8402 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.738\n",
      "INFO:tensorflow:loss = 13.6643, step = 8502 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.34\n",
      "INFO:tensorflow:loss = 16.6797, step = 8602 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.559\n",
      "INFO:tensorflow:loss = 15.7203, step = 8702 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.351\n",
      "INFO:tensorflow:loss = 18.0737, step = 8802 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.772\n",
      "INFO:tensorflow:loss = 11.4268, step = 8902 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.588\n",
      "INFO:tensorflow:loss = 13.445, step = 9002 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.941\n",
      "INFO:tensorflow:loss = 19.4516, step = 9102 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.256\n",
      "INFO:tensorflow:loss = 18.4194, step = 9202 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.711\n",
      "INFO:tensorflow:loss = 6.87338, step = 9302 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.261\n",
      "INFO:tensorflow:loss = 14.5495, step = 9402 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.269\n",
      "INFO:tensorflow:loss = 10.6152, step = 9502 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.186\n",
      "INFO:tensorflow:loss = 11.7088, step = 9602 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.47\n",
      "INFO:tensorflow:loss = 15.798, step = 9702 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.057\n",
      "INFO:tensorflow:loss = 14.8131, step = 9802 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.276\n",
      "INFO:tensorflow:loss = 14.5972, step = 9902 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.753\n",
      "INFO:tensorflow:loss = 13.1746, step = 10002 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.436\n",
      "INFO:tensorflow:loss = 19.0885, step = 10102 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.287\n",
      "INFO:tensorflow:loss = 13.5989, step = 10202 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.358\n",
      "INFO:tensorflow:loss = 25.4579, step = 10302 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.261\n",
      "INFO:tensorflow:loss = 12.1536, step = 10402 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.184\n",
      "INFO:tensorflow:loss = 13.825, step = 10502 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.567\n",
      "INFO:tensorflow:loss = 12.5027, step = 10602 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.431\n",
      "INFO:tensorflow:loss = 14.9072, step = 10702 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.01\n",
      "INFO:tensorflow:loss = 13.1078, step = 10802 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.394\n",
      "INFO:tensorflow:loss = 13.2122, step = 10902 (0.241 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11001 into census/dnn/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 10.9782.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f5679ba4890>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(train_input, steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-13-18:04:21\n",
      "INFO:tensorflow:Restoring parameters from census/dnn/model.ckpt-11001\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-13-18:04:22\n",
      "INFO:tensorflow:Saving dict for global step 11001: accuracy = 0.799177, accuracy_baseline = 0.75919, auc = 0.821079, auc_precision_recall = 0.585971, average_loss = 0.421931, global_step = 11001, label/mean = 0.24081, loss = 53.8765, prediction/mean = 0.220763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.79917693,\n",
       " 'accuracy_baseline': 0.75919044,\n",
       " 'auc': 0.82107949,\n",
       " 'auc_precision_recall': 0.585971,\n",
       " 'average_loss': 0.42193109,\n",
       " 'global_step': 11001,\n",
       " 'label/mean': 0.24080956,\n",
       " 'loss': 53.876461,\n",
       " 'prediction/mean': 0.22076258}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Input Pipeline using Datasets API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def census_input_fn(path):\n",
    "    def input_fn():    \n",
    "        dataset = (\n",
    "            tf.contrib.data.TextLineDataset(path)\n",
    "                .map(csv_decoder)\n",
    "                .shuffle(buffer_size=100)\n",
    "                .batch(32)\n",
    "                .repeat())\n",
    "\n",
    "        columns = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        income = tf.equal(columns.pop('income'),\" >50K\") \n",
    "\n",
    "        return columns, income\n",
    "    \n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_defaults = collections.OrderedDict([\n",
    "  ('age',[0]),\n",
    "  ('workclass',['']),\n",
    "  ('fnlwgt',[0]),\n",
    "  ('education',['']),\n",
    "  ('education-num',[0]),\n",
    "  ('marital-status',['']),\n",
    "  ('occupation',['']),\n",
    "  ('relationship',['']),\n",
    "  ('race',['']),\n",
    "  ('sex',['']),\n",
    "  ('capital-gain',[0]),\n",
    "  ('capital-loss',[0]),\n",
    "  ('hours-per-week',[0]),\n",
    "  ('native-country',['']),\n",
    "  ('income',['']),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_decoder(line):\n",
    "  parsed = tf.decode_csv(line, csv_defaults.values())\n",
    "  return dict(zip(csv_defaults.keys(), parsed))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "census_input = census_input_fn(census_train_path)\n",
    "training_batch = census_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    features, high_income = sess.run(training_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' HS-grad' ' Bachelors' ' HS-grad' ' HS-grad' ' HS-grad' ' Assoc-voc'\n",
      " ' 11th' ' HS-grad' ' HS-grad' ' HS-grad' ' HS-grad' ' 5th-6th'\n",
      " ' Some-college' ' HS-grad' ' Some-college' ' HS-grad' ' HS-grad'\n",
      " ' HS-grad' ' Assoc-voc' ' Bachelors' ' 9th' ' 7th-8th' ' HS-grad'\n",
      " ' Bachelors' ' Assoc-acdm' ' Some-college' ' 7th-8th' ' HS-grad'\n",
      " ' Assoc-voc' ' HS-grad' ' Bachelors' ' HS-grad']\n"
     ]
    }
   ],
   "source": [
    "print(features['education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54 50 47 49 52 57 38 19 44 48 32 46 49 53 43 29 19 30 49 44 31 32 30 31 48\n",
      " 55 34 49 29 27 40 42]\n"
     ]
    }
   ],
   "source": [
    "print(features['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False  True False False False  True False  True False\n",
      "  True  True  True False False False  True  True False False False False\n",
      " False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "print(high_income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Building a custom estimator to classify handwritten digits (MNIST)\n",
    "\n",
    "![mnist](http://rodrigob.github.io/are_we_there_yet/build/images/mnist.png?1363085077)\n",
    "Image from: http://rodrigob.github.io/are_we_there_yet/build/images/mnist.png?1363085077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train,test = tf.contrib.keras.datasets.mnist.load_data()\n",
    "x_train,y_train = train \n",
    "x_test,y_test = test\n",
    "\n",
    "mnist_train_input = tf.estimator.inputs.numpy_input_fn({'x':np.array(x_train, dtype=np.float32)},\n",
    "                                                       np.array(y_train,dtype=np.int32),\n",
    "                                                       shuffle=True,\n",
    "                                                       num_epochs=None)\n",
    "\n",
    "mnist_test_input = tf.estimator.inputs.numpy_input_fn({'x':np.array(x_test, dtype=np.float32)},\n",
    "                                                      np.array(y_test,dtype=np.int32),\n",
    "                                                      shuffle=True,\n",
    "                                                      num_epochs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### tf.estimator.LinearClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_model_dir': 'mnist/linear', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from mnist/linear/model.ckpt-40002\n",
      "INFO:tensorflow:Saving checkpoints for 40003 into mnist/linear/model.ckpt.\n",
      "INFO:tensorflow:loss = 523.441, step = 40003\n",
      "INFO:tensorflow:global_step/sec: 522.507\n",
      "INFO:tensorflow:loss = 224.057, step = 40103 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 765.69\n",
      "INFO:tensorflow:loss = 328.933, step = 40203 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 814.354\n",
      "INFO:tensorflow:loss = 192.314, step = 40303 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 919.682\n",
      "INFO:tensorflow:loss = 472.075, step = 40403 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 915.777\n",
      "INFO:tensorflow:loss = 441.126, step = 40503 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 947.679\n",
      "INFO:tensorflow:loss = 292.754, step = 40603 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 892.386\n",
      "INFO:tensorflow:loss = 522.521, step = 40703 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 893.512\n",
      "INFO:tensorflow:loss = 214.606, step = 40803 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 882.97\n",
      "INFO:tensorflow:loss = 401.57, step = 40903 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 879.586\n",
      "INFO:tensorflow:loss = 336.252, step = 41003 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 846.102\n",
      "INFO:tensorflow:loss = 986.988, step = 41103 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 845.481\n",
      "INFO:tensorflow:loss = 587.033, step = 41203 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 912.2\n",
      "INFO:tensorflow:loss = 194.873, step = 41303 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 968.814\n",
      "INFO:tensorflow:loss = 689.631, step = 41403 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.973\n",
      "INFO:tensorflow:loss = 517.357, step = 41503 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 901.541\n",
      "INFO:tensorflow:loss = 554.943, step = 41603 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.361\n",
      "INFO:tensorflow:loss = 131.975, step = 41703 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 913.702\n",
      "INFO:tensorflow:loss = 219.673, step = 41803 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 765.198\n",
      "INFO:tensorflow:loss = 437.133, step = 41903 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 881.99\n",
      "INFO:tensorflow:loss = 491.346, step = 42003 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 894.325\n",
      "INFO:tensorflow:loss = 229.138, step = 42103 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 906.602\n",
      "INFO:tensorflow:loss = 65.2129, step = 42203 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 856.54\n",
      "INFO:tensorflow:loss = 437.087, step = 42303 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 803.077\n",
      "INFO:tensorflow:loss = 426.736, step = 42403 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.252\n",
      "INFO:tensorflow:loss = 231.63, step = 42503 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 871.308\n",
      "INFO:tensorflow:loss = 233.802, step = 42603 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 902.591\n",
      "INFO:tensorflow:loss = 100.03, step = 42703 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 831.739\n",
      "INFO:tensorflow:loss = 587.92, step = 42803 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 922.671\n",
      "INFO:tensorflow:loss = 551.286, step = 42903 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.703\n",
      "INFO:tensorflow:loss = 666.145, step = 43003 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.736\n",
      "INFO:tensorflow:loss = 381.559, step = 43103 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 801.321\n",
      "INFO:tensorflow:loss = 193.693, step = 43203 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 783.669\n",
      "INFO:tensorflow:loss = 460.646, step = 43303 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.883\n",
      "INFO:tensorflow:loss = 719.336, step = 43403 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 836.827\n",
      "INFO:tensorflow:loss = 129.032, step = 43503 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 802.337\n",
      "INFO:tensorflow:loss = 348.094, step = 43603 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 801.102\n",
      "INFO:tensorflow:loss = 503.907, step = 43703 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 828.136\n",
      "INFO:tensorflow:loss = 271.608, step = 43803 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 838.442\n",
      "INFO:tensorflow:loss = 358.111, step = 43903 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 809.893\n",
      "INFO:tensorflow:loss = 421.507, step = 44003 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 821.646\n",
      "INFO:tensorflow:loss = 224.4, step = 44103 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 790.358\n",
      "INFO:tensorflow:loss = 169.664, step = 44203 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 940.788\n",
      "INFO:tensorflow:loss = 411.93, step = 44303 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 947.471\n",
      "INFO:tensorflow:loss = 369.55, step = 44403 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.407\n",
      "INFO:tensorflow:loss = 736.672, step = 44503 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.587\n",
      "INFO:tensorflow:loss = 378.4, step = 44603 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 740.401\n",
      "INFO:tensorflow:loss = 171.653, step = 44703 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 902.259\n",
      "INFO:tensorflow:loss = 331.002, step = 44803 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 899.531\n",
      "INFO:tensorflow:loss = 651.724, step = 44903 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 919.83\n",
      "INFO:tensorflow:loss = 382.485, step = 45003 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 954.133\n",
      "INFO:tensorflow:loss = 661.141, step = 45103 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 944.518\n",
      "INFO:tensorflow:loss = 613.341, step = 45203 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 937.524\n",
      "INFO:tensorflow:loss = 270.104, step = 45303 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 913.042\n",
      "INFO:tensorflow:loss = 377.591, step = 45403 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 933.219\n",
      "INFO:tensorflow:loss = 268.649, step = 45503 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 981.606\n",
      "INFO:tensorflow:loss = 618.282, step = 45603 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 904.044\n",
      "INFO:tensorflow:loss = 506.812, step = 45703 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 964.693\n",
      "INFO:tensorflow:loss = 467.239, step = 45803 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 960.549\n",
      "INFO:tensorflow:loss = 421.831, step = 45903 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 922.569\n",
      "INFO:tensorflow:loss = 246.254, step = 46003 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 962.029\n",
      "INFO:tensorflow:loss = 469.986, step = 46103 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 947.354\n",
      "INFO:tensorflow:loss = 438.547, step = 46203 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 925.909\n",
      "INFO:tensorflow:loss = 498.384, step = 46303 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 956.654\n",
      "INFO:tensorflow:loss = 317.459, step = 46403 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 921.473\n",
      "INFO:tensorflow:loss = 285.086, step = 46503 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.401\n",
      "INFO:tensorflow:loss = 408.372, step = 46603 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 928.885\n",
      "INFO:tensorflow:loss = 160.538, step = 46703 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 911.942\n",
      "INFO:tensorflow:loss = 126.065, step = 46803 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 972.101\n",
      "INFO:tensorflow:loss = 409.363, step = 46903 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 967.194\n",
      "INFO:tensorflow:loss = 767.325, step = 47003 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.029\n",
      "INFO:tensorflow:loss = 687.314, step = 47103 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 931.012\n",
      "INFO:tensorflow:loss = 386.823, step = 47203 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 962.334\n",
      "INFO:tensorflow:loss = 221.577, step = 47303 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 893.352\n",
      "INFO:tensorflow:loss = 515.302, step = 47403 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 892.601\n",
      "INFO:tensorflow:loss = 415.385, step = 47503 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.8\n",
      "INFO:tensorflow:loss = 459.839, step = 47603 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 786.906\n",
      "INFO:tensorflow:loss = 133.315, step = 47703 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 808.453\n",
      "INFO:tensorflow:loss = 449.682, step = 47803 (0.124 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 907.408\n",
      "INFO:tensorflow:loss = 556.473, step = 47903 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 976.037\n",
      "INFO:tensorflow:loss = 434.922, step = 48003 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 897.385\n",
      "INFO:tensorflow:loss = 610.174, step = 48103 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.736\n",
      "INFO:tensorflow:loss = 603.513, step = 48203 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.535\n",
      "INFO:tensorflow:loss = 167.918, step = 48303 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 851.587\n",
      "INFO:tensorflow:loss = 546.752, step = 48403 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 951.383\n",
      "INFO:tensorflow:loss = 358.82, step = 48503 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 919.584\n",
      "INFO:tensorflow:loss = 744.178, step = 48603 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 905.698\n",
      "INFO:tensorflow:loss = 77.2728, step = 48703 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 948.991\n",
      "INFO:tensorflow:loss = 206.162, step = 48803 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 965.513\n",
      "INFO:tensorflow:loss = 361.603, step = 48903 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 883.354\n",
      "INFO:tensorflow:loss = 459.009, step = 49003 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 929.169\n",
      "INFO:tensorflow:loss = 229.588, step = 49103 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 943.023\n",
      "INFO:tensorflow:loss = 172.127, step = 49203 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 906.741\n",
      "INFO:tensorflow:loss = 376.392, step = 49303 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.333\n",
      "INFO:tensorflow:loss = 710.361, step = 49403 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 865.074\n",
      "INFO:tensorflow:loss = 589.128, step = 49503 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 939.654\n",
      "INFO:tensorflow:loss = 348.416, step = 49603 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.511\n",
      "INFO:tensorflow:loss = 150.515, step = 49703 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 941.275\n",
      "INFO:tensorflow:loss = 137.432, step = 49803 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 891.256\n",
      "INFO:tensorflow:loss = 427.903, step = 49903 (0.112 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 50002 into mnist/linear/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 219.711.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7f5678643110>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = tf.estimator.LinearClassifier([tf.feature_column.numeric_column('x',shape=784)], \n",
    "                                          n_classes=10,\n",
    "                                          model_dir=\"mnist/linear\")\n",
    "estimator.train(mnist_train_input, steps = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-07-13-18:04:35\n",
      "INFO:tensorflow:Restoring parameters from mnist/linear/model.ckpt-50002\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-13-18:04:35\n",
      "INFO:tensorflow:Saving dict for global step 50002: accuracy = 0.9012, average_loss = 4.98164, global_step = 50002, loss = 630.588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9012,\n",
       " 'average_loss': 4.9816413,\n",
       " 'global_step': 50002,\n",
       " 'loss': 630.58752}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(mnist_test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the results with [TensorBoard](http://0.0.0.0:6006)\n",
    "$> tensorboard --logdir census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_model_dir': 'mnist/DNN', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from mnist/DNN/model.ckpt-40001\n",
      "INFO:tensorflow:Saving checkpoints for 40002 into mnist/DNN/model.ckpt.\n",
      "INFO:tensorflow:loss = 20.4059, step = 40002\n",
      "INFO:tensorflow:global_step/sec: 333.091\n",
      "INFO:tensorflow:loss = 25.0221, step = 40102 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.488\n",
      "INFO:tensorflow:loss = 34.8886, step = 40202 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.04\n",
      "INFO:tensorflow:loss = 27.3445, step = 40302 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.413\n",
      "INFO:tensorflow:loss = 19.9712, step = 40402 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.55\n",
      "INFO:tensorflow:loss = 12.7345, step = 40502 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.102\n",
      "INFO:tensorflow:loss = 4.42723, step = 40602 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.655\n",
      "INFO:tensorflow:loss = 23.4216, step = 40702 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.345\n",
      "INFO:tensorflow:loss = 12.9914, step = 40802 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.955\n",
      "INFO:tensorflow:loss = 16.2477, step = 40902 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.326\n",
      "INFO:tensorflow:loss = 15.525, step = 41002 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.273\n",
      "INFO:tensorflow:loss = 16.0928, step = 41102 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.035\n",
      "INFO:tensorflow:loss = 13.7238, step = 41202 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.887\n",
      "INFO:tensorflow:loss = 30.3196, step = 41302 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.752\n",
      "INFO:tensorflow:loss = 22.3215, step = 41402 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.451\n",
      "INFO:tensorflow:loss = 14.4886, step = 41502 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.505\n",
      "INFO:tensorflow:loss = 19.2227, step = 41602 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.61\n",
      "INFO:tensorflow:loss = 9.67383, step = 41702 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.401\n",
      "INFO:tensorflow:loss = 9.24746, step = 41802 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.453\n",
      "INFO:tensorflow:loss = 13.3365, step = 41902 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.719\n",
      "INFO:tensorflow:loss = 9.52944, step = 42002 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.708\n",
      "INFO:tensorflow:loss = 29.1738, step = 42102 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.417\n",
      "INFO:tensorflow:loss = 15.4786, step = 42202 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.053\n",
      "INFO:tensorflow:loss = 19.3768, step = 42302 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.198\n",
      "INFO:tensorflow:loss = 21.4434, step = 42402 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.796\n",
      "INFO:tensorflow:loss = 15.1987, step = 42502 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.689\n",
      "INFO:tensorflow:loss = 19.6099, step = 42602 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.239\n",
      "INFO:tensorflow:loss = 7.94017, step = 42702 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.019\n",
      "INFO:tensorflow:loss = 7.97696, step = 42802 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.909\n",
      "INFO:tensorflow:loss = 11.2066, step = 42902 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.031\n",
      "INFO:tensorflow:loss = 8.49086, step = 43002 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.16\n",
      "INFO:tensorflow:loss = 12.4103, step = 43102 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.205\n",
      "INFO:tensorflow:loss = 24.0194, step = 43202 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.441\n",
      "INFO:tensorflow:loss = 27.2065, step = 43302 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.791\n",
      "INFO:tensorflow:loss = 12.116, step = 43402 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.855\n",
      "INFO:tensorflow:loss = 7.38143, step = 43502 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.385\n",
      "INFO:tensorflow:loss = 33.429, step = 43602 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.163\n",
      "INFO:tensorflow:loss = 20.8088, step = 43702 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.49\n",
      "INFO:tensorflow:loss = 14.931, step = 43802 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.81\n",
      "INFO:tensorflow:loss = 31.3252, step = 43902 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.662\n",
      "INFO:tensorflow:loss = 10.2943, step = 44002 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.108\n",
      "INFO:tensorflow:loss = 10.1225, step = 44102 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.031\n",
      "INFO:tensorflow:loss = 21.3659, step = 44202 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.54\n",
      "INFO:tensorflow:loss = 9.74118, step = 44302 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.661\n",
      "INFO:tensorflow:loss = 26.5208, step = 44402 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.879\n",
      "INFO:tensorflow:loss = 6.32994, step = 44502 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.75\n",
      "INFO:tensorflow:loss = 20.1623, step = 44602 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.728\n",
      "INFO:tensorflow:loss = 20.3927, step = 44702 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.587\n",
      "INFO:tensorflow:loss = 20.8277, step = 44802 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.659\n",
      "INFO:tensorflow:loss = 30.4846, step = 44902 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.786\n",
      "INFO:tensorflow:loss = 11.6605, step = 45002 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.698\n",
      "INFO:tensorflow:loss = 7.98221, step = 45102 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.446\n",
      "INFO:tensorflow:loss = 17.7248, step = 45202 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.294\n",
      "INFO:tensorflow:loss = 13.9711, step = 45302 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.689\n",
      "INFO:tensorflow:loss = 18.0874, step = 45402 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.04\n",
      "INFO:tensorflow:loss = 7.98847, step = 45502 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.127\n",
      "INFO:tensorflow:loss = 13.5995, step = 45602 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.308\n",
      "INFO:tensorflow:loss = 10.076, step = 45702 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.648\n",
      "INFO:tensorflow:loss = 15.3053, step = 45802 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.323\n",
      "INFO:tensorflow:loss = 6.98811, step = 45902 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.266\n",
      "INFO:tensorflow:loss = 15.2807, step = 46002 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.355\n",
      "INFO:tensorflow:loss = 18.8629, step = 46102 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.308\n",
      "INFO:tensorflow:loss = 14.2457, step = 46202 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.162\n",
      "INFO:tensorflow:loss = 10.4608, step = 46302 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.512\n",
      "INFO:tensorflow:loss = 15.0061, step = 46402 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.962\n",
      "INFO:tensorflow:loss = 16.6534, step = 46502 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.324\n",
      "INFO:tensorflow:loss = 10.235, step = 46602 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.437\n",
      "INFO:tensorflow:loss = 14.6542, step = 46702 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.214\n",
      "INFO:tensorflow:loss = 15.448, step = 46802 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.382\n",
      "INFO:tensorflow:loss = 10.6443, step = 46902 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.746\n",
      "INFO:tensorflow:loss = 18.3274, step = 47002 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.75\n",
      "INFO:tensorflow:loss = 8.63073, step = 47102 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.068\n",
      "INFO:tensorflow:loss = 8.58208, step = 47202 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.821\n",
      "INFO:tensorflow:loss = 15.9975, step = 47302 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.487\n",
      "INFO:tensorflow:loss = 14.8768, step = 47402 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.35\n",
      "INFO:tensorflow:loss = 13.0863, step = 47502 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.343\n",
      "INFO:tensorflow:loss = 19.036, step = 47602 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.886\n",
      "INFO:tensorflow:loss = 9.55777, step = 47702 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.05\n",
      "INFO:tensorflow:loss = 26.2822, step = 47802 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 14.2463, step = 47902 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.838\n",
      "INFO:tensorflow:loss = 31.2345, step = 48002 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.783\n",
      "INFO:tensorflow:loss = 15.5333, step = 48102 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.137\n",
      "INFO:tensorflow:loss = 31.9774, step = 48202 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.328\n",
      "INFO:tensorflow:loss = 12.7595, step = 48302 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.371\n",
      "INFO:tensorflow:loss = 18.8486, step = 48402 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.397\n",
      "INFO:tensorflow:loss = 8.32962, step = 48502 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.682\n",
      "INFO:tensorflow:loss = 23.0522, step = 48602 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.4\n",
      "INFO:tensorflow:loss = 33.2136, step = 48702 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.296\n",
      "INFO:tensorflow:loss = 8.8079, step = 48802 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.692\n",
      "INFO:tensorflow:loss = 15.0631, step = 48902 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.825\n",
      "INFO:tensorflow:loss = 14.424, step = 49002 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.416\n",
      "INFO:tensorflow:loss = 22.2621, step = 49102 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.75\n",
      "INFO:tensorflow:loss = 17.2221, step = 49202 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.777\n",
      "INFO:tensorflow:loss = 24.0641, step = 49302 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.621\n",
      "INFO:tensorflow:loss = 16.1325, step = 49402 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.872\n",
      "INFO:tensorflow:loss = 7.04931, step = 49502 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.318\n",
      "INFO:tensorflow:loss = 14.785, step = 49602 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.932\n",
      "INFO:tensorflow:loss = 16.339, step = 49702 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.25\n",
      "INFO:tensorflow:loss = 17.2215, step = 49802 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.085\n",
      "INFO:tensorflow:loss = 18.673, step = 49902 (0.252 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 50001 into mnist/DNN/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.65905.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f5679f29390>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = tf.estimator.DNNClassifier(hidden_units=[256],\n",
    "                                       feature_columns=[tf.feature_column.numeric_column('x',shape=784)], \n",
    "                                       n_classes=10,\n",
    "                                       model_dir=\"mnist/DNN\")\n",
    "estimator.train(mnist_train_input, steps = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-07-13-18:05:03\n",
      "INFO:tensorflow:Restoring parameters from mnist/DNN/model.ckpt-50001\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-13-18:05:03\n",
      "INFO:tensorflow:Saving dict for global step 50001: accuracy = 0.9402, average_loss = 0.289987, global_step = 50001, loss = 36.7072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.94019997,\n",
       " 'average_loss': 0.2899867,\n",
       " 'global_step': 50001,\n",
       " 'loss': 36.707176}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(mnist_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 128\n",
    "STEPS = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_cnn(input_layer, mode):\n",
    "  with tf.name_scope(\"CNN\"):\n",
    "      conv1 = tf.layers.conv2d(inputs=input_layer,filters=32, kernel_size=[5, 5],\n",
    "                               padding='same', activation=tf.nn.relu)\n",
    "      pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      conv2 = tf.layers.conv2d(inputs=pool1,filters=64, kernel_size=[5, 5],\n",
    "                               padding='same', activation=tf.nn.relu)\n",
    "      pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "      dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "      is_training_mode = mode == tf.estimator.ModeKeys.TRAIN\n",
    "      dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=is_training_mode)\n",
    "\n",
    "      logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "        \n",
    "      return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "  # Describing the model\n",
    "  input_layer = tf.reshape(features['x'], [-1, 28, 28, 1])\n",
    "    \n",
    "  tf.summary.image('mnist_input',input_layer)\n",
    "    \n",
    "  logits = build_cnn(input_layer, mode)\n",
    " \n",
    "  # Generate Predictions\n",
    "  classes = tf.argmax(input=logits, axis=1)\n",
    "  predictions = {\n",
    "      'classes': classes,\n",
    "      'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    # Return an EstimatorSpec object\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "  loss = tf.reduce_sum(loss)\n",
    "\n",
    "  tf.summary.scalar('loss', loss)\n",
    "    \n",
    "  accuracy = tf.cast(tf.equal(tf.cast(classes,tf.int32),labels),tf.float32)\n",
    "  accuracy = tf.reduce_mean(accuracy)\n",
    "  tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        learning_rate=1e-4,\n",
    "        optimizer='Adam')\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions,\n",
    "                                      loss=loss, train_op=train_op)\n",
    "\n",
    "  # Configure the accuracy metric for evaluation\n",
    "  eval_metric_ops = {\n",
    "      'accuracy': tf.metrics.accuracy(\n",
    "          classes,\n",
    "          input=labels)\n",
    "  }\n",
    "\n",
    "  return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions,\n",
    "                                    loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'mnist/CNN', '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_session_config': None, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5679e16d90>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from mnist/CNN/model.ckpt-2\n",
      "INFO:tensorflow:Saving checkpoints for 3 into mnist/CNN/model.ckpt.\n",
      "INFO:tensorflow:loss = 2716.56, step = 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-038c863f71a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# train for 10000 steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist_train_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/markdaoust/venv/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps)\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/markdaoust/venv/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/markdaoust/venv/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    516\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/markdaoust/venv/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    860\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/google/home/markdaoust/venv/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/markdaoust/venv/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    970\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/markdaoust/venv/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/markdaoust/venv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/markdaoust/venv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/markdaoust/venv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/markdaoust/venv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/markdaoust/venv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create estimator\n",
    "run_config = tf.contrib.learn.RunConfig(model_dir='mnist/CNN')\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
    "\n",
    "# train for 10000 steps\n",
    "estimator.train(input_fn=mnist_train_input, steps=10000)\n",
    "\n",
    "# evaluate\n",
    "estimator.evaluate(input_fn=mnist_test_input)\n",
    "\n",
    "# predict\n",
    "preds = estimator.predict(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed tensorflow: using experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run an experiment\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "\n",
    "# Enable TensorFlow logs\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create experiment\n",
    "def experiment_fn(run_config, hparams):\n",
    "  # create estimator\n",
    "  estimator = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                     config=run_config)\n",
    "  return tf.contrib.learn.Experiment(\n",
    "      estimator,\n",
    "      train_input_fn=train_input_fn,\n",
    "      eval_input_fn=test_input_fn,\n",
    "      train_steps=STEPS\n",
    "  )\n",
    "\n",
    "# run experiment\n",
    "learn_runner.run(experiment_fn,\n",
    "    run_config=run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the results with [TensorBoard](http://0.0.0.0:6006)\n",
    "$> tensorboard --logdir census"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
