{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "** ----- IMPORTANT ------ **  \n",
    "The code presented here assumes that you're running TensorFlow v1.3.0 or higher, this was not released yet so the easiet way to run this is update your TensorFlow version to TensorFlow's master.  \n",
    "\n",
    "\n",
    "To do that go [here](https://github.com/tensorflow/tensorflow#installation) and then execute:  \n",
    "`pip install --upgrade <URL for the right binary for your machine>`.  \n",
    "\n",
    "For example, considering a Linux CPU-only running python2:  \n",
    "`pip install --upgrade https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-1.2.1-cp27-none-linux_x86_64.whl`\n",
    "\n",
    "## Here is walk-through to help getting started with tensorflow\n",
    "\n",
    "\n",
    "1) Simple Linear Regression with low-level TensorFlow  \n",
    "2) Simple Linear Regression with a canned estimator  \n",
    "3) Playing with real data: linear regressor and DNN  \n",
    "4) Building a custom estimator to classify handwritten digits (MNIST)\n",
    "\n",
    "### [What's next?](https://goo.gl/hZaLPA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "print('Expected TensorFlow version is v1.3.0 or higher')\n",
    "print('Your TensorFlow version:', tf.__version__)\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = [12,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Simple Linear Regression with low-level TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data\n",
    "\n",
    "This function creates a noisy dataset that's roughly linear, according to the equation y = mx + b + noise.\n",
    "\n",
    "Notice that the expected value for m is 0.1 and for b is 0.3. This is the values we expect the model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_noisy_data(m=0.1, b=0.3, n=100):\n",
    "    x = np.random.randn(n)\n",
    "    noise = np.random.normal(scale=0.01, size=len(x))\n",
    "    y = m * x + b + noise\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = make_noisy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x_train, y_train, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input and output\n",
    "x = tf.placeholder(shape=[None], dtype=tf.float32, name='x')\n",
    "y_label = tf.placeholder(shape=[None], dtype=tf.float32, name='y_label')\n",
    "\n",
    "# variables\n",
    "W = tf.Variable(tf.random_normal([1], name=\"W\")) # weight\n",
    "b = tf.Variable(tf.random_normal([1], name=\"b\")) # bias\n",
    "\n",
    "# actual model\n",
    "y = W * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Loss and Optimizer\n",
    "\n",
    "Define a loss function (here, squared error) and an optimizer (here, gradient descent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y - y_label))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Loop and generating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init) # initialize variables\n",
    "  for i in range(100): # train for 100 steps\n",
    "    sess.run(train, feed_dict={x: x_train, y_label:y_train})\n",
    "\n",
    "  x_plot = np.linspace(-3, 3, 101) # return evenly spaced numbers over a specified interval\n",
    "  # using the trained model to predict values for the training data\n",
    "  y_plot = sess.run(y, feed_dict={x: x_plot})\n",
    "\n",
    "  # saving final weight and bias\n",
    "  final_W = sess.run(W)\n",
    "  final_b = sess.run(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(x_plot, y_plot, 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the final weight and bias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('W:', final_W, 'expected: 0.1')\n",
    "print('b:', final_b, 'expected: 0.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Simple Linear Regression with a canned estimator  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_dict = {'x': x_train}\n",
    "train_input = tf.estimator.inputs.numpy_input_fn(x_dict, y_train,\n",
    "                                                 shuffle=True,\n",
    "                                                 num_epochs=None) # repeat forever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe input feature usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [tf.feature_column.numeric_column('x')] # because x is a real number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.LinearRegressor(features)\n",
    "estimator.train(train_input, steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating and visualizing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_dict = {'x': np.linspace(-5, 5, 11)}\n",
    "data_source = tf.estimator.inputs.numpy_input_fn(x_test_dict, shuffle=False)\n",
    "\n",
    "predictions = list(estimator.predict(data_source))\n",
    "preds = [p['predictions'][0] for p in predictions]\n",
    "\n",
    "for y in predictions:\n",
    "    print(y['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(x_test_dict['x'], preds, 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Playing with real data: linear regressor and DNN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "\n",
    "The Adult dataset is from the Census bureau and the task is to predict whether a given adult makes more than $50,000 a year based attributes such as education, hours of work per week, etc.\n",
    "\n",
    "But the code here presented can be easilly aplicable to any csv dataset that fits in memory.\n",
    "\n",
    "More about the data [here](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/old.adult.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census_train_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "census_train_path = tf.contrib.keras.utils.get_file('census.train', census_train_url)\n",
    "\n",
    "census_test_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
    "census_test_path = tf.contrib.keras.utils.get_file('census.test', census_test_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names = [\n",
    "  'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "  'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "  'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "  'income'\n",
    "]\n",
    "\n",
    "census_train = pd.read_csv(census_train_path, index_col=False, names=column_names) \n",
    "census_test = pd.read_csv(census_train_path, index_col=False, names=column_names) \n",
    "\n",
    "census_train_label = census_train.pop('income') == \" >50K\" \n",
    "census_test_label = census_test.pop('income') == \" >50K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "census_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_train_label[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = tf.estimator.inputs.pandas_input_fn(\n",
    "    census_train, \n",
    "    census_train_label,\n",
    "    shuffle=True, \n",
    "    batch_size = 32, # process 32 examples at a time\n",
    "    num_epochs=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input = tf.estimator.inputs.pandas_input_fn(\n",
    "    census_test, \n",
    "    census_test_label, \n",
    "    shuffle=True, \n",
    "    num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = train_input()\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    tf.feature_column.numeric_column('hours-per-week'),\n",
    "    tf.feature_column.bucketized_column(tf.feature_column.numeric_column('education-num'), list(range(25))),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('sex', ['male','female']),\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('native-country', 1000),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.LinearClassifier(features, model_dir='census/linear',n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.train(train_input, steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.evaluate(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update input pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    tf.feature_column.numeric_column('education-num'),\n",
    "    tf.feature_column.numeric_column('hours-per-week'),\n",
    "    tf.feature_column.numeric_column('age'),\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list('sex',['male','female'])),\n",
    "    tf.feature_column.embedding_column(  # now using embedding!\n",
    "        tf.feature_column.categorical_column_with_hash_bucket('native-country', 1000), 10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.DNNClassifier(hidden_units=[20,20], \n",
    "                                       feature_columns=features, \n",
    "                                       n_classes=2, \n",
    "                                       model_dir='census/dnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.train(train_input, steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.evaluate(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Input Pipeline using Datasets API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def census_input_fn(path):\n",
    "    def input_fn():    \n",
    "        dataset = (\n",
    "            tf.contrib.data.TextLineDataset(path)\n",
    "                .map(csv_decoder)\n",
    "                .shuffle(buffer_size=100)\n",
    "                .batch(32)\n",
    "                .repeat())\n",
    "\n",
    "        columns = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        income = tf.equal(columns.pop('income'),\" >50K\") \n",
    "\n",
    "        return columns, income\n",
    "    \n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_defaults = collections.OrderedDict([\n",
    "  ('age',[0]),\n",
    "  ('workclass',['']),\n",
    "  ('fnlwgt',[0]),\n",
    "  ('education',['']),\n",
    "  ('education-num',[0]),\n",
    "  ('marital-status',['']),\n",
    "  ('occupation',['']),\n",
    "  ('relationship',['']),\n",
    "  ('race',['']),\n",
    "  ('sex',['']),\n",
    "  ('capital-gain',[0]),\n",
    "  ('capital-loss',[0]),\n",
    "  ('hours-per-week',[0]),\n",
    "  ('native-country',['']),\n",
    "  ('income',['']),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_decoder(line):\n",
    "  parsed = tf.decode_csv(line, csv_defaults.values())\n",
    "  return dict(zip(csv_defaults.keys(), parsed))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "census_input = census_input_fn(census_train_path)\n",
    "training_batch = census_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    features, high_income = sess.run(training_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features['education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(high_income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Building a custom estimator to classify handwritten digits (MNIST)\n",
    "\n",
    "![mnist](http://rodrigob.github.io/are_we_there_yet/build/images/mnist.png?1363085077)\n",
    "Image from: http://rodrigob.github.io/are_we_there_yet/build/images/mnist.png?1363085077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train,test = tf.contrib.keras.datasets.mnist.load_data()\n",
    "x_train,y_train = train \n",
    "x_test,y_test = test\n",
    "\n",
    "mnist_train_input = tf.estimator.inputs.numpy_input_fn({'x':np.array(x_train, dtype=np.float32)},\n",
    "                                                       np.array(y_train,dtype=np.int32),\n",
    "                                                       shuffle=True,\n",
    "                                                       num_epochs=None)\n",
    "\n",
    "mnist_test_input = tf.estimator.inputs.numpy_input_fn({'x':np.array(x_test, dtype=np.float32)},\n",
    "                                                      np.array(y_test,dtype=np.int32),\n",
    "                                                      shuffle=True,\n",
    "                                                      num_epochs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### tf.estimator.LinearClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.LinearClassifier([tf.feature_column.numeric_column('x',shape=784)], \n",
    "                                          n_classes=10,\n",
    "                                          model_dir=\"mnist/linear\")\n",
    "estimator.train(mnist_train_input, steps = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.evaluate(mnist_test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the results with [TensorBoard](http://0.0.0.0:6006)\n",
    "$> tensorboard --logdir census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.DNNClassifier(hidden_units=[256],\n",
    "                                       feature_columns=[tf.feature_column.numeric_column('x',shape=784)], \n",
    "                                       n_classes=10,\n",
    "                                       model_dir=\"mnist/DNN\")\n",
    "estimator.train(mnist_train_input, steps = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.evaluate(mnist_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 128\n",
    "STEPS = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_cnn(input_layer, mode):\n",
    "  with tf.name_scope(\"CNN\"):\n",
    "      conv1 = tf.layers.conv2d(inputs=input_layer,filters=32, kernel_size=[5, 5],\n",
    "                               padding='same', activation=tf.nn.relu)\n",
    "      pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      conv2 = tf.layers.conv2d(inputs=pool1,filters=64, kernel_size=[5, 5],\n",
    "                               padding='same', activation=tf.nn.relu)\n",
    "      pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "      dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "      is_training_mode = mode == tf.estimator.ModeKeys.TRAIN\n",
    "      dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=is_training_mode)\n",
    "\n",
    "      logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "        \n",
    "      return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "  # Describing the model\n",
    "  input_layer = tf.reshape(features['x'], [-1, 28, 28, 1])\n",
    "    \n",
    "  tf.summary.image('mnist_input',input_layer)\n",
    "    \n",
    "  logits = build_cnn(input_layer, mode)\n",
    " \n",
    "  # Generate Predictions\n",
    "  classes = tf.argmax(input=logits, axis=1)\n",
    "  predictions = {\n",
    "      'classes': classes,\n",
    "      'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    # Return an EstimatorSpec object\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "  loss = tf.reduce_sum(loss)\n",
    "\n",
    "  tf.summary.scalar('loss', loss)\n",
    "    \n",
    "  accuracy = tf.cast(tf.equal(tf.cast(classes,tf.int32),labels),tf.float32)\n",
    "  accuracy = tf.reduce_mean(accuracy)\n",
    "  tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        learning_rate=1e-4,\n",
    "        optimizer='Adam')\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions,\n",
    "                                      loss=loss, train_op=train_op)\n",
    "\n",
    "  # Configure the accuracy metric for evaluation\n",
    "  eval_metric_ops = {\n",
    "      'accuracy': tf.metrics.accuracy(\n",
    "          classes,\n",
    "          input=labels)\n",
    "  }\n",
    "\n",
    "  return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions,\n",
    "                                    loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create estimator\n",
    "run_config = tf.contrib.learn.RunConfig(model_dir='mnist/CNN')\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
    "\n",
    "# train for 10000 steps\n",
    "estimator.train(input_fn=mnist_train_input, steps=10000)\n",
    "\n",
    "# evaluate\n",
    "estimator.evaluate(input_fn=mnist_test_input)\n",
    "\n",
    "# predict\n",
    "preds = estimator.predict(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed tensorflow: using experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run an experiment\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "\n",
    "# Enable TensorFlow logs\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create experiment\n",
    "def experiment_fn(run_config, hparams):\n",
    "  # create estimator\n",
    "  estimator = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                     config=run_config)\n",
    "  return tf.contrib.learn.Experiment(\n",
    "      estimator,\n",
    "      train_input_fn=train_input_fn,\n",
    "      eval_input_fn=test_input_fn,\n",
    "      train_steps=STEPS\n",
    "  )\n",
    "\n",
    "# run experiment\n",
    "learn_runner.run(experiment_fn,\n",
    "    run_config=run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the results with [TensorBoard](http://0.0.0.0:6006)\n",
    "$> tensorboard --logdir census"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
