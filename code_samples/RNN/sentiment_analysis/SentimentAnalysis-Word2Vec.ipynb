{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mDT8S9C9CYtr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested with TensorFLow 1.2.0\n",
      "Your TensorFlow version: 1.2.0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "print('Tested with TensorFlow 1.2.0')\n",
    "print('Your TensorFlow version:', tf.__version__) \n",
    "\n",
    "# Feeding function for enqueue data\n",
    "from tensorflow.python.estimator.inputs.queues import feeding_functions as ff\n",
    "\n",
    "# Rnn common functions\n",
    "from tensorflow.contrib.learn.python.learn.estimators import rnn_common\n",
    "\n",
    "# Model builder\n",
    "from tensorflow.python.estimator import model_fn as model_fn_lib\n",
    "\n",
    "# Run an experiment\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "\n",
    "# Helpers for data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "First, we want to create our word vectors. For simplicity, we're going to be using a pretrained model. \n",
    "\n",
    "As one of the biggest players in the ML game, Google was able to train a Word2Vec model on a massive Google News dataset that contained over 100 billion different words! From that model, Google [was able to create 3 million word vectors](https://code.google.com/archive/p/word2vec/#Pre-trained_word_and_phrase_vectors), each with a dimensionality of 300. \n",
    "\n",
    "In an ideal scenario, we'd use those vectors, but since the word vectors matrix is quite large (3.6 GB!), we'll be using a much more manageable matrix that is trained using [GloVe](http://nlp.stanford.edu/projects/glove/), a similar word vector generation model. The matrix will contain 400,000 word vectors, each with a dimensionality of 50. \n",
    "\n",
    "We're going to be importing two different data structures, one will be a Python list with the 400,000 words, and one will be a 400,000 x 50 dimensional embedding matrix that holds all of the word vector values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list, length: 400000\n",
      "Loaded the word vector, shape: (400000, 50)\n"
     ]
    }
   ],
   "source": [
    "# data from: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "TRAIN_INPUT = 'data/train.csv'\n",
    "TEST_INPUT = 'data/test.csv'\n",
    "\n",
    "# data manually generated\n",
    "MY_TEST_INPUT = 'data/mytest.csv'\n",
    "\n",
    "# wordtovec\n",
    "# https://nlp.stanford.edu/projects/glove/\n",
    "# the matrix will contain 400,000 word vectors, each with a dimensionality of 50.\n",
    "word_list = np.load('word_list.npy')\n",
    "word_list = word_list.tolist() # originally loaded as numpy array\n",
    "word_list = [word.decode('UTF-8') for word in word_list] # encode words as UTF-8\n",
    "print('Loaded the word list, length:', len(word_list))\n",
    "\n",
    "word_vector = np.load('word_vector.npy')\n",
    "print ('Loaded the word vector, shape:', word_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can search our word list for a word like \"baseball\", and then access its corresponding vector through the embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: baseball\n",
      "[-1.93270004  1.04209995 -0.78514999  0.91033     0.22711    -0.62158\n",
      " -1.64929998  0.07686    -0.58679998  0.058831    0.35628     0.68915999\n",
      " -0.50598001  0.70472997  1.26639998 -0.40031001 -0.020687    0.80862999\n",
      " -0.90565997 -0.074054   -0.87674999 -0.62910002 -0.12684999  0.11524\n",
      " -0.55685002 -1.68260002 -0.26291001  0.22632     0.713      -1.08280003\n",
      "  2.12310004  0.49869001  0.066711   -0.48225999 -0.17896999  0.47699001\n",
      "  0.16384     0.16537    -0.11506    -0.15962    -0.94926    -0.42833\n",
      " -0.59456998  1.35660005 -0.27506     0.19918001 -0.36008     0.55667001\n",
      " -0.70314997  0.17157   ]\n"
     ]
    }
   ],
   "source": [
    "baseball_index = word_list.index('baseball')\n",
    "print('Example: baseball')\n",
    "print(word_vector[baseball_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our vectors, our first step is taking an input sentence and then constructing the its vector representation. Let's say that we have the input sentence \"I thought the movie was incredible and inspiring\". In order to get the word vectors, we can use Tensorflow's embedding lookup function. This function takes in two arguments, one for the embedding matrix (the wordVectors matrix in our case), and one for the ids of each of the words. The ids vector can be thought of as the integerized representation of the training set. This is basically just the row index of each of the words. Let's look at a quick example to make this concrete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[    41    804 201534   1005     15   7446      5  13767      0      0]\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 10 # maximum length of sentence\n",
    "num_dims = 50 # dimensions for each word vector\n",
    "\n",
    "first_sentence = np.zeros((max_seq_length), dtype='int32')\n",
    "first_sentence[0] = word_list.index(\"i\")\n",
    "first_sentence[1] = word_list.index(\"thought\")\n",
    "first_sentence[2] = word_list.index(\"the\")\n",
    "first_sentence[3] = word_list.index(\"movie\")\n",
    "first_sentence[4] = word_list.index(\"was\")\n",
    "first_sentence[5] = word_list.index(\"incredible\")\n",
    "first_sentence[6] = word_list.index(\"and\")\n",
    "first_sentence[7] = word_list.index(\"inspiring\")\n",
    "# first_sentence[8] = 0\n",
    "# first_sentence[9] = 0\n",
    "\n",
    "print(first_sentence.shape)\n",
    "print(first_sentence) # shows the row index for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###TODO### Insert image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10 x 50 output should contain the 50 dimensional word vectors for each of the 10 words in the sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(word_vector, first_sentence).eval().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the ids matrix for the whole training set, letâ€™s first take some time to visualize the type of data that we have. This will help us determine the best value for setting our maximum sequence length. In the previous example, we used a max length of 10, but this value is largely dependent on the inputs you have.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set we're going to use is the Imdb movie review dataset. This set has 25,000 movie reviews, with 12,500 positive reviews and 12,500 negative reviews. Each of the reviews is stored in a txt file that we need to parse through. The positive reviews are stored in one directory and the negative reviews are stored in another. The following piece of code will determine total and average number of words in each review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive files finished\n",
      "Negative files finished\n",
      "The total number of files is 25000\n",
      "The total number of words in the files is 5844680\n",
      "The average number of words in the files is 233.7872\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "positiveFiles = ['positiveReviews/' + f for f in listdir('positiveReviews/') if isfile(join('positiveReviews/', f))]\n",
    "negativeFiles = ['negativeReviews/' + f for f in listdir('negativeReviews/') if isfile(join('negativeReviews/', f))]\n",
    "numWords = []\n",
    "for pf in positiveFiles:\n",
    "    with open(pf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)       \n",
    "print('Positive files finished')\n",
    "\n",
    "for nf in negativeFiles:\n",
    "    with open(nf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)  \n",
    "print('Negative files finished')\n",
    "\n",
    "numFiles = len(numWords)\n",
    "print('The total number of files is', numFiles)\n",
    "print('The total number of words in the files is', sum(numWords))\n",
    "print('The average number of words in the files is', sum(numWords)/len(numWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the Matplot library to visualize this data in a histogram format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEKCAYAAADenhiQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nObmYmVnlnFzMzKxyTi5mZla5/w+bvdrW6fGbcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a83845390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(numWords, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram as well as the average number of words per file, we can safely say that most reviews will fall under 250 words, which is the max sequence length value we will set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_seq_len = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_matrix = np.load('ids_matrix.npy').tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UrAyWt23AtCM"
   },
   "outputs": [],
   "source": [
    "# Parameters for training\n",
    "STEPS = 15000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Parameters for data processing\n",
    "REVIEW_KEY = 'review'\n",
    "SEQUENCE_LENGTH_KEY = 'sequence_length'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating train and test data\n",
    "\n",
    "The training set we're going to use is the Imdb movie review dataset. This set has 25,000 movie reviews, with 12,500 positive reviews and 12,500 negative reviews. \n",
    "\n",
    "Let's first give a positive label [1, 0] to the first 12500 reviews, and a negative label [0, 1] to the other reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POSITIVE_REVIEWS = 12500\n",
    "\n",
    "# copying sequences\n",
    "data_sequences = [np.asarray(v, dtype=np.int32) for v in ids_matrix]\n",
    "# generating labels\n",
    "data_labels = [[1, 0] if i < POSITIVE_REVIEWS else [0, 1] for i in range(len(ids_matrix))]\n",
    "# also creating a length column, this will be used by the Dynamic RNN\n",
    "# see more about it here: https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "data_length = [max_seq_len for i in range(len(ids_matrix))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's shuffle the data and use 90% of the reviews for training and the other 10% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = list(zip(data_sequences, data_labels, data_length))\n",
    "random.shuffle(data) # shuffle\n",
    "\n",
    "data = np.asarray(data)\n",
    "# separating train and test data\n",
    "limit = int(len(data) * 0.9)\n",
    "\n",
    "train_data = data[:limit]\n",
    "test_data = data[limit:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying if the train and test data have enough positive and negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of positive labels: 12500\n",
      "Proportion of positive labels on the Train data: 0.49933333333333335\n",
      "Proportion of positive labels on the Test data: 0.506\n"
     ]
    }
   ],
   "source": [
    "LABEL_INDEX = 1\n",
    "def _number_of_pos_labels(df):\n",
    "    pos_labels = 0\n",
    "    for value in df:\n",
    "        if value[LABEL_INDEX] == [1, 0]:\n",
    "            pos_labels += 1\n",
    "    return pos_labels\n",
    "\n",
    "pos_labels_train = _number_of_pos_labels(train_data)\n",
    "total_labels_train = len(train_data)\n",
    "\n",
    "pos_labels_test = _number_of_pos_labels(test_data)\n",
    "total_labels_test = len(test_data)\n",
    "\n",
    "print('Total number of positive labels:', pos_labels_train + pos_labels_test)\n",
    "print('Proportion of positive labels on the Train data:', pos_labels_train/total_labels_train)\n",
    "print('Proportion of positive labels on the Test data:', pos_labels_test/total_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_fn(df, batch_size, num_epochs=1, shuffle=True):  \n",
    "    def input_fn():\n",
    "        \n",
    "        sequences = np.asarray([v for v in df[:,0]], dtype=np.int32)\n",
    "        labels = np.asarray([v for v in df[:,1]], dtype=np.int32)\n",
    "        length = np.asarray(df[:,2], dtype=np.int32)\n",
    "\n",
    "        # https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data\n",
    "        dataset = (\n",
    "            tf.contrib.data.Dataset.from_tensor_slices((sequences, labels, length)) # reading data from memory\n",
    "            .repeat(num_epochs) # repeat dataset the number of epochs\n",
    "            .batch(batch_size)\n",
    "        )\n",
    "        \n",
    "        # for our \"manual\" test we don't want to shuffle the data\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=100000)\n",
    "\n",
    "        # create iterator\n",
    "        review, label, length = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        features = {\n",
    "            REVIEW_KEY: review,\n",
    "            SEQUENCE_LENGTH_KEY: length,\n",
    "        }\n",
    "\n",
    "        return features, label\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, label = get_input_fn(test_data, 2, shuffle=False)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    36     29   7503    978    465     10 201534    371     65     34\n",
      "     102      7  12474      6 201534    621      4    567    264   2500\n",
      "  201534   1607    153      3 201534    281     14     12     20   2444\n",
      "       4    480   1003     19   2532   6769     65      5     14   1096\n",
      "      34    301      5    266     12  21853     44    973      4 201534\n",
      "    2500      3   1487   7763    439     73     37    102     14    182\n",
      "     749    164      6      7 399999 106337   3349 399999   1301  99048\n",
      "   11027     13      7   4706 399999 399999      7    333   1983    151\n",
      "  201534   1570      3  59651     32  12734 201534    371     19   4424\n",
      "     142   1670   1222    152    164 399999    992   9742    197    109\n",
      "     246     86     39    234 201534 399999    635      3 201534  22866\n",
      "    2913      6 201534 399999  33830  24445   2115 201534    215   8183\n",
      "     295   2956 217684      4    359 399999    401   4537   2280     46\n",
      "      36      5     76     34     36    338     65     56    941   1088\n",
      "     615     73     81     94   6597      7   4403 399999 399999 399999\n",
      "      41    303      4    253   6494    142    161      5 399999   6412\n",
      "   12193     41     54   1716   8273  14789      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [    37   1005     14     36 399999     58     48    591 399999     40\n",
      "      12  32795   1945      4    159     20   1089 399999     48     31\n",
      "  399999   4014 399999   4333     46 399999 399999    588      7   5988\n",
      "  399999      3 201534   5059 399999    273 399999     84   2182      4\n",
      "    2199 399999     94    591     30      7 399999     10      7   1594\n",
      "       3  16580      5      7   1594      3 399999   2050     14     36\n",
      "     191 399999 399999    169    285    551     13 201534 399999     10\n",
      "  201534   2661 399999 399999 399999  12073     20     94     33     51\n",
      "  399999     41 399999    253 399999    127 399999     14    440     73\n",
      "    1645    599 399999     41   5020 399999      7    219 399999     20\n",
      "    1349      7    530   1078   1896     37     14 201534    611   1062\n",
      "       3 201534 214247    238     20     10      7    191   5115 399999\n",
      "      20    149     36   1089 399999     81    303 201534  34357     56\n",
      "    5320 399999     66 201534   7118   1255 399999   1062      3 204834\n",
      "    1176 399999  24235   1666      7    365   3747  91549     25    285\n",
      "  399999     81   1716     37 399999     43    965     30      7  15002\n",
      "       5   7894 399999     81     32      7    567 399999    414    303\n",
      "       4   2065     60   7118 399999 204834 399999   5300   9492     87\n",
      "    5976   1720   3910 201534     58     87   2459  34357      5     17\n",
      "     557   1410      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]]\n",
      "[[0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    items = sess.run(features)\n",
    "    print(items[REVIEW_KEY])\n",
    "\n",
    "    print(sess.run(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "m5UJyvW5P0Sy"
   },
   "outputs": [],
   "source": [
    "train_input_fn = get_input_fn(train_data, BATCH_SIZE, None)\n",
    "test_input_fn = get_input_fn(test_data, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Estimator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "VxXAUrYN7TvR"
   },
   "outputs": [],
   "source": [
    "def get_model_fn(rnn_cell_sizes,\n",
    "                 label_dimension,\n",
    "                 dnn_layer_sizes=[],\n",
    "                 optimizer='SGD',\n",
    "                 learning_rate=0.01,\n",
    "                 embed_dim=128):\n",
    "    \n",
    "    def model_fn(features, labels, mode):\n",
    "        \n",
    "        review = features[REVIEW_KEY]\n",
    "        sequence_length = tf.cast(features[SEQUENCE_LENGTH_KEY], tf.int32)\n",
    "\n",
    "        # Creating embedding\n",
    "        data = tf.Variable(tf.zeros([BATCH_SIZE, max_seq_len, 50]),dtype=tf.float32)\n",
    "        data = tf.nn.embedding_lookup(word_vector, review)\n",
    "        \n",
    "        # Each RNN layer will consist of a LSTM cell\n",
    "        rnn_layers = [tf.contrib.rnn.LSTMCell(size) for size in rnn_cell_sizes]\n",
    "        \n",
    "        # Construct the layers\n",
    "        multi_rnn_cell = tf.contrib.rnn.MultiRNNCell(rnn_layers)\n",
    "        \n",
    "        # Runs the RNN model dynamically\n",
    "        # more about it at: \n",
    "        # https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
    "                                                 inputs=data,\n",
    "                                                 dtype=tf.float32)\n",
    "\n",
    "        # Slice to keep only the last cell of the RNN\n",
    "        last_activations = rnn_common.select_last_activations(outputs, sequence_length)\n",
    "\n",
    "        # Construct dense layers on top of the last cell of the RNN\n",
    "        for units in dnn_layer_sizes:\n",
    "            last_activations = tf.layers.dense(\n",
    "              last_activations, units, activation=tf.nn.relu)\n",
    "        \n",
    "        # Final dense layer for prediction\n",
    "        predictions = tf.layers.dense(last_activations, label_dimension)\n",
    "        predictions_softmax = tf.nn.softmax(predictions)\n",
    "        \n",
    "        loss = None\n",
    "        train_op = None\n",
    "        eval_op = None\n",
    "        \n",
    "        preds_op = {\n",
    "            'prediction': predictions_softmax,\n",
    "            'label': labels\n",
    "        }\n",
    "        \n",
    "        if mode == tf.contrib.learn.ModeKeys.EVAL:\n",
    "            eval_op = {\n",
    "                \"accuracy\": tf.metrics.accuracy(\n",
    "                         tf.argmax(input=predictions_softmax, axis=1),\n",
    "                         tf.argmax(input=labels, axis=1))\n",
    "            }\n",
    "        \n",
    "        if mode != tf.contrib.learn.ModeKeys.INFER:    \n",
    "            loss = tf.losses.softmax_cross_entropy(labels, predictions)\n",
    "    \n",
    "        if mode == tf.contrib.learn.ModeKeys.TRAIN:    \n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "              loss,\n",
    "              tf.contrib.framework.get_global_step(),\n",
    "              optimizer=optimizer,\n",
    "              learning_rate=learning_rate)\n",
    "        \n",
    "        return model_fn_lib.EstimatorSpec(mode,\n",
    "                                          predictions=predictions_softmax,\n",
    "                                          loss=loss,\n",
    "                                          train_op=train_op,\n",
    "                                          eval_metric_ops=eval_op)\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fn = get_model_fn(rnn_cell_sizes=[64], # size of the hidden layers\n",
    "                        label_dimension=2, # since are just 2 classes\n",
    "                        dnn_layer_sizes=[128, 64], # size of units in the dense layers on top of the RNN\n",
    "                        optimizer='Adam',\n",
    "                        learning_rate=0.001,\n",
    "                        embed_dim=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "DUZEKQrdGgZE"
   },
   "outputs": [],
   "source": [
    "# create experiment\n",
    "def generate_experiment_fn():\n",
    "  \n",
    "    \"\"\"\n",
    "        Create an experiment function given hyperparameters.\n",
    "        Returns:\n",
    "        A function (output_dir) -> Experiment where output_dir is a string\n",
    "        representing the location of summaries, checkpoints, and exports.\n",
    "        this function is used by learn_runner to create an Experiment which\n",
    "        executes model code provided in the form of an Estimator and\n",
    "        input functions.\n",
    "        All listed arguments in the outer function are used to create an\n",
    "        Estimator, and input functions (training, evaluation, serving).\n",
    "        Unlisted args are passed through to Experiment.\n",
    "    \"\"\"\n",
    "\n",
    "    def _experiment_fn(run_config, hparams):\n",
    "        estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
    "        return tf.contrib.learn.Experiment(\n",
    "            estimator,\n",
    "            train_input_fn=train_input_fn,\n",
    "            eval_input_fn=test_input_fn,\n",
    "            train_steps=STEPS\n",
    "        )\n",
    "    return _experiment_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3a18f5a550>, '_tf_random_seed': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_model_dir': 'testing2', '_task_id': 0, '_evaluation_master': '', '_environment': 'local', '_master': '', '_is_chief': True, '_save_checkpoints_secs': 600, '_task_type': None, '_keep_checkpoint_max': 5, '_num_worker_replicas': 0}\n",
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:268: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into testing2/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.702224, step = 1\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-29-13:09:09\n",
      "INFO:tensorflow:Restoring parameters from testing2/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-29-13:09:14\n",
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.5084, global_step = 1, loss = 0.692447\n",
      "INFO:tensorflow:Validation (step 1): accuracy = 0.5084, global_step = 1, loss = 0.692447\n",
      "INFO:tensorflow:global_step/sec: 5.77426\n",
      "INFO:tensorflow:loss = 0.709747, step = 101 (17.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8153\n",
      "INFO:tensorflow:loss = 0.663808, step = 201 (9.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9954\n",
      "INFO:tensorflow:loss = 0.679195, step = 301 (9.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8191\n",
      "INFO:tensorflow:loss = 0.688457, step = 401 (9.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.059\n",
      "INFO:tensorflow:loss = 0.646141, step = 501 (9.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0316\n",
      "INFO:tensorflow:loss = 0.662266, step = 601 (9.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9618\n",
      "INFO:tensorflow:loss = 0.689469, step = 701 (9.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7993\n",
      "INFO:tensorflow:loss = 0.702996, step = 801 (9.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6876\n",
      "INFO:tensorflow:loss = 0.702799, step = 901 (9.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8427\n",
      "INFO:tensorflow:loss = 0.694457, step = 1001 (9.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.653\n",
      "INFO:tensorflow:loss = 0.698411, step = 1101 (9.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4024\n",
      "INFO:tensorflow:loss = 0.681778, step = 1201 (9.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6156\n",
      "INFO:tensorflow:loss = 0.6818, step = 1301 (9.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0213\n",
      "INFO:tensorflow:loss = 0.690526, step = 1401 (9.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9186\n",
      "INFO:tensorflow:loss = 0.689741, step = 1501 (9.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7999\n",
      "INFO:tensorflow:loss = 0.69076, step = 1601 (9.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9234\n",
      "INFO:tensorflow:loss = 0.695023, step = 1701 (9.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8265\n",
      "INFO:tensorflow:loss = 0.693486, step = 1801 (9.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9657\n",
      "INFO:tensorflow:loss = 0.694407, step = 1901 (9.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9904\n",
      "INFO:tensorflow:loss = 0.70909, step = 2001 (9.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9457\n",
      "INFO:tensorflow:loss = 0.69318, step = 2101 (9.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9819\n",
      "INFO:tensorflow:loss = 0.69311, step = 2201 (9.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0748\n",
      "INFO:tensorflow:loss = 0.691624, step = 2301 (9.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.88195\n",
      "INFO:tensorflow:loss = 0.696891, step = 2401 (10.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3211\n",
      "INFO:tensorflow:loss = 0.694153, step = 2501 (9.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4255\n",
      "INFO:tensorflow:loss = 0.693779, step = 2601 (9.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4922\n",
      "INFO:tensorflow:loss = 0.686663, step = 2701 (9.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3552\n",
      "INFO:tensorflow:loss = 0.689399, step = 2801 (9.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4535\n",
      "INFO:tensorflow:loss = 0.692903, step = 2901 (9.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6268\n",
      "INFO:tensorflow:loss = 0.657506, step = 3001 (9.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3449\n",
      "INFO:tensorflow:loss = 0.688102, step = 3101 (9.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.308\n",
      "INFO:tensorflow:loss = 0.69259, step = 3201 (9.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1049\n",
      "INFO:tensorflow:loss = 0.694794, step = 3301 (9.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2761\n",
      "INFO:tensorflow:loss = 0.687033, step = 3401 (9.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7702\n",
      "INFO:tensorflow:loss = 0.692886, step = 3501 (9.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6976\n",
      "INFO:tensorflow:loss = 0.693455, step = 3601 (9.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7679\n",
      "INFO:tensorflow:loss = 0.694858, step = 3701 (9.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6501\n",
      "INFO:tensorflow:loss = 0.689595, step = 3801 (9.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6292\n",
      "INFO:tensorflow:loss = 0.749494, step = 3901 (9.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.97154\n",
      "INFO:tensorflow:loss = 0.67323, step = 4001 (10.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4696\n",
      "INFO:tensorflow:loss = 0.704927, step = 4101 (9.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4357\n",
      "INFO:tensorflow:loss = 0.664953, step = 4201 (9.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5034\n",
      "INFO:tensorflow:loss = 0.698912, step = 4301 (9.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4302\n",
      "INFO:tensorflow:loss = 0.693565, step = 4401 (9.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3919\n",
      "INFO:tensorflow:loss = 0.694478, step = 4501 (9.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4539\n",
      "INFO:tensorflow:loss = 0.680164, step = 4601 (9.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3179\n",
      "INFO:tensorflow:loss = 0.696179, step = 4701 (9.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6305\n",
      "INFO:tensorflow:loss = 0.693791, step = 4801 (9.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5707\n",
      "INFO:tensorflow:loss = 0.691543, step = 4901 (9.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9516\n",
      "INFO:tensorflow:loss = 0.687856, step = 5001 (9.131 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 10.859\n",
      "INFO:tensorflow:loss = 0.659731, step = 5101 (9.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.95\n",
      "INFO:tensorflow:loss = 0.751493, step = 5201 (9.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8978\n",
      "INFO:tensorflow:loss = 0.652734, step = 5301 (9.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6529\n",
      "INFO:tensorflow:loss = 0.701441, step = 5401 (9.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6547\n",
      "INFO:tensorflow:loss = 0.693071, step = 5501 (9.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.549\n",
      "INFO:tensorflow:loss = 0.692545, step = 5601 (9.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8424\n",
      "INFO:tensorflow:loss = 0.680459, step = 5701 (9.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0042\n",
      "INFO:tensorflow:loss = 0.693177, step = 5801 (9.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6846\n",
      "INFO:tensorflow:loss = 0.696385, step = 5901 (9.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6851\n",
      "INFO:tensorflow:loss = 0.694919, step = 6001 (9.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7049\n",
      "INFO:tensorflow:loss = 0.680568, step = 6101 (9.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.616\n",
      "INFO:tensorflow:loss = 0.725044, step = 6201 (9.420 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6282 into testing2/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-29-13:19:09\n",
      "INFO:tensorflow:Restoring parameters from testing2/model.ckpt-6282\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-29-13:19:13\n",
      "INFO:tensorflow:Saving dict for global step 6282: accuracy = 0.5644, global_step = 6282, loss = 0.672052\n",
      "INFO:tensorflow:Validation (step 6282): accuracy = 0.5644, global_step = 6282, loss = 0.672052\n",
      "INFO:tensorflow:global_step/sec: 6.91504\n",
      "INFO:tensorflow:loss = 0.680763, step = 6301 (14.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2158\n",
      "INFO:tensorflow:loss = 0.683204, step = 6401 (9.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4113\n",
      "INFO:tensorflow:loss = 0.641561, step = 6501 (9.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.513\n",
      "INFO:tensorflow:loss = 0.715619, step = 6601 (9.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6212\n",
      "INFO:tensorflow:loss = 0.677847, step = 6701 (9.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5124\n",
      "INFO:tensorflow:loss = 0.588227, step = 6801 (9.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6684\n",
      "INFO:tensorflow:loss = 0.694563, step = 6901 (9.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4209\n",
      "INFO:tensorflow:loss = 0.689794, step = 7001 (9.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6475\n",
      "INFO:tensorflow:loss = 0.685898, step = 7101 (9.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6997\n",
      "INFO:tensorflow:loss = 0.68545, step = 7201 (9.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.95594\n",
      "INFO:tensorflow:loss = 0.648137, step = 7301 (10.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2897\n",
      "INFO:tensorflow:loss = 0.531919, step = 7401 (9.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6325\n",
      "INFO:tensorflow:loss = 0.662547, step = 7501 (9.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4012\n",
      "INFO:tensorflow:loss = 0.519547, step = 7601 (9.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9943\n",
      "INFO:tensorflow:loss = 0.385066, step = 7701 (9.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8404\n",
      "INFO:tensorflow:loss = 0.439061, step = 7801 (9.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3278\n",
      "INFO:tensorflow:loss = 0.220641, step = 7901 (9.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.60152\n",
      "INFO:tensorflow:loss = 0.526734, step = 8001 (10.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9489\n",
      "INFO:tensorflow:loss = 0.458283, step = 8101 (9.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5164\n",
      "INFO:tensorflow:loss = 0.426452, step = 8201 (9.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5491\n",
      "INFO:tensorflow:loss = 0.406577, step = 8301 (9.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0236\n",
      "INFO:tensorflow:loss = 0.586833, step = 8401 (9.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.954\n",
      "INFO:tensorflow:loss = 0.382276, step = 8501 (9.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3982\n",
      "INFO:tensorflow:loss = 0.253388, step = 8601 (9.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5247\n",
      "INFO:tensorflow:loss = 0.56352, step = 8701 (9.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4862\n",
      "INFO:tensorflow:loss = 0.453695, step = 8801 (9.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4503\n",
      "INFO:tensorflow:loss = 0.592724, step = 8901 (9.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5971\n",
      "INFO:tensorflow:loss = 0.478521, step = 9001 (9.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9681\n",
      "INFO:tensorflow:loss = 0.498691, step = 9101 (9.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7513\n",
      "INFO:tensorflow:loss = 0.475168, step = 9201 (9.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.446\n",
      "INFO:tensorflow:loss = 0.332189, step = 9301 (9.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2459\n",
      "INFO:tensorflow:loss = 0.411877, step = 9401 (9.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6161\n",
      "INFO:tensorflow:loss = 0.219225, step = 9501 (9.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.92121\n",
      "INFO:tensorflow:loss = 0.359576, step = 9601 (10.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4171\n",
      "INFO:tensorflow:loss = 0.338412, step = 9701 (9.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5304\n",
      "INFO:tensorflow:loss = 0.418522, step = 9801 (9.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4868\n",
      "INFO:tensorflow:loss = 0.396225, step = 9901 (9.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2108\n",
      "INFO:tensorflow:loss = 0.353239, step = 10001 (9.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.316909, step = 10101 (9.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5245\n",
      "INFO:tensorflow:loss = 0.251563, step = 10201 (9.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4461\n",
      "INFO:tensorflow:loss = 0.344501, step = 10301 (9.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.522\n",
      "INFO:tensorflow:loss = 0.372052, step = 10401 (9.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5911\n",
      "INFO:tensorflow:loss = 0.319963, step = 10501 (9.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5216\n",
      "INFO:tensorflow:loss = 0.369244, step = 10601 (9.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.521\n",
      "INFO:tensorflow:loss = 0.264259, step = 10701 (9.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5213\n",
      "INFO:tensorflow:loss = 0.443012, step = 10801 (9.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.522\n",
      "INFO:tensorflow:loss = 0.328671, step = 10901 (9.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4649\n",
      "INFO:tensorflow:loss = 0.370794, step = 11001 (9.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.521\n",
      "INFO:tensorflow:loss = 0.274471, step = 11101 (9.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3697\n",
      "INFO:tensorflow:loss = 0.361685, step = 11201 (9.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4652\n",
      "INFO:tensorflow:loss = 0.291704, step = 11301 (9.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5341\n",
      "INFO:tensorflow:loss = 0.273949, step = 11401 (9.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4882\n",
      "INFO:tensorflow:loss = 0.247468, step = 11501 (9.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5441\n",
      "INFO:tensorflow:loss = 0.245574, step = 11601 (9.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5348\n",
      "INFO:tensorflow:loss = 0.632971, step = 11701 (9.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4848\n",
      "INFO:tensorflow:loss = 0.411189, step = 11801 (9.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5086\n",
      "INFO:tensorflow:loss = 0.355353, step = 11901 (9.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5229\n",
      "INFO:tensorflow:loss = 0.252377, step = 12001 (9.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.598\n",
      "INFO:tensorflow:loss = 0.352639, step = 12101 (9.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7476\n",
      "INFO:tensorflow:loss = 0.292668, step = 12201 (9.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8645\n",
      "INFO:tensorflow:loss = 0.115168, step = 12301 (9.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9346\n",
      "INFO:tensorflow:loss = 0.394358, step = 12401 (9.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9483\n",
      "INFO:tensorflow:loss = 0.417252, step = 12501 (9.134 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12547 into testing2/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-29-13:29:08\n",
      "INFO:tensorflow:Restoring parameters from testing2/model.ckpt-12547\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-29-13:29:11\n",
      "INFO:tensorflow:Saving dict for global step 12547: accuracy = 0.84, global_step = 12547, loss = 0.357392\n",
      "INFO:tensorflow:Validation (step 12547): accuracy = 0.84, global_step = 12547, loss = 0.357392\n",
      "INFO:tensorflow:global_step/sec: 7.79841\n",
      "INFO:tensorflow:loss = 0.168538, step = 12601 (12.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8611\n",
      "INFO:tensorflow:loss = 0.190768, step = 12701 (9.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7893\n",
      "INFO:tensorflow:loss = 0.377361, step = 12801 (9.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8096\n",
      "INFO:tensorflow:loss = 0.169103, step = 12901 (9.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7698\n",
      "INFO:tensorflow:loss = 0.249736, step = 13001 (9.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.888\n",
      "INFO:tensorflow:loss = 0.374019, step = 13101 (9.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.942\n",
      "INFO:tensorflow:loss = 0.578929, step = 13201 (9.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0056\n",
      "INFO:tensorflow:loss = 0.425376, step = 13301 (9.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8779\n",
      "INFO:tensorflow:loss = 0.384443, step = 13401 (9.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8776\n",
      "INFO:tensorflow:loss = 0.322913, step = 13501 (9.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9114\n",
      "INFO:tensorflow:loss = 0.385036, step = 13601 (9.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8789\n",
      "INFO:tensorflow:loss = 0.140187, step = 13701 (9.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9905\n",
      "INFO:tensorflow:loss = 0.287861, step = 13801 (9.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9527\n",
      "INFO:tensorflow:loss = 0.362631, step = 13901 (9.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9066\n",
      "INFO:tensorflow:loss = 0.509308, step = 14001 (9.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9685\n",
      "INFO:tensorflow:loss = 0.240151, step = 14101 (9.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9161\n",
      "INFO:tensorflow:loss = 0.205992, step = 14201 (9.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9554\n",
      "INFO:tensorflow:loss = 0.217344, step = 14301 (9.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7673\n",
      "INFO:tensorflow:loss = 0.230715, step = 14401 (9.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8307\n",
      "INFO:tensorflow:loss = 0.276864, step = 14501 (9.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7863\n",
      "INFO:tensorflow:loss = 0.263115, step = 14601 (9.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9323\n",
      "INFO:tensorflow:loss = 0.281702, step = 14701 (9.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8883\n",
      "INFO:tensorflow:loss = 0.199386, step = 14801 (9.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8822\n",
      "INFO:tensorflow:loss = 0.116956, step = 14901 (9.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9012\n",
      "INFO:tensorflow:loss = 0.0649144, step = 15001 (9.173 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 10.8143\n",
      "INFO:tensorflow:loss = 0.335126, step = 15101 (9.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8845\n",
      "INFO:tensorflow:loss = 0.386393, step = 15201 (9.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8657\n",
      "INFO:tensorflow:loss = 0.20567, step = 15301 (9.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5443\n",
      "INFO:tensorflow:loss = 0.198978, step = 15401 (9.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5136\n",
      "INFO:tensorflow:loss = 0.230477, step = 15501 (9.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5629\n",
      "INFO:tensorflow:loss = 0.208272, step = 15601 (9.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6166\n",
      "INFO:tensorflow:loss = 0.303766, step = 15701 (9.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5211\n",
      "INFO:tensorflow:loss = 0.398745, step = 15801 (9.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5106\n",
      "INFO:tensorflow:loss = 0.190603, step = 15901 (9.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4468\n",
      "INFO:tensorflow:loss = 0.415988, step = 16001 (9.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5555\n",
      "INFO:tensorflow:loss = 0.424059, step = 16101 (9.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0741\n",
      "INFO:tensorflow:loss = 0.253785, step = 16201 (9.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4485\n",
      "INFO:tensorflow:loss = 0.112803, step = 16301 (9.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1263\n",
      "INFO:tensorflow:loss = 0.25306, step = 16401 (9.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4117\n",
      "INFO:tensorflow:loss = 0.144182, step = 16501 (9.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1748\n",
      "INFO:tensorflow:loss = 0.281317, step = 16601 (9.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2507\n",
      "INFO:tensorflow:loss = 0.0880013, step = 16701 (9.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0706\n",
      "INFO:tensorflow:loss = 0.175008, step = 16801 (9.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.91204\n",
      "INFO:tensorflow:loss = 0.216902, step = 16901 (10.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.93574\n",
      "INFO:tensorflow:loss = 0.393399, step = 17001 (10.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3329\n",
      "INFO:tensorflow:loss = 0.294201, step = 17101 (9.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0167\n",
      "INFO:tensorflow:loss = 0.237406, step = 17201 (9.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2399\n",
      "INFO:tensorflow:loss = 0.266638, step = 17301 (9.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3119\n",
      "INFO:tensorflow:loss = 0.282131, step = 17401 (9.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0057\n",
      "INFO:tensorflow:loss = 0.334409, step = 17501 (9.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3245\n",
      "INFO:tensorflow:loss = 0.402662, step = 17601 (9.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4525\n",
      "INFO:tensorflow:loss = 0.109814, step = 17701 (9.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2608\n",
      "INFO:tensorflow:loss = 0.206623, step = 17801 (9.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5391\n",
      "INFO:tensorflow:loss = 0.172913, step = 17901 (9.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5477\n",
      "INFO:tensorflow:loss = 0.106871, step = 18001 (9.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3579\n",
      "INFO:tensorflow:loss = 0.215493, step = 18101 (9.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1419\n",
      "INFO:tensorflow:loss = 0.195881, step = 18201 (9.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7757\n",
      "INFO:tensorflow:loss = 0.163682, step = 18301 (9.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3338\n",
      "INFO:tensorflow:loss = 0.138341, step = 18401 (9.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2334\n",
      "INFO:tensorflow:loss = 0.204241, step = 18501 (9.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5684\n",
      "INFO:tensorflow:loss = 0.117975, step = 18601 (9.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6854\n",
      "INFO:tensorflow:loss = 0.157836, step = 18701 (9.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7622\n",
      "INFO:tensorflow:loss = 0.0623179, step = 18801 (9.292 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18858 into testing2/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-29-13:39:08\n",
      "INFO:tensorflow:Restoring parameters from testing2/model.ckpt-18858\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-29-13:39:12\n",
      "INFO:tensorflow:Saving dict for global step 18858: accuracy = 0.8496, global_step = 18858, loss = 0.393123\n",
      "INFO:tensorflow:Validation (step 18858): accuracy = 0.8496, global_step = 18858, loss = 0.393123\n",
      "INFO:tensorflow:global_step/sec: 7.63898\n",
      "INFO:tensorflow:loss = 0.296969, step = 18901 (13.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.134\n",
      "INFO:tensorflow:loss = 0.198794, step = 19001 (9.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.90147\n",
      "INFO:tensorflow:loss = 0.355534, step = 19101 (10.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1805\n",
      "INFO:tensorflow:loss = 0.231664, step = 19201 (9.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1964\n",
      "INFO:tensorflow:loss = 0.233768, step = 19301 (9.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1765\n",
      "INFO:tensorflow:loss = 0.121018, step = 19401 (9.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4554\n",
      "INFO:tensorflow:loss = 0.0577645, step = 19501 (9.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2567\n",
      "INFO:tensorflow:loss = 0.267758, step = 19601 (9.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.81198\n",
      "INFO:tensorflow:loss = 0.305589, step = 19701 (10.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0452\n",
      "INFO:tensorflow:loss = 0.129044, step = 19801 (9.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.61078\n",
      "INFO:tensorflow:loss = 0.0934473, step = 19901 (10.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.84472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0573027, step = 20001 (10.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0328\n",
      "INFO:tensorflow:loss = 0.14195, step = 20101 (9.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.67057\n",
      "INFO:tensorflow:loss = 0.262287, step = 20201 (10.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.54714\n",
      "INFO:tensorflow:loss = 0.102364, step = 20301 (10.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0709\n",
      "INFO:tensorflow:loss = 0.0309285, step = 20401 (9.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0926\n",
      "INFO:tensorflow:loss = 0.0468883, step = 20501 (9.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.056\n",
      "INFO:tensorflow:loss = 0.0746669, step = 20601 (9.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1143\n",
      "INFO:tensorflow:loss = 0.412788, step = 20701 (9.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.8962\n",
      "INFO:tensorflow:loss = 0.228101, step = 20801 (10.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3426\n",
      "INFO:tensorflow:loss = 0.184479, step = 20901 (9.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.95871\n",
      "INFO:tensorflow:loss = 0.105869, step = 21001 (10.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2425\n",
      "INFO:tensorflow:loss = 0.0978621, step = 21101 (9.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2865\n",
      "INFO:tensorflow:loss = 0.050883, step = 21201 (9.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.89516\n",
      "INFO:tensorflow:loss = 0.0585258, step = 21301 (10.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.274\n",
      "INFO:tensorflow:loss = 0.182068, step = 21401 (9.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.207\n",
      "INFO:tensorflow:loss = 0.15961, step = 21501 (9.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3535\n",
      "INFO:tensorflow:loss = 0.134946, step = 21601 (9.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3885\n",
      "INFO:tensorflow:loss = 0.0516901, step = 21701 (9.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6494\n",
      "INFO:tensorflow:loss = 0.0361726, step = 21801 (9.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.716\n",
      "INFO:tensorflow:loss = 0.110561, step = 21901 (9.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5541\n",
      "INFO:tensorflow:loss = 0.14585, step = 22001 (9.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4912\n",
      "INFO:tensorflow:loss = 0.0292277, step = 22101 (9.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7152\n",
      "INFO:tensorflow:loss = 0.129825, step = 22201 (9.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6897\n",
      "INFO:tensorflow:loss = 0.108444, step = 22301 (9.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2329\n",
      "INFO:tensorflow:loss = 0.100388, step = 22401 (9.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1734\n",
      "INFO:tensorflow:loss = 0.0241034, step = 22501 (9.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1079\n",
      "INFO:tensorflow:loss = 0.0453775, step = 22601 (9.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.97848\n",
      "INFO:tensorflow:loss = 0.251391, step = 22701 (10.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0627\n",
      "INFO:tensorflow:loss = 0.104536, step = 22801 (9.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0783\n",
      "INFO:tensorflow:loss = 0.110236, step = 22901 (9.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0009\n",
      "INFO:tensorflow:loss = 0.187455, step = 23001 (9.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.84202\n",
      "INFO:tensorflow:loss = 0.146792, step = 23101 (10.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.84893\n",
      "INFO:tensorflow:loss = 0.034457, step = 23201 (10.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.99413\n",
      "INFO:tensorflow:loss = 0.0565486, step = 23301 (10.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.87454\n",
      "INFO:tensorflow:loss = 0.0672359, step = 23401 (10.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.9731\n",
      "INFO:tensorflow:loss = 0.016807, step = 23501 (10.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.70943\n",
      "INFO:tensorflow:loss = 0.0304512, step = 23601 (10.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.72636\n",
      "INFO:tensorflow:loss = 0.157335, step = 23701 (10.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1877\n",
      "INFO:tensorflow:loss = 0.152418, step = 23801 (9.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4844\n",
      "INFO:tensorflow:loss = 0.0916263, step = 23901 (9.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6246\n",
      "INFO:tensorflow:loss = 0.222999, step = 24001 (9.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6499\n",
      "INFO:tensorflow:loss = 0.0628916, step = 24101 (9.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.656\n",
      "INFO:tensorflow:loss = 0.152039, step = 24201 (9.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6739\n",
      "INFO:tensorflow:loss = 0.364461, step = 24301 (9.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2224\n",
      "INFO:tensorflow:loss = 0.0836938, step = 24401 (9.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3452\n",
      "INFO:tensorflow:loss = 0.0618011, step = 24501 (9.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2704\n",
      "INFO:tensorflow:loss = 0.0751874, step = 24601 (9.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.75828\n",
      "INFO:tensorflow:loss = 0.0735404, step = 24701 (10.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.92074\n",
      "INFO:tensorflow:loss = 0.0457174, step = 24801 (10.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.41088\n",
      "INFO:tensorflow:loss = 0.221096, step = 24901 (10.626 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24903 into testing2/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-29-13:49:09\n",
      "INFO:tensorflow:Restoring parameters from testing2/model.ckpt-24903\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-29-13:49:13\n",
      "INFO:tensorflow:Saving dict for global step 24903: accuracy = 0.8324, global_step = 24903, loss = 0.578522\n",
      "INFO:tensorflow:Validation (step 24903): accuracy = 0.8324, global_step = 24903, loss = 0.578522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.52353\n",
      "INFO:tensorflow:loss = 0.0341375, step = 25001 (15.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0441\n",
      "INFO:tensorflow:loss = 0.0274761, step = 25101 (9.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1661\n",
      "INFO:tensorflow:loss = 0.300942, step = 25201 (9.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.227\n",
      "INFO:tensorflow:loss = 0.0524202, step = 25301 (9.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.84267\n",
      "INFO:tensorflow:loss = 0.0874858, step = 25401 (10.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.98989\n",
      "INFO:tensorflow:loss = 0.380375, step = 25501 (10.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0228\n",
      "INFO:tensorflow:loss = 0.167019, step = 25601 (9.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1635\n",
      "INFO:tensorflow:loss = 0.10299, step = 25701 (9.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.97289\n",
      "INFO:tensorflow:loss = 0.0480214, step = 25801 (10.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1747\n",
      "INFO:tensorflow:loss = 0.249856, step = 25901 (9.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1208\n",
      "INFO:tensorflow:loss = 0.115353, step = 26001 (9.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.98893\n",
      "INFO:tensorflow:loss = 0.140886, step = 26101 (10.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1737\n",
      "INFO:tensorflow:loss = 0.0291444, step = 26201 (9.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1633\n",
      "INFO:tensorflow:loss = 0.106773, step = 26301 (9.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1504\n",
      "INFO:tensorflow:loss = 0.0279159, step = 26401 (9.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1401\n",
      "INFO:tensorflow:loss = 0.0808731, step = 26501 (9.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.90735\n",
      "INFO:tensorflow:loss = 0.0298186, step = 26601 (10.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2026\n",
      "INFO:tensorflow:loss = 0.0187685, step = 26701 (9.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.243\n",
      "INFO:tensorflow:loss = 0.0356779, step = 26801 (9.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2908\n",
      "INFO:tensorflow:loss = 0.0174884, step = 26901 (9.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3543\n",
      "INFO:tensorflow:loss = 0.166417, step = 27001 (9.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6206\n",
      "INFO:tensorflow:loss = 0.116242, step = 27101 (9.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5835\n",
      "INFO:tensorflow:loss = 0.0291956, step = 27201 (9.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5545\n",
      "INFO:tensorflow:loss = 0.0611862, step = 27301 (9.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4988\n",
      "INFO:tensorflow:loss = 0.0127632, step = 27401 (9.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.81971\n",
      "INFO:tensorflow:loss = 0.0755489, step = 27501 (10.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2222\n",
      "INFO:tensorflow:loss = 0.0179902, step = 27601 (9.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.881\n",
      "INFO:tensorflow:loss = 0.0464621, step = 27701 (10.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2568\n",
      "INFO:tensorflow:loss = 0.180232, step = 27801 (9.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2395\n",
      "INFO:tensorflow:loss = 0.0273141, step = 27901 (9.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.58837\n",
      "INFO:tensorflow:loss = 0.185907, step = 28001 (10.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0512\n",
      "INFO:tensorflow:loss = 0.118873, step = 28101 (9.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.97048\n",
      "INFO:tensorflow:loss = 0.0535866, step = 28201 (10.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2256\n",
      "INFO:tensorflow:loss = 0.0161786, step = 28301 (9.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5405\n",
      "INFO:tensorflow:loss = 0.0145144, step = 28401 (9.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3069\n",
      "INFO:tensorflow:loss = 0.0277693, step = 28501 (9.702 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-c5365892903e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_experiment_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'testing2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(experiment_fn, output_dir, schedule, run_config, hparams)\u001b[0m\n\u001b[1;32m    208\u001b[0m   \u001b[0mschedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_default_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_execute_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\u001b[0m in \u001b[0;36m_execute_schedule\u001b[0;34m(experiment, schedule)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Allowed values for this experiment are: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Schedule references non-callable member %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dir_suffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )]\n\u001b[0;32m--> 495\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     eval_result = self._call_evaluate(input_fn=self._eval_input_fn,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, delay_secs)\u001b[0m\n\u001b[1;32m    273\u001b[0m     return self._call_train(input_fn=self._train_input_fn,\n\u001b[1;32m    274\u001b[0m                             \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                             hooks=self._train_monitors + extra_hooks)\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\u001b[0m in \u001b[0;36m_call_train\u001b[0;34m(self, _sentinel, input_fn, steps, hooks, max_steps)\u001b[0m\n\u001b[1;32m    658\u001b[0m                                    \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                                    \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                                    hooks=hooks)\n\u001b[0m\u001b[1;32m    661\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m       return self._estimator.fit(input_fn=input_fn,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps)\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    503\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    840\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    843\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run experiment \n",
    "learn_runner.run(generate_experiment_fn(), run_config=tf.contrib.learn.RunConfig(model_dir='testing2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "First let's generate our own sentences to see how the model classifies them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_to_array(s, separator=' '):\n",
    "    return s.split(separator)\n",
    "\n",
    "def generate_data_row(sentence, label, max_length):\n",
    "    sequence = np.zeros((max_length), dtype='int32')\n",
    "    for i, word in enumerate(string_to_array(sentence)):\n",
    "        sequence[i] = word_list.index(word)\n",
    "    \n",
    "    return sequence, label, max_length\n",
    "    \n",
    "def generate_data(sentences, labels, max_length):\n",
    "    data = []\n",
    "    for s, l in zip(sentences, labels):\n",
    "        data.append(generate_data_row(s, l, max_length))\n",
    "    \n",
    "    return np.asarray(data)\n",
    "\n",
    "\n",
    "sentences = ['i thought the movie was incredible and inspiring', \n",
    "             'this is a great movie',\n",
    "             'this is a good movie but isnt the best',\n",
    "             'it was fine i guess',\n",
    "             'it was definitely bad',\n",
    "             'its not that bad',\n",
    "             'its not that bad i think its a good movie',\n",
    "             'its not bad i think its a good movie']\n",
    "\n",
    "labels = [[1, 0],\n",
    "          [1, 0],\n",
    "          [1, 0],\n",
    "          [0, 1],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 0],\n",
    "          [1, 0]] # [1, 0]: positive, [0, 1]: negative\n",
    "\n",
    "my_test_data = generate_data(sentences, labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate predictions for the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/batch_32/model.ckpt-12547\n",
      "sentence: i thought the movie was incredible and inspiring\n",
      "good review: 0.932236 bad review: 0.0677641\n",
      "----------\n",
      "sentence: this is a great movie\n",
      "good review: 0.980506 bad review: 0.0194938\n",
      "----------\n",
      "sentence: this is a good movie but isnt the best\n",
      "good review: 0.926685 bad review: 0.0733154\n",
      "----------\n",
      "sentence: it was fine i guess\n",
      "good review: 0.504088 bad review: 0.495912\n",
      "----------\n",
      "sentence: it was definitely bad\n",
      "good review: 0.0672349 bad review: 0.932765\n",
      "----------\n",
      "sentence: its not that bad\n",
      "good review: 0.234982 bad review: 0.765018\n",
      "----------\n",
      "sentence: its not that bad i think its a good movie\n",
      "good review: 0.323138 bad review: 0.676862\n",
      "----------\n",
      "sentence: its not bad i think its a good movie\n",
      "good review: 0.461568 bad review: 0.538432\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "preds = estimator.predict(input_fn=get_input_fn(my_test_data, 1, 1, shuffle=False))\n",
    "\n",
    "print()\n",
    "for p, s in zip(preds, sentences):\n",
    "    print('sentence:', s)\n",
    "    print('good review:', p[0], 'bad review:', p[1])\n",
    "    print('-' * 10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "last_runtime": {
    "build_target": "//experimental/users/jamieas/transform_colab:notebook",
    "kind": "private"
   },
   "name": "Copy of CustomEstimator.ipynb",
   "provenance": [
    {
     "file_id": "0BwN-JPfIIHwgdFkwUTVIWTQwU00",
     "timestamp": 1496845355496
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
