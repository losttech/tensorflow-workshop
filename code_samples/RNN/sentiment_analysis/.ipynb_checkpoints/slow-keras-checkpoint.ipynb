{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Estimators\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "# Model builder\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "print (tf.__version__) # tested with v1.1\n",
    "\n",
    "# Input function\n",
    "from tensorflow.python.estimator.inputs import numpy_io\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# Enable TensorFlow logs\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# keras\n",
    "from tensorflow.contrib.keras.python.keras.preprocessing import sequence\n",
    "from tensorflow.contrib.keras.python.keras.layers import Embedding, GRU, Dense, SimpleRNN\n",
    "from tensorflow.contrib.keras.python.keras.layers import Reshape, Activation\n",
    "\n",
    "# data\n",
    "from tensorflow.contrib.keras.python.keras.datasets import imdb \n",
    "\n",
    "\n",
    "# Run an experiment\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 88584 words in the files\n"
     ]
    }
   ],
   "source": [
    "# map word to index\n",
    "word_to_index = imdb.get_word_index()\n",
    "# map index to word\n",
    "index_to_word = {}\n",
    "num_words = 0\n",
    "for k in word_to_index: \n",
    "    index_to_word[word_to_index[k]] = k\n",
    "    num_words += 1\n",
    "\n",
    "# turn a sequence into a sentence\n",
    "def get_sentence(seq):\n",
    "    sentence = ''\n",
    "    for v in seq:\n",
    "        if v != 0: # 0 means it was just added to the sentence so it could have maxlen words\n",
    "            sentence += index_to_word[int(v)] + ' '\n",
    "    return sentence\n",
    "\n",
    "# turn a sentence into a sequence\n",
    "def gen_sequence(sentence):\n",
    "    seq = []\n",
    "    for word in sentence:\n",
    "        seq.append(word_to_index[word])\n",
    "    return np.asarray(seq, dtype=np.float32)\n",
    "\n",
    "print('there are', num_words, 'words in the files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Example of a negative review\n",
      "------------------------------\n",
      "Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n",
      "\n",
      "------------------------------\n",
      "Example of a positive review\n",
      "------------------------------\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n"
     ]
    }
   ],
   "source": [
    "# ------------------- negative\n",
    "print('-' * 30)\n",
    "print('Example of a negative review')\n",
    "print('-' * 30)\n",
    "\n",
    "x = open('data/train/neg/0_3.txt')\n",
    "r = x.readline()\n",
    "print(r)\n",
    "\n",
    "# ------------------ positive\n",
    "print()\n",
    "print('-' * 30)\n",
    "print('Example of a positive review')\n",
    "print('-' * 30)\n",
    "\n",
    "x = open('data/train/pos/0_9.txt')\n",
    "r = x.readline()\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
    "\n",
    "# lets make things faster\n",
    "maxlen = 200\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "limit = x_train.shape[0]\n",
    "\n",
    "x_train = x_train[:limit].astype('float32')\n",
    "y_train = y_train[:limit].astype('int32')\n",
    "\n",
    "x_test = x_test[:limit].astype('float32')\n",
    "y_test = y_test[:limit].astype('int32')\n",
    "\n",
    "# y to onehot\n",
    "y_train_one_hot = np.zeros((limit, 2), dtype=np.float32)\n",
    "for i in range(limit):\n",
    "    y_train_one_hot[i][y_train[i]] = 1\n",
    "\n",
    "y_test_one_hot = np.zeros((limit, 2), dtype=np.float32)\n",
    "for i in range(limit):\n",
    "    y_test_one_hot[i][y_test[i]] = 1\n",
    "\n",
    "#print(y_train)\n",
    "#print(y_train_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 25\n",
    "STEPS = (limit / BATCH_SIZE) * 2\n",
    "\n",
    "# Define the model, using Keras\n",
    "def model_fn(features, targets, mode, params):\n",
    "\n",
    "    embed = Embedding(num_words, 128)(features['x'])\n",
    "    gru = GRU(128)(embed)\n",
    "    logits = Dense(2)(gru)\n",
    "    logits_softmax = Activation('softmax')(logits)\n",
    "\n",
    "    # make logits shape the same as the targets: (BATCH_SIZE, 2)\n",
    "    if mode != learn.ModeKeys.PREDICT:\n",
    "        logits = tf.reshape(logits, shape=[BATCH_SIZE, 2])\n",
    "        logits_softmax = tf.reshape(logits, shape=[BATCH_SIZE, 2])\n",
    "        targets = tf.reshape(targets, shape=[BATCH_SIZE, 2])\n",
    "    \n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "            onehot_labels=targets, logits=logits)\n",
    "    \n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            optimizer=\"Adam\")\n",
    "    \n",
    "    predictions = {\n",
    "        \"probabilities\": tf.nn.softmax(logits)\n",
    "    }\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "                    tf.argmax(input=logits_softmax, axis=1),\n",
    "                    tf.argmax(input=targets, axis=1))\n",
    "    }\n",
    "\n",
    "    return model_fn_lib.ModelFnOps(\n",
    "        mode=mode,\n",
    "        predictions=predictions,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_master': '', '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f51bc636198>, '_task_type': None, '_environment': 'local', '_tf_random_seed': None, '_save_checkpoints_steps': None, '_task_id': 0, '_model_dir': None, '_keep_checkpoint_max': 5, '_is_chief': True, '_save_summary_steps': 100, '_num_worker_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      "}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmptlllc6j1\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmptlllc6j1/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.697093, step = 1\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-01-18:38:51\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptlllc6j1/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-01-18:38:59\n",
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.5064, global_step = 1, loss = 0.697411\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "INFO:tensorflow:Validation (step 1): loss = 0.697411, accuracy = 0.5064, global_step = 1\n",
      "INFO:tensorflow:global_step/sec: 2.88576\n",
      "INFO:tensorflow:loss = 0.542751, step = 101 (34.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24555\n",
      "INFO:tensorflow:loss = 0.500627, step = 201 (23.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.18547\n",
      "INFO:tensorflow:loss = 0.497138, step = 301 (23.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34285\n",
      "INFO:tensorflow:loss = 0.419409, step = 401 (23.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26523\n",
      "INFO:tensorflow:loss = 0.323458, step = 501 (23.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26512\n",
      "INFO:tensorflow:loss = 0.441192, step = 601 (23.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24252\n",
      "INFO:tensorflow:loss = 0.383271, step = 701 (23.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.33602\n",
      "INFO:tensorflow:loss = 0.401585, step = 801 (18.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.86105\n",
      "INFO:tensorflow:loss = 0.342149, step = 901 (17.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.87515\n",
      "INFO:tensorflow:loss = 0.220034, step = 1001 (17.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.76368\n",
      "INFO:tensorflow:loss = 0.39617, step = 1101 (17.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.83836\n",
      "INFO:tensorflow:loss = 0.220169, step = 1201 (17.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.8894\n",
      "INFO:tensorflow:loss = 0.399787, step = 1301 (16.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.86954\n",
      "INFO:tensorflow:loss = 0.138703, step = 1401 (17.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.85165\n",
      "INFO:tensorflow:loss = 0.444231, step = 1501 (17.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.91257\n",
      "INFO:tensorflow:loss = 0.614964, step = 1601 (16.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.84146\n",
      "INFO:tensorflow:loss = 0.229508, step = 1701 (17.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.91633\n",
      "INFO:tensorflow:loss = 0.123582, step = 1801 (16.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.91386\n",
      "INFO:tensorflow:loss = 0.0803328, step = 1901 (16.909 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmptlllc6j1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.275166.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-01-18:45:30\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptlllc6j1/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-01-18:45:35\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.8164, global_step = 2000, loss = 0.41119\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.81639999, 'global_step': 2000, 'loss': 0.41119015}, [])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "# Input functions\n",
    "\n",
    "# this couldn't possibly be right... \n",
    "x_train_dict = {'x': x_train }\n",
    "\n",
    "train_input_fn = numpy_io.numpy_input_fn(\n",
    "          x_train_dict, y_train_one_hot, batch_size=BATCH_SIZE, \n",
    "           shuffle=False, num_epochs=None, \n",
    "            queue_capacity=1000, num_threads=1)\n",
    "\n",
    "x_test_dict = {'x': x_test }\n",
    "\t\n",
    "test_input_fn = numpy_io.numpy_input_fn(\n",
    "          x_test_dict, y_test_one_hot, batch_size=BATCH_SIZE, shuffle=False, num_epochs=1)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "model_params = {\"learning_rate\": LEARNING_RATE}\n",
    "\n",
    "# create estimator\n",
    "estimator = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params)\n",
    "\n",
    "# create experiment\n",
    "def generate_experiment_fn():\n",
    "  \n",
    "  \"\"\"\n",
    "  Create an experiment function given hyperparameters.\n",
    "  Returns:\n",
    "    A function (output_dir) -> Experiment where output_dir is a string\n",
    "    representing the location of summaries, checkpoints, and exports.\n",
    "    this function is used by learn_runner to create an Experiment which\n",
    "    executes model code provided in the form of an Estimator and\n",
    "    input functions.\n",
    "    All listed arguments in the outer function are used to create an\n",
    "    Estimator, and input functions (training, evaluation, serving).\n",
    "    Unlisted args are passed through to Experiment.\n",
    "  \"\"\"\n",
    "\n",
    "  def _experiment_fn(output_dir):\n",
    "\n",
    "    train_input = train_input_fn\n",
    "    test_input = test_input_fn\n",
    "    \n",
    "    return tf.contrib.learn.Experiment(\n",
    "        estimator,\n",
    "        train_input_fn=train_input,\n",
    "        eval_input_fn=test_input,\n",
    "        train_steps=STEPS\n",
    "    )\n",
    "  return _experiment_fn\n",
    "\n",
    "# run experiment \n",
    "learn_runner.run(generate_experiment_fn(), '/tmp/outputdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmptlllc6j1/model.ckpt-2000\n"
     ]
    }
   ],
   "source": [
    "# generate predictions\n",
    "preds = list(estimator.predict(input_fn=test_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 12934\n",
      "------------------------------\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     1    11   285     9 22970\n",
      " 13245  2137   299  4409 62192     6  2920   298    37     9   267    18\n",
      "     4   255    37  1894    27  4494   315  3018    11     6   281     4\n",
      "   255    15  1894    27   436   223    10    10    14     9     6   483\n",
      "   421   787    44   294    37     9    23     6  1573  5034  1311     6\n",
      "  3128    11     6   680  1541    38     8  1128  4409     9    24  1097\n",
      "  2848    18    14  1154    29  3775    46    40     6  8891  8978    11\n",
      "     4 70118    29    62   242  1231    46    40     6  8891  8978  1764\n",
      "    21    51    29  2147     9    53    76    53    74    29  6658    14\n",
      "    20    80    97    25   462     5    80    97    25  1415 13245  2137\n",
      "     9    66    52    11    14    22   448    23     4   667    34  4409\n",
      " 55907 62192    10    10    39   294    13  3543     8    14    20     9\n",
      "   643   275    39     4   274     6   274    13  5231     9    66    52\n",
      "  2185    14     9     6    52    20    12    47   142    18   316     5\n",
      "    13    66   510    12    70   294   135   735]\n",
      "prediction: 1\n",
      "target: 1\n",
      "sentence: the this dvd it dissolving desdemona insane effects inventive exorcises is amongst said like it set but of found like understanding be hop special laura this is actor of found for understanding be problem whole i i as it is humor supposed 9 has play like it are is winning uplifting fully is arm this is call agent her in died inventive it his bored people's but as trash all darker some just is golf bothering this of opiate all story away values some just is golf bothering surprising not when all dreadful it up get up been all voyage as on into could have dark to into could have critics desdemona insane it had very this as you fans are of robert who inventive painfulness exorcises i i or play was jamie in as on it cool money or of ending is ending was cream it had very asian as it is very on that there back but seeing to was had town that well play why needs \n",
      "\n",
      "test: 24959\n",
      "------------------------------\n",
      "[ 2856  2684    19    27   118   971  1914   799  1820  5889    15    16\n",
      " 11825  1113    29    16     4  2095   268   632   366    27   205 10609\n",
      "     5    78  2852  1059    56    19    90  2107     5  3652    11     6\n",
      "    96    26   729    21  3652    16     4    53  5626     7     4   107\n",
      "    12     9   614     8    67  2107    17  1705   541    21  3652    11\n",
      "     4  9442    65   443 68604  3861    27   925   313    42  3606   970\n",
      "    42  4652 31013  2533   679   148   555    23    68  6770  4371    88\n",
      "   240    99  1543   252    23    27  2194     5     4   861  1074    29\n",
      "  2533   839  1958  2533    93     4    65   411 13926    21    14 13926\n",
      "  5041     9    43     6 63303   650     7  3652     5    27   999    50\n",
      "    26   211    54    13   320   873     6   462  1406    42    35   311\n",
      "     8   140 32892    33    49   213    12   152   140  1685    83 11825\n",
      "   113    43     4   268  3413   650    12    82   152  9555    83    27\n",
      "  1651     8    30  1192    53    74     6 30342 45341    40     4 11037\n",
      "    56 15954     7 12194 11467     4   336    24     4 10963    42 15538\n",
      "     7  6302     5   349     5  5325  2065   224    11     4 20062    14\n",
      "     9    43     6    58   880   418     7  5628]\n",
      "prediction: 0\n",
      "target: 0\n",
      "sentence: bollywood jungle film be where admit delightful editing explanation feat for with explicitly ultimately all with of rob goes reality friends be right saturated to do purely pace she film made types to push this is too he sets not push with of up demonstrates br of seen that it shown in can types movie energy voice not push this of micheal their called duwayne warren be interested everyone it's distant casting it's amounts passers technically modern though god are were bikini honesty most kind movies imagination woman are be barbara to of okay uses all technically hear opposite technically way of their dialogue readings not as readings america's it out is streeb change br push to be cop more he gets no was star nature is dark aspects it's so night in through 14a they good come that thing through willing first explicitly acting out of goes karloff change that other thing dusty first be stone in at sick up been is flickers actionscenes just of trelkovsky she arabia br typecast prayer of help his of effeminate it's woodland br 200 to budget to misleading decade bit this of restoring as it out is my romance felt br bow \n",
      "\n",
      "test: 23486\n",
      "------------------------------\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     1   103     4   831     6    22    15 13925     4   113     7\n",
      " 12500  2112     4   831     8   141  3818  8726    15    12    93     4\n",
      "   856 12500   415  1195   367   216  1842     5    27  3367  1146     7\n",
      "   443  2219    42  1593 12234  2544     4   831     4   116     9    38\n",
      "    78    15    14   823   453   461     6   212    18     4  2174  4477\n",
      "     5     6  1521    18     4  1842  5131   337    11   346     9     4\n",
      "    20   290     6   168    57   894  1206    40    78   116    19   642\n",
      " 69697  2531  2458  3795   252     8    30   252     8    30     4    65\n",
      "     9  3314   125    39     4 13196  1112  1065 36028    63   466     9\n",
      " 25429     7     6    73   573 12500  1626    11  1593 12234     9   131\n",
      "   290     6   168    23     6  4816  2407    88    12   287   147   780\n",
      "   707 12500     5    23    35  1966  2407    88     7    29   283  2531\n",
      "   116     5   455   177   587   308  4252    32    11    32 39319   542\n",
      " 63235     9   233    21     6   542    22   798]\n",
      "prediction: 0\n",
      "target: 0\n",
      "sentence: the watch of space is you for bravado of acting br temperature brown of space in should ho monologues for that way of forget temperature piece somewhere camera saw field to be painting pointless br called send it's intense ida magical of space of love it her do for as peter lives friend is must but of graphic 35 to is lighting but of field kyle completely this men it of on main is few even superb f just do love film started renounce committed degree areas woman in at woman in at of their it dragged better or of homages violent decides deere really throughout it fascinatingly br is much extremely temperature teen this intense ida it these main is few are is serving cutting most that worth now die silly temperature to are so ups cutting most br all wasn't committed love to direction down s audience surfing an this an vishk highly candidature it last not is highly you typical \n",
      "\n",
      "test: 23369\n",
      "------------------------------\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     1  8426    20  5958\n",
      "   203    28   510     5  1150    14    22   545    88    12    16  8426\n",
      "    21    13   258    12     8    30  3104  2332  4953   357     5  5617\n",
      "   174    13  1781 53457    11   661     8  8817  7821     7    14   912\n",
      "     7     6    22  5509  4213    14    22    17   112    44     6   378\n",
      "     7 12969    15  5994     8  2306    56    21    13    80   140    31\n",
      "  1037    13   104    12     9    44   107 12969    15    28  5978     6\n",
      "  1110     7 17605     5  3126  1729    15    97    57   281     8   259\n",
      "    13    28    77   579    15    31     7     4   156    11     4    22\n",
      "  2534  1720   103     4    22     5    13    62   264    12    54    29\n",
      "   219    27   239    29   242  1706    51     6  7534   373   292    29\n",
      "    69   224     5  1706    15     4    64    96     8   798 11648  4467\n",
      "    16     8    97     4   194  6389    63    13   244   252    16    76\n",
      "    53   905     5     6    76   128   239    15    29    69   224    11\n",
      " 14830  3673    92   437   129    58    42   278    23    14  1235   239\n",
      "    45   164    21     6   912    11     6 32095]\n",
      "prediction: 0\n",
      "target: 0\n",
      "sentence: the crowded on neurotic action one town to hair as you fight most that with crowded not was although that in at cook hunt willis rest to curly cast was twenty 'terror this documentary in shiny je br as male br is you corpses stinker as you movie never has is stars br conceal for mermaid in facts she not was into through by wrote was two that it has seen conceal for one seeming is trouble br danni to enjoyment unusual for could even actor in especially was one will coming for by br of before this of you recognize filmmaker watch of you to was story looking that no all least be probably all away station when is shore tell together all me bit to station for of see too in typical hacks pretending with in could of thought identical really was rather woman with get up earlier to is get still probably for all me bit this electrocuted tall then hope man my it's sense are as surprisingly probably if director not is male this is glisten \n",
      "\n",
      "test: 5062\n",
      "------------------------------\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     1     4    20    16   165    24    15    78   262   114  1567\n",
      "    21     4     5  8557   284    36  2471    18     4   971   217    16\n",
      "     6   117 21549    11     4   116  2550    13    62    28  2218   294\n",
      "   334     4   326     7   170     8   938    16    55  5792     5     4\n",
      "   293   109  7533   285    15  2708   126   573    93    90   643  1451\n",
      "    21    24    55    76    38    54   225     6 25517  3706    18     6\n",
      "   971   284    10    10     4   769    16   221    12   961    44     4\n",
      "   888     7    89     4   875     7 20925    80    30  2400    11     4\n",
      "   705   434 20925   586    30  1668    18     4  4935    11     4    20\n",
      "    21    45   131     6  7513  3743    60    18   639 11636    26   131\n",
      "    84   208    10    10     4    20   286   572   318    21    12   131\n",
      "     9     6   176   128    74    49     7     4  3043   626   315     4\n",
      "  2226   387   178    24   859     4  1463  5072  4710    13   202    12\n",
      "     6   470   237    12   161   484  7225    21     4  3179   310   166\n",
      "    14    20     6   158    13   131    40   884  1165  4386   490    40\n",
      "    14    20    21    12   528    30   129   514]\n",
      "prediction: 1\n",
      "target: 0\n",
      "sentence: the of on with look his for do course little 50 not of to presume shows from adventures but of admit almost with is over diarrhea this of love friday was story one combination play fan of less br part in keeps with time feeding to of watched being flag dvd for clichéd your extremely way made cool falling not his time get her no music is arne fx but is admit shows i i of using with done that total has of 20 br don't of difficult br sod into at offensive this of thriller waste sod attempt at carry but of keith this of on not if these is sammo outcome which but hilarious slang he these great times i i of on three happened excellent not that these it is quite still been good br of expressions scary special of excited episode want his poorly of spot masses resort was own that is wanted he's that nothing writing intro not of holiday house find as on is didn't was these just needed mad shirley guys just as on not that parts at man starts \n",
      "\n",
      "test: 1542\n",
      "------------------------------\n",
      "[  111     7     4  3277    19     4   582  5113     7     4  3446  3239\n",
      "  6281    17     4   182  3895  3418    38   127  4659    18  3239     5\n",
      "   671    17    75 14581  3239     5   671    75   216     8     6  5113\n",
      "    11   365    53  3239     9 10893   329  3239     9  4891     4  3455\n",
      "  3746     9  1944     5   678   653    10    10    14    22    80    30\n",
      "  1193     5 12111    48   335   162     8     4  2989    25   203  4027\n",
      "    33    86    19  2563     5  8692    88     4 10099    26    38  2671\n",
      "    12   144    30  2594   829   724  2420   724  8715     4 10400     9\n",
      " 11205    10    10 12170     9     4  1152    88   263  6371   581  3798\n",
      "    80    30     4 11002    91 21928    54     4  1866     7  1708 76351\n",
      "   137 20997  2091    62   376    25    15     4   194  4803    80    30\n",
      "     4  1370     8   798   315     6    58     7  3112     4  4600    46\n",
      "   876     7 12170    80    97    12   878    48    24  1167     8  4560\n",
      "    35  8903  1830   209   263  6225     8  8128   178    10    10  5113\n",
      "  3239     9    57  1207     6  2989    18  3772    34     5  9001 16832\n",
      "    14  1834    80    30    33   263 13944  5525    74    75   104    14\n",
      "    22     9     6 15673  3984   168    33    12]\n",
      "prediction: 1\n",
      "target: 1\n",
      "sentence: plot br of closely film of experience exchange br of medium cousin divorced movie of young demands represents her end purchased but cousin to important movie bad completists cousin to important bad saw in is exchange this full up cousin it farcical read cousin it poem of le scientific it concerned to word taking i i as you into at failed to coolness what poor actually in of inspector have action intrigue they how film performed to animations most of surpassed he her stayed that real at donald leads predictable presents predictable judges of superlative it intentioned i i resentment it of younger most comes hindi alone wannabe into at of danning its impactful no of hadn't br epic quoit go serpico awkward story stupid have for of thought lone into at of details in typical special is my br succeed of poetry some free br resentment into could that screenplay what his college in cheated so jones' deserve comedy comes audition in bernsen want i i exchange cousin it even anti is inspector but sticks who to beth hash as dick into at they comes emphasized invited been bad two as you it is vignette mountains few they that \n",
      "\n",
      "test: 16188\n",
      "------------------------------\n",
      "[    7   134   860   108   151    50    16    31  6456   653    50    16\n",
      "     6    55  7442   361     7    51   610    40  6594 46220    18     4\n",
      "  4260    14    16    24     6    78   155    33    32     4  1334 21974\n",
      "    40   168    16    55  5754     5   955    11    49   771    12   610\n",
      "    40     6  2409   227     7   988   498   405    16 15951    83     6\n",
      "   801  7302    22    19     6   312  2122   967  3160   109   748    63\n",
      " 18550    98    19  3400     7  1613     5     6    87  1318  2367    14\n",
      "     9    35  3160    22    18    32  2088   151   695  2429    53    18\n",
      "  1155  1221     4 32526   451   262    12     9     6   227   629   133\n",
      "     5    50   315     4  3162  3309    21    50     9   958     7    87\n",
      "   538    18  1473    17    35  1158    33   222 18161    38    13   447\n",
      "     4  1036   538     5  6144     4    85 42234     7     4    22    10\n",
      "    10     6    87    22   793  9263   118    13    92   202    12     6\n",
      "   158    88    13   244 12367     8   126    81    15   935    13   122\n",
      "    40     6   171     7     4 10958    85   108     6   227    53   572\n",
      " 32526    21    15   152   384    25  1616  3409    46   150     5    67\n",
      "    12    81    12     5    81   624     6  2077]\n",
      "prediction: 1\n",
      "target: 1\n",
      "sentence: br while premise many old more with by id taking more with is time epics low br when song just melvyn krimis but of advance as with his is do 10 they an of nobody walton just few with time marries to plenty this good haven't that song just is holding far br masterpiece past gives with biographies first is famous faux you film is during speed business drink being near really brainy any film they'd br shouldn't to is him narrative hall as it so drink you but an logic old british qualities up but adult brain of wars' beginning course that it is far hero scene to more special of searching rushed not more it brings br him blood but fresh movie so respect they there's sinclair her was several of copy blood to wrenching of because scholes br of you i i is him you re traumatized where was then own that is didn't most was rather slaughterhouse in your people for america was off just is again br of gazzara because many is far up happened wars' not for thing let have chinese smoking some years to can that people that to people cinematography is allows \n",
      "\n",
      "test: 12150\n",
      "------------------------------\n",
      "[   14    16    66     6   212    10    10     4    65     9     6  5034\n",
      "  1844  1422    15   304   273   120     6   378     7  5122  9724 11381\n",
      "   685    11   119 10444    18     6   282     8   412    59    47     6\n",
      "   464   256    34  3164  2021    37 18992    41    21    59   304    90\n",
      "    18  2482    59     9  3624     8     6  1042   256    34  2595  6378\n",
      "    21    29     9   532  5742     5   218   928    11    41    59 12837\n",
      "    18     6 21874    15   738    41  2724    59  5757    90    64     8\n",
      "   169    15    50     9  6040    11    27   223     5    59    70   115\n",
      "    28     6   506    19    90   367   266     4  1042    37 33287  4761\n",
      "     6 36019    11    41 24905    64     8   169    46   303    15    29\n",
      "  1388    41   103    32     4   506  3861  4454    11    41   658    37\n",
      "   461     6  1023    21    59  2503    15    45    66  2595    59  1388\n",
      "   103    32  1471   246   859     4   360    43   106     6   378     7\n",
      "   672     7    17     4   182   505     5  4092    32   413   788    10\n",
      "    10    48   129    26   126   918     8   106    14    20  1070    46\n",
      "    18     4   477   136     4 60767     7     4   156   276  5794  3414\n",
      "     8   902    12     9    24     8    30  1049]\n",
      "prediction: 1\n",
      "target: 0\n",
      "sentence: as with had is must i i of their it is uplifting plots support for beautiful put show is stars br 1995 shouts fenton due this did crouse but is everything in person would there is under anyone who scripts murdered like simulate about not would beautiful made but weeks would it trap in is following anyone who regret sensible not all it expect gear to interesting comment this about would reaper but is scarlet's for rock about dress would rendered made see in same for more it brooding this be whole to would well best one is flick film made camera trying of following like brannagh lively is kornbluth's this about newport see in same some seem for all developed about watch an of flick warren dinosaur this about order like friend is rich not would sympathy for if had regret would developed watch an difference worst poorly of hollywood out character is stars br rating br movie of young hand to satisfied an lost elements i i what man he your emotional in character as on party some but of amazing scenes of 'eliminated' br of before maybe norm stronger in dramatic that it his in at office \n",
      "\n",
      "test: 6548\n",
      "------------------------------\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     1 16574  3891     9    35   204     5   218    40   148    85    78\n",
      "   910    22  1361     6   430   773 12940  1102     8     6   162   513\n",
      "     5    47  1113    33   396    29     9    52  4730     6   250    11\n",
      "     4  3781  1131    19    41  1432    54    68   519    16  8072   125\n",
      "     6  3026 16574  4232  8133  2820    39     4   671  4873  4998  9040\n",
      "     9  2760 12940    17     6  1213     8    79     6 18114   367     4\n",
      "    96    29   215  1260     8    27   799    44    41  1213     5   417\n",
      "   397    14 18114 16574  1747     8     4  3026    59  1131    23     5\n",
      "    95    59   214    11     4  8046   519     7    41  1432     5    36\n",
      " 10216    56   303    17    29  3758    41    29   659     6   250    37\n",
      "   272    43    40    41    81    25   264    11  9580 16574  3891     9\n",
      "     6    52    20     8    67   150     5    95    21    36  1201   202\n",
      "    88   910   738     8  2233   285    56    19   379   102     5   287\n",
      "    13   202    12     6    10    10   693   158]\n",
      "prediction: 1\n",
      "target: 1\n",
      "sentence: the halls genres it so i've to interesting just though because do badly you slowly is worse easy individually dancing in is actually kill to there ultimately they doing all it very fascinated is fun this of sloppy effective film about serial no were late with fairness better is navy halls judging 1966 depiction or of important royal spain ogre it flashback individually movie is thanks in also is congregation camera of too all isn't west in be editing has about thanks to case often as congregation halls teacher in of navy would effective are to them would role this of motivated late br about serial to from restoration she seem movie all elaborate about all talking is fun like different out just about people have looking this looney halls genres it is very on in can years to them not from questions own most badly rock in gordon dvd she film perhaps characters to worth was own that is i i supporting didn't \n",
      "\n",
      "test: 13184\n",
      "------------------------------\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     1    13    40   102    21    14\n",
      "    31     9     4   118   207   110    33 12070  1626  4830    19   861\n",
      "  1663  2160     9  5318     5     4   229     9   480   262  1069    45\n",
      "   424     8   193   273    23     4   270     7   160     7   102    25\n",
      "    92    28     8  1041    19    41   193    23   285     8    79     6\n",
      "   176    46     7    14    12    93    72   104     6   176    44  8947\n",
      "     5   671   353     8   838     6   915   167    19 31437    24  1167\n",
      "    21     6   117   330 13119     4 77678   861 23298    15    26   210\n",
      "   984    54  1714    79   295     8    97   233     9  1428    56     8\n",
      "  1927   641   133    21    24     6  1043   641]\n",
      "prediction: 1\n",
      "target: 1\n",
      "sentence: the was just characters not as by it of where always life they pinned teen tends film okay sleep robin it conscience to of guy it heart course cartoon if absolutely in long put are of place br funny br characters have then one in plain film about long are dvd in also is quite some br as that way we two is quite has goo to important classic in atmosphere is forced going film verboten his college not is over second valiant of recant okay marian for he point create no comedic also american in could last it million she in screaming usual scene not his is mentioned usual \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of outputs we want to see the prediction\n",
    "NUM_EVAL = 10\n",
    "def check_prediction(x, y, p, index):\n",
    "    print('prediction:', np.argmax(p[index]['probabilities']))\n",
    "    print('target:', np.argmax(y[index]))\n",
    "    print('sentence:', get_sentence(x[index]))\n",
    "\n",
    "for i in range(NUM_EVAL):\n",
    "    index = np.random.randint(limit)\n",
    "    print('test:', index)\n",
    "    print('-' * 30)\n",
    "    print(np.asarray(x_test[index], dtype=np.int32))\n",
    "    check_prediction(x_test, y_test_one_hot, preds, index)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmptlllc6j1/model.ckpt-2000\n",
      "bad\n",
      "[{'probabilities': array([ 0.60433686,  0.39566317], dtype=float32)}]\n",
      "prediction: 0\n"
     ]
    }
   ],
   "source": [
    "test_sentence = ['bad']\n",
    "seq = np.asarray([gen_sequence(test_sentence)], dtype=np.float32)\n",
    "dict_seq = {'x': seq}\n",
    "my_test_input_fn = numpy_io.numpy_input_fn(dict_seq, batch_size=1, shuffle=False, num_epochs=1)\n",
    "\n",
    "my_preds = list(estimator.predict(input_fn=my_test_input_fn))\n",
    "print(' '.join(test_sentence))\n",
    "print(my_preds)\n",
    "print('prediction:', np.argmax(my_preds[0]['probabilities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmptlllc6j1/model.ckpt-2000\n",
      "good\n",
      "[{'probabilities': array([ 0.37379846,  0.62620157], dtype=float32)}]\n",
      "prediction: 1\n"
     ]
    }
   ],
   "source": [
    "test_sentence = ['good']\n",
    "seq = np.asarray([gen_sequence(test_sentence)], dtype=np.float32)\n",
    "dict_seq = {'x': seq}\n",
    "my_test_input_fn = numpy_io.numpy_input_fn(dict_seq, batch_size=1, shuffle=False, num_epochs=1)\n",
    "\n",
    "my_preds = list(estimator.predict(input_fn=my_test_input_fn))\n",
    "print(' '.join(test_sentence))\n",
    "print(my_preds)\n",
    "print('prediction:', np.argmax(my_preds[0]['probabilities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmptlllc6j1/model.ckpt-2000\n",
      "not bad\n",
      "[{'probabilities': array([ 0.56060457,  0.43939534], dtype=float32)}]\n",
      "prediction: 0\n"
     ]
    }
   ],
   "source": [
    "test_sentence = ['not', 'bad']\n",
    "seq = np.asarray([gen_sequence(test_sentence)], dtype=np.float32)\n",
    "dict_seq = {'x': seq}\n",
    "my_test_input_fn = numpy_io.numpy_input_fn(dict_seq, batch_size=1, shuffle=False, num_epochs=1)\n",
    "\n",
    "my_preds = list(estimator.predict(input_fn=my_test_input_fn))\n",
    "print(' '.join(test_sentence))\n",
    "print(my_preds)\n",
    "print('prediction:', np.argmax(my_preds[0]['probabilities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sentence = ['not', 'good']\n",
    "seq = np.asarray([gen_sequence(test_sentence)], dtype=np.float32)\n",
    "dict_seq = {'x': seq}\n",
    "my_test_input_fn = numpy_io.numpy_input_fn(dict_seq, batch_size=1, shuffle=False, num_epochs=1)\n",
    "\n",
    "my_preds = list(estimator.predict(input_fn=my_test_input_fn))\n",
    "print(' '.join(test_sentence))\n",
    "print(my_preds)\n",
    "print('prediction:', np.argmax(my_preds[0]['probabilities']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
