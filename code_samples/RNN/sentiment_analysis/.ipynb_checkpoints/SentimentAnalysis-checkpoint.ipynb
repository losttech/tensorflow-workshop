{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "mDT8S9C9CYtr"
   },
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Feeding function for enqueue data\n",
    "# \n",
    "from tensorflow.python.estimator.inputs.queues import feeding_functions as ff\n",
    "\n",
    "# Rnn common functions\n",
    "from tensorflow.contrib.learn.python.learn.estimators import rnn_common\n",
    "\n",
    "# Run an experiment\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "\n",
    "# Input function\n",
    "from tensorflow.python.estimator.inputs import numpy_io\n",
    "\n",
    "# Helpers for data processing\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UrAyWt23AtCM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 62701 words in the train and test files\n"
     ]
    }
   ],
   "source": [
    "# data from: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "TRAIN_INPUT = 'data/train.csv'\n",
    "TEST_INPUT = 'data/test.csv'\n",
    "\n",
    "# data manually generated\n",
    "MY_TEST_INPUT = 'data/mytest.csv'\n",
    "\n",
    "# Parameters for training\n",
    "STEPS = 5000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Parameters for data processing\n",
    "SEQUENCE_LENGTH_KEY = 'sequence_length'\n",
    "REVIEW_KEY = 'review'\n",
    "CLASSIFICATION_KEY = 'is_positive'\n",
    "\n",
    "# Vocabulary size\n",
    "VOCAB_FILE = 'data/vocab.txt'\n",
    "VOCAB = [line[:len(line)-1] for line in open(VOCAB_FILE)]\n",
    "VOCAB_SIZE = len(VOCAB) - 1\n",
    "\n",
    "print('there are %s words in the train and test files' % VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0dlZ9C27M-bS"
   },
   "outputs": [],
   "source": [
    "# This function creates a sparse tensor in the following way, given:\n",
    "# indices = [[0, 0], [1, 1], [2, 2]]\n",
    "# values = [1, 2, 3]\n",
    "# dense_shape = [3, 4]\n",
    "#\n",
    "# The output will be a sparse tensor that represents this dense tensor:\n",
    "# [ \n",
    "#   [1, 0, 0, 0]\n",
    "#   [0, 2, 0, 0]\n",
    "#   [0, 0, 3, 0]\n",
    "# ]\n",
    "#\n",
    "# We're using this to generate a Sparse tensor that can be easily\n",
    "# formated in a one hot representation.\n",
    "# More at: https://www.tensorflow.org/api_docs/python/tf/SparseTensor\n",
    "def _sparse_string_to_index(sp, mapping):\n",
    "    return tf.SparseTensor(indices=sp.indices,\n",
    "                           values=tf.contrib.lookup.string_to_index(sp.values,\n",
    "                                                                    mapping),\n",
    "                           dense_shape=sp.dense_shape)\n",
    "\n",
    "def array_to_onehot(array, num_dim=2):\n",
    "    array = np.asarray(array, dtype=np.int32)\n",
    "    onehot = np.zeros([array.shape[0], num_dim])\n",
    "    for i in range(array.shape[0]):\n",
    "        onehot[i][array[i]] = 1\n",
    "    return onehot\n",
    "\n",
    "# Returns the column values from a CSV file as a list\n",
    "def _get_csv_column(csv_file, column_name):\n",
    "    with open(csv_file, 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "        return df[column_name].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input function used for training and testing                                                \n",
    "def get_input_fn(csv_file, batch_size, epochs=1):\n",
    "    with open(csv_file, 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "        \n",
    "        def input_fn():\n",
    "            # Using queue with multiple threads to make it scalable\n",
    "            pandas_queue = ff._enqueue_data(df,\n",
    "                                            capacity=1024,\n",
    "                                            shuffle=True,\n",
    "                                            min_after_dequeue=256,\n",
    "                                            num_threads=4,\n",
    "                                            enqueue_size=16,\n",
    "                                            num_epochs=epochs)\n",
    "\n",
    "            _, review, classification, seq_len = pandas_queue.dequeue_up_to(batch_size)\n",
    "            \n",
    "            # Split sentences into words\n",
    "            split_review = tf.string_split(review, delimiter=' ')\n",
    "            # Creating a tf constant to hold the word -> index\n",
    "            # this is need to create the sparse tensor and after the one hot encode\n",
    "            mapping = tf.constant(VOCAB, name=\"mapping\")\n",
    "            \n",
    "            # Words represented in a sparse tensor\n",
    "            integerized_review = _sparse_string_to_index(split_review, mapping)\n",
    "\n",
    "            # Converting numbers to int 32\n",
    "            classification = tf.cast(classification, tf.int32)\n",
    "            seq_len = tf.cast(seq_len, tf.int32)\n",
    "            \n",
    "            # Generates batcheds\n",
    "            batched = tf.train.shuffle_batch({REVIEW_KEY: integerized_review,\n",
    "                                              SEQUENCE_LENGTH_KEY: seq_len,\n",
    "                                              CLASSIFICATION_KEY: classification},\n",
    "                                             batch_size,\n",
    "                                             min_after_dequeue=100,\n",
    "                                             num_threads=4,\n",
    "                                             capacity=1000,\n",
    "                                             enqueue_many=True,\n",
    "                                             allow_smaller_final_batch=True)\n",
    "            \n",
    "            label = batched.pop(CLASSIFICATION_KEY)\n",
    "            label_onehot = tf.one_hot(label, 2)\n",
    "            return batched, label_onehot\n",
    "    return input_fn\n",
    "\n",
    "# Creating my own input function for a custom CSV file\n",
    "# it's simpler than the input_fn above but just used for small tests\n",
    "def get_my_input_fn():\n",
    "    def _input_fn():\n",
    "        with open(MY_TEST_INPUT, 'r') as f:\n",
    "            df = pd.read_csv(f)\n",
    "\n",
    "            review = df.review.tolist()\n",
    "\n",
    "            # Split sentences into words\n",
    "            split_review = tf.string_split(review, delimiter=' ')\n",
    "            # Creating a tf constant to hold the word -> index\n",
    "            # this is need to create the sparse tensor and after the one hot encode\n",
    "            mapping = tf.constant(VOCAB, name=\"mapping\")\n",
    "            \n",
    "            # Words represented in a sparse tensor\n",
    "            integerized_review = _sparse_string_to_index(split_review, mapping)\n",
    "            \n",
    "            x = {REVIEW_KEY: integerized_review, SEQUENCE_LENGTH_KEY: df.sequence_length.tolist()}\n",
    "\n",
    "            y = df.is_positive.tolist()\n",
    "\n",
    "            return x, y\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "m5UJyvW5P0Sy"
   },
   "outputs": [],
   "source": [
    "train_input_fn = get_input_fn(TRAIN_INPUT, BATCH_SIZE, None)\n",
    "test_input_fn = get_input_fn(TEST_INPUT, BATCH_SIZE)\n",
    "my_test_input_fn = get_my_input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lE4c3ELMQjHJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-52-82d13ba8809b>:19: string_to_index (from tensorflow.contrib.lookup.lookup_ops) is deprecated and will be removed after 2017-01-07.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to index_table_from_tensor and call the lookup method of the returned table.\n",
      "({'sequence_length': array([80, 80, 80, 80, 80, 80, 80, 80, 71, 80, 80, 80, 80, 80, 80, 80, 80,\n",
      "       80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
      "       80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
      "       80, 80, 58, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80], dtype=int32), 'review': SparseTensorValue(indices=array([[ 0,  0],\n",
      "       [ 0,  1],\n",
      "       [ 0,  2],\n",
      "       ..., \n",
      "       [63, 77],\n",
      "       [63, 78],\n",
      "       [63, 79]]), values=array([  37, 1527,   10, ..., 1909,   91,   91]), dense_shape=array([64, 80]))}, array([[ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing the input function\n",
    "with tf.Graph().as_default():\n",
    "    train_input = train_input_fn()\n",
    "    with tf.train.MonitoredSession() as sess:\n",
    "        #print (train_input)\n",
    "        print (sess.run(train_input))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Estimator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "VxXAUrYN7TvR"
   },
   "outputs": [],
   "source": [
    "def get_model_fn(rnn_cell_sizes,\n",
    "                 label_dimension,\n",
    "                 dnn_layer_sizes=[],\n",
    "                 optimizer='SGD',\n",
    "                 learning_rate=0.01,\n",
    "                 embed_dim=128):\n",
    "    \n",
    "    def model_fn(features, labels, mode):\n",
    "        \n",
    "        review = features[REVIEW_KEY]\n",
    "        sequence_length = tf.cast(features[SEQUENCE_LENGTH_KEY], tf.int32)\n",
    "        labels_onehot = labels\n",
    "        \n",
    "        # Creating dense representation for the sentences\n",
    "        # and then converting it to embeding representation\n",
    "        dense_review = tf.sparse_tensor_to_dense(review, default_value=VOCAB_SIZE)\n",
    "        embed_review = tf.contrib.layers.embed_sequence(dense_review,\n",
    "                                                        vocab_size=VOCAB_SIZE,\n",
    "                                                        embed_dim=embed_dim)\n",
    "        \n",
    "        \n",
    "        # Each RNN layer will consist of a LSTM cell\n",
    "        rnn_layers = [tf.contrib.rnn.LSTMCell(size) for size in rnn_cell_sizes]\n",
    "        \n",
    "        # Construct the layers\n",
    "        multi_rnn_cell = tf.contrib.rnn.MultiRNNCell(rnn_layers)\n",
    "        \n",
    "        # Runs the RNN model dynamically\n",
    "        # more about it at: \n",
    "        # https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
    "                                                 inputs=embed_review,\n",
    "                                                 sequence_length=sequence_length,\n",
    "                                                 dtype=tf.float32)\n",
    "\n",
    "        # Slice to keep only the last cell of the RNN\n",
    "        last_activations = rnn_common.select_last_activations(outputs,\n",
    "                                                              sequence_length)\n",
    "\n",
    "        # Construct dense layers on top of the last cell of the RNN\n",
    "        for units in dnn_layer_sizes:\n",
    "            last_activations = tf.layers.dense(\n",
    "              last_activations, units, activation=tf.nn.relu)\n",
    "        \n",
    "        # Final dense layer for prediction\n",
    "        predictions = tf.layers.dense(last_activations, label_dimension)\n",
    "        predictions_softmax = tf.nn.softmax(predictions)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss = None\n",
    "        train_op = None\n",
    "        \n",
    "        preds_op = {\n",
    "            'prediction': predictions_softmax,\n",
    "            'label': labels_onehot\n",
    "        }\n",
    "        \n",
    "        eval_op = {\n",
    "            \"accuracy\": tf.metrics.accuracy(\n",
    "                     tf.argmax(input=predictions_softmax, axis=1),\n",
    "                     tf.argmax(input=labels_onehot, axis=1))\n",
    "        }\n",
    "        \n",
    "        if mode != tf.contrib.learn.ModeKeys.INFER:    \n",
    "            loss = tf.losses.softmax_cross_entropy(labels_onehot, predictions)\n",
    "    \n",
    "        if mode == tf.contrib.learn.ModeKeys.TRAIN:    \n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "              loss,\n",
    "              tf.contrib.framework.get_global_step(),\n",
    "              optimizer=optimizer,\n",
    "              learning_rate=learning_rate)\n",
    "        \n",
    "        return tf.contrib.learn.ModelFnOps(mode,\n",
    "                                           predictions=predictions_softmax,\n",
    "                                           loss=loss,\n",
    "                                           train_op=train_op,\n",
    "                                           eval_metric_ops=eval_op)\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gUHR3Mzc7Tvb"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_model_fn() got an unexpected keyword argument 'embedding_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-dabed347b374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                         embedding_dim=[256])\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tensorboard/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_model_fn() got an unexpected keyword argument 'embedding_dim'"
     ]
    }
   ],
   "source": [
    "model_fn = get_model_fn(rnn_cell_sizes=[256, 128], # size of the hidden layers\n",
    "                        label_dimension=2, # since are just 2 classes\n",
    "                        dnn_layer_sizes=[128, 64], # size of units in the dense layers on top of the RNN\n",
    "                        optimizer='Adam',\n",
    "                        learning_rate=0.001,\n",
    "                        embedding_dim=[256])\n",
    "estimator = tf.contrib.learn.Estimator(model_fn=model_fn, model_dir='tensorboard/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "DUZEKQrdGgZE"
   },
   "outputs": [],
   "source": [
    "# create experiment\n",
    "def generate_experiment_fn():\n",
    "  \n",
    "  \"\"\"\n",
    "  Create an experiment function given hyperparameters.\n",
    "  Returns:\n",
    "    A function (output_dir) -> Experiment where output_dir is a string\n",
    "    representing the location of summaries, checkpoints, and exports.\n",
    "    this function is used by learn_runner to create an Experiment which\n",
    "    executes model code provided in the form of an Estimator and\n",
    "    input functions.\n",
    "    All listed arguments in the outer function are used to create an\n",
    "    Estimator, and input functions (training, evaluation, serving).\n",
    "    Unlisted args are passed through to Experiment.\n",
    "  \"\"\"\n",
    "\n",
    "  def _experiment_fn(output_dir):\n",
    "    return tf.contrib.learn.Experiment(\n",
    "        estimator,\n",
    "        train_input_fn=train_input_fn,\n",
    "        eval_input_fn=test_input_fn,\n",
    "        train_steps=STEPS\n",
    "    )\n",
    "  return _experiment_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:268: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From <ipython-input-52-82d13ba8809b>:19: string_to_index (from tensorflow.contrib.lookup.lookup_ops) is deprecated and will be removed after 2017-01-07.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to index_table_from_tensor and call the lookup method of the returned table.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving checkpoints for 1 into tensorboard/model.ckpt.\n",
      "WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n",
      "INFO:tensorflow:loss = 0.692785, step = 1\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING:tensorflow:From <ipython-input-52-82d13ba8809b>:19: string_to_index (from tensorflow.contrib.lookup.lookup_ops) is deprecated and will be removed after 2017-01-07.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to index_table_from_tensor and call the lookup method of the returned table.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-15-22:02:49\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-22:02:57\n",
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.662188, global_step = 1, loss = 0.68718\n",
      "INFO:tensorflow:Validation (step 1): loss = 0.68718, accuracy = 0.662188, global_step = 1\n",
      "INFO:tensorflow:global_step/sec: 3.22189\n",
      "INFO:tensorflow:loss = 0.426912, step = 101 (31.039 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into tensorboard/model.ckpt.\n",
      "WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n",
      "INFO:tensorflow:Loss for final step: 0.511911.\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING:tensorflow:From <ipython-input-52-82d13ba8809b>:19: string_to_index (from tensorflow.contrib.lookup.lookup_ops) is deprecated and will be removed after 2017-01-07.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to index_table_from_tensor and call the lookup method of the returned table.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-15-22:03:42\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/model.ckpt-200\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-22:03:50\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.779375, global_step = 200, loss = 0.479282\n",
      "WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.77937502, 'global_step': 200, 'loss': 0.47928202}, [])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run experiment \n",
    "learn_runner.run(generate_experiment_fn(), '/tmp/outputdir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-82d13ba8809b>:19: string_to_index (from tensorflow.contrib.lookup.lookup_ops) is deprecated and will be removed after 2017-01-07.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to index_table_from_tensor and call the lookup method of the returned table.\n",
      "INFO:tensorflow:Restoring parameters from tensorboard2/model.ckpt-1000\n",
      "\n",
      "sentence: this is a great movie\n",
      "bad review: 0.286051 good review: 0.713949\n",
      "----------\n",
      "sentence: this is a good movie but isnt the best\n",
      "bad review: 0.533478 good review: 0.466522\n",
      "----------\n",
      "sentence: this is a ok movie\n",
      "bad review: 0.781319 good review: 0.218681\n",
      "----------\n",
      "sentence: this movie sucks\n",
      "bad review: 0.970781 good review: 0.0292185\n",
      "----------\n",
      "sentence: this movie sucks but isnt the worst\n",
      "bad review: 0.993411 good review: 0.00658858\n",
      "----------\n",
      "sentence: its not that bad\n",
      "bad review: 0.887022 good review: 0.112978\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "preds = estimator.predict(input_fn=my_test_input_fn, as_iterable=True)\n",
    "\n",
    "sentences = _get_csv_column(MY_TEST_INPUT, 'review')\n",
    "\n",
    "print()\n",
    "for p, s in zip(preds, sentences):\n",
    "    print('sentence:', s)\n",
    "    print('bad review:', p[0], 'good review:', p[1])\n",
    "    print('-' * 10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "last_runtime": {
    "build_target": "//experimental/users/jamieas/transform_colab:notebook",
    "kind": "private"
   },
   "name": "Copy of CustomEstimator.ipynb",
   "provenance": [
    {
     "file_id": "0BwN-JPfIIHwgdFkwUTVIWTQwU00",
     "timestamp": 1496845355496
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
