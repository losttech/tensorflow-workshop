{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "mDT8S9C9CYtr"
   },
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Feeding function for enqueue data\n",
    "# \n",
    "from tensorflow.python.estimator.inputs.queues import feeding_functions as ff\n",
    "\n",
    "# Rnn common functions\n",
    "from tensorflow.contrib.learn.python.learn.estimators import rnn_common\n",
    "\n",
    "# Run an experiment\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "\n",
    "# Input function\n",
    "from tensorflow.python.estimator.inputs import numpy_io\n",
    "\n",
    "# Helpers for data processing\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UrAyWt23AtCM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 62701 words in the train and test files\n"
     ]
    }
   ],
   "source": [
    "# data from: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "TRAIN_INPUT = 'data/train.csv'\n",
    "TEST_INPUT = 'data/test.csv'\n",
    "\n",
    "# data manually generated\n",
    "MY_TEST_INPUT = 'data/mytest.csv'\n",
    "\n",
    "# Parameters for training\n",
    "STEPS = 5000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Parameters for data processing\n",
    "SEQUENCE_LENGTH_KEY = 'sequence_length'\n",
    "REVIEW_KEY = 'review'\n",
    "CLASSIFICATION_KEY = 'is_positive'\n",
    "\n",
    "# Vocabulary size\n",
    "VOCAB_FILE = 'data/vocab.txt'\n",
    "VOCAB = [line[:len(line)-1] for line in open(VOCAB_FILE)]\n",
    "VOCAB_SIZE = len(VOCAB) - 1\n",
    "\n",
    "print('there are %s words in the train and test files' % VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0dlZ9C27M-bS"
   },
   "outputs": [],
   "source": [
    "# This function creates a sparse tensor in the following way, given:\n",
    "# indices = [[0, 0], [1, 1], [2, 2]]\n",
    "# values = [1, 2, 3]\n",
    "# dense_shape = [3, 4]\n",
    "#\n",
    "# The output will be a sparse tensor that represents this dense tensor:\n",
    "# [ \n",
    "#   [1, 0, 0, 0]\n",
    "#   [0, 2, 0, 0]\n",
    "#   [0, 0, 3, 0]\n",
    "# ]\n",
    "#\n",
    "# We're using this to generate a Sparse tensor that can be easily\n",
    "# formated in a one hot representation.\n",
    "# More at: https://www.tensorflow.org/api_docs/python/tf/SparseTensor\n",
    "def _sparse_string_to_index(sp, mapping):\n",
    "    return tf.SparseTensor(indices=sp.indices,\n",
    "                           values=tf.contrib.lookup.string_to_index(sp.values,\n",
    "                                                                    mapping),\n",
    "                           dense_shape=sp.dense_shape)\n",
    "\n",
    "def array_to_onehot(array, num_dim=2):\n",
    "    array = np.asarray(array, dtype=np.int32)\n",
    "    onehot = np.zeros([array.shape[0], num_dim])\n",
    "    for i in range(array.shape[0]):\n",
    "        onehot[i][array[i]] = 1\n",
    "    return onehot\n",
    "\n",
    "# Returns the column values from a CSV file as a list\n",
    "def _get_csv_column(csv_file, column_name):\n",
    "    with open(csv_file, 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "        return df[column_name].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input function used for training and testing                                                \n",
    "def get_input_fn(csv_file, batch_size, epochs=1):\n",
    "    with open(csv_file, 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "        \n",
    "        def input_fn():\n",
    "            # Using queue with multiple threads to make it scalable\n",
    "            pandas_queue = ff._enqueue_data(df,\n",
    "                                            capacity=1024,\n",
    "                                            shuffle=True,\n",
    "                                            min_after_dequeue=256,\n",
    "                                            num_threads=4,\n",
    "                                            enqueue_size=16,\n",
    "                                            num_epochs=epochs)\n",
    "\n",
    "            _, review, classification, seq_len = pandas_queue.dequeue_up_to(batch_size)\n",
    "            \n",
    "            # Split sentences into words\n",
    "            split_review = tf.string_split(review, delimiter=' ')\n",
    "            # Creating a tf constant to hold the word -> index\n",
    "            # this is need to create the sparse tensor and after the one hot encode\n",
    "            mapping = tf.constant(VOCAB, name=\"mapping\")\n",
    "            \n",
    "            # Words represented in a sparse tensor\n",
    "            integerized_review = _sparse_string_to_index(split_review, mapping)\n",
    "\n",
    "            # Converting numbers to int 32\n",
    "            classification = tf.cast(classification, tf.int32)\n",
    "            seq_len = tf.cast(seq_len, tf.int32)\n",
    "            \n",
    "            # Generates batcheds\n",
    "            batched = tf.train.shuffle_batch({REVIEW_KEY: integerized_review,\n",
    "                                              SEQUENCE_LENGTH_KEY: seq_len,\n",
    "                                              CLASSIFICATION_KEY: classification},\n",
    "                                             batch_size,\n",
    "                                             min_after_dequeue=100,\n",
    "                                             num_threads=4,\n",
    "                                             capacity=1000,\n",
    "                                             enqueue_many=True,\n",
    "                                             allow_smaller_final_batch=True)\n",
    "            \n",
    "            label = batched.pop(CLASSIFICATION_KEY)\n",
    "            label_onehot = tf.one_hot(label, 2)\n",
    "            return batched, label_onehot\n",
    "    return input_fn\n",
    "\n",
    "# Creating my own input function for a custom CSV file\n",
    "# it's simpler than the input_fn above but just used for small tests\n",
    "def get_my_input_fn():\n",
    "    def _input_fn():\n",
    "        with open(MY_TEST_INPUT, 'r') as f:\n",
    "            df = pd.read_csv(f)\n",
    "\n",
    "            review = df.review.tolist()\n",
    "\n",
    "            # Split sentences into words\n",
    "            split_review = tf.string_split(review, delimiter=' ')\n",
    "            # Creating a tf constant to hold the word -> index\n",
    "            # this is need to create the sparse tensor and after the one hot encode\n",
    "            mapping = tf.constant(VOCAB, name=\"mapping\")\n",
    "            \n",
    "            # Words represented in a sparse tensor\n",
    "            integerized_review = _sparse_string_to_index(split_review, mapping)\n",
    "            \n",
    "            x = {REVIEW_KEY: integerized_review, SEQUENCE_LENGTH_KEY: df.sequence_length.tolist()}\n",
    "\n",
    "            y = df.is_positive.tolist()\n",
    "\n",
    "            return x, y\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "m5UJyvW5P0Sy"
   },
   "outputs": [],
   "source": [
    "train_input_fn = get_input_fn(TRAIN_INPUT, BATCH_SIZE, None)\n",
    "test_input_fn = get_input_fn(TEST_INPUT, BATCH_SIZE)\n",
    "my_test_input_fn = get_my_input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lE4c3ELMQjHJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-52-82d13ba8809b>:19: string_to_index (from tensorflow.contrib.lookup.lookup_ops) is deprecated and will be removed after 2017-01-07.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to index_table_from_tensor and call the lookup method of the returned table.\n",
      "({'sequence_length': array([80, 80, 80, 80, 80, 80, 80, 80, 71, 80, 80, 80, 80, 80, 80, 80, 80,\n",
      "       80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
      "       80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
      "       80, 80, 58, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80], dtype=int32), 'review': SparseTensorValue(indices=array([[ 0,  0],\n",
      "       [ 0,  1],\n",
      "       [ 0,  2],\n",
      "       ..., \n",
      "       [63, 77],\n",
      "       [63, 78],\n",
      "       [63, 79]]), values=array([  37, 1527,   10, ..., 1909,   91,   91]), dense_shape=array([64, 80]))}, array([[ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 1.,  0.],\n",
      "       [ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [ 0.,  1.]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing the input function\n",
    "with tf.Graph().as_default():\n",
    "    train_input = train_input_fn()\n",
    "    with tf.train.MonitoredSession() as sess:\n",
    "        #print (train_input)\n",
    "        print (sess.run(train_input))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Estimator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "VxXAUrYN7TvR"
   },
   "outputs": [],
   "source": [
    "def get_model_fn(rnn_cell_sizes,\n",
    "                 label_dimension,\n",
    "                 dnn_layer_sizes=[],\n",
    "                 optimizer='SGD',\n",
    "                 learning_rate=0.01,\n",
    "                 embed_dim=128):\n",
    "    \n",
    "    def model_fn(features, labels, mode):\n",
    "        \n",
    "        review = features[REVIEW_KEY]\n",
    "        sequence_length = tf.cast(features[SEQUENCE_LENGTH_KEY], tf.int32)\n",
    "        labels_onehot = labels\n",
    "        \n",
    "        # Creating dense representation for the sentences\n",
    "        # and then converting it to embeding representation\n",
    "        dense_review = tf.sparse_tensor_to_dense(review, default_value=VOCAB_SIZE)\n",
    "        embed_review = tf.contrib.layers.embed_sequence(dense_review,\n",
    "                                                        vocab_size=VOCAB_SIZE,\n",
    "                                                        embed_dim=embed_dim)\n",
    "        \n",
    "        \n",
    "        # Each RNN layer will consist of a LSTM cell\n",
    "        rnn_layers = [tf.contrib.rnn.LSTMCell(size) for size in rnn_cell_sizes]\n",
    "        \n",
    "        # Construct the layers\n",
    "        multi_rnn_cell = tf.contrib.rnn.MultiRNNCell(rnn_layers)\n",
    "        \n",
    "        # Runs the RNN model dynamically\n",
    "        # more about it at: \n",
    "        # https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
    "                                                 inputs=embed_review,\n",
    "                                                 sequence_length=sequence_length,\n",
    "                                                 dtype=tf.float32)\n",
    "\n",
    "        # Slice to keep only the last cell of the RNN\n",
    "        last_activations = rnn_common.select_last_activations(outputs,\n",
    "                                                              sequence_length)\n",
    "\n",
    "        # Construct dense layers on top of the last cell of the RNN\n",
    "        for units in dnn_layer_sizes:\n",
    "            last_activations = tf.layers.dense(\n",
    "              last_activations, units, activation=tf.nn.relu)\n",
    "        \n",
    "        # Final dense layer for prediction\n",
    "        predictions = tf.layers.dense(last_activations, label_dimension)\n",
    "        predictions_softmax = tf.nn.softmax(predictions)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss = None\n",
    "        train_op = None\n",
    "        \n",
    "        preds_op = {\n",
    "            'prediction': predictions_softmax,\n",
    "            'label': labels_onehot\n",
    "        }\n",
    "        \n",
    "        eval_op = {\n",
    "            \"accuracy\": tf.metrics.accuracy(\n",
    "                     tf.argmax(input=predictions_softmax, axis=1),\n",
    "                     tf.argmax(input=labels_onehot, axis=1))\n",
    "        }\n",
    "        \n",
    "        if mode != tf.contrib.learn.ModeKeys.INFER:    \n",
    "            loss = tf.losses.softmax_cross_entropy(labels_onehot, predictions)\n",
    "    \n",
    "        if mode == tf.contrib.learn.ModeKeys.TRAIN:    \n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "              loss,\n",
    "              tf.contrib.framework.get_global_step(),\n",
    "              optimizer=optimizer,\n",
    "              learning_rate=learning_rate)\n",
    "        \n",
    "        return tf.contrib.learn.ModelFnOps(mode,\n",
    "                                           predictions=predictions_softmax,\n",
    "                                           loss=loss,\n",
    "                                           train_op=train_op,\n",
    "                                           eval_metric_ops=eval_op)\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gUHR3Mzc7Tvb"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_model_fn() got an unexpected keyword argument 'embedding_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-dabed347b374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                         embedding_dim=[256])\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tensorboard/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_model_fn() got an unexpected keyword argument 'embedding_dim'"
     ]
    }
   ],
   "source": [
    "model_fn = get_model_fn(rnn_cell_sizes=[256, 128], # size of the hidden layers\n",
    "                        label_dimension=2, # since are just 2 classes\n",
    "                        dnn_layer_sizes=[128, 64], # size of units in the dense layers on top of the RNN\n",
    "                        optimizer='Adam',\n",
    "                        learning_rate=0.001,\n",
    "                        embedding_dim=[256])\n",
    "estimator = tf.contrib.learn.Estimator(model_fn=model_fn, model_dir='tensorboard/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "DUZEKQrdGgZE"
   },
   "outputs": [],
   "source": [
    "# create experiment\n",
    "def generate_experiment_fn():\n",
    "  \n",
    "  \"\"\"\n",
    "  Create an experiment function given hyperparameters.\n",
    "  Returns:\n",
    "    A function (output_dir) -> Experiment where output_dir is a string\n",
    "    representing the location of summaries, checkpoints, and exports.\n",
    "    this function is used by learn_runner to create an Experiment which\n",
    "    executes model code provided in the form of an Estimator and\n",
    "    input functions.\n",
    "    All listed arguments in the outer function are used to create an\n",
    "    Estimator, and input functions (training, evaluation, serving).\n",
    "    Unlisted args are passed through to Experiment.\n",
    "  \"\"\"\n",
    "\n",
    "  def _experiment_fn(output_dir):\n",
    "    return tf.contrib.learn.Experiment(\n",
    "        estimator,\n",
    "        train_input_fn=train_input_fn,\n",
    "        eval_input_fn=test_input_fn,\n",
    "        train_steps=STEPS\n",
    "    )\n",
    "  return _experiment_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:268: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From <ipython-input-52-82d13ba8809b>:19: string_to_index (from tensorflow.contrib.lookup.lookup_ops) is deprecated and will be removed after 2017-01-07.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to index_table_from_tensor and call the lookup method of the returned table.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/model.ckpt-200\n",
      "WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving checkpoints for 201 into tensorboard/model.ckpt.\n",
      "WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n",
      "INFO:tensorflow:loss = 0.247897, step = 201\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING:tensorflow:From <ipython-input-52-82d13ba8809b>:19: string_to_index (from tensorflow.contrib.lookup.lookup_ops) is deprecated and will be removed after 2017-01-07.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to index_table_from_tensor and call the lookup method of the returned table.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-15-22:05:38\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/model.ckpt-201\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-22:05:46\n",
      "INFO:tensorflow:Saving dict for global step 201: accuracy = 0.787812, global_step = 201, loss = 0.460524\n",
      "INFO:tensorflow:Validation (step 201): loss = 0.460524, accuracy = 0.787812, global_step = 201\n",
      "INFO:tensorflow:global_step/sec: 3.16427\n",
      "INFO:tensorflow:loss = 0.208706, step = 301 (31.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.37072\n",
      "INFO:tensorflow:loss = 0.421901, step = 401 (22.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4588\n",
      "INFO:tensorflow:loss = 0.281606, step = 501 (22.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45203\n",
      "INFO:tensorflow:loss = 0.189271, step = 601 (22.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.56207\n",
      "INFO:tensorflow:loss = 0.122213, step = 701 (21.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.55802\n",
      "INFO:tensorflow:loss = 0.109293, step = 801 (21.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.57078\n",
      "INFO:tensorflow:loss = 0.0779261, step = 901 (21.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.58279\n",
      "INFO:tensorflow:loss = 0.196289, step = 1001 (21.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.54119\n",
      "INFO:tensorflow:loss = 0.277374, step = 1101 (22.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.55139\n",
      "INFO:tensorflow:loss = 0.114073, step = 1201 (21.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5551\n",
      "INFO:tensorflow:loss = 0.128765, step = 1301 (21.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.57568\n",
      "INFO:tensorflow:loss = 0.0662823, step = 1401 (21.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.58404\n",
      "INFO:tensorflow:loss = 0.00377776, step = 1501 (21.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.57288\n",
      "INFO:tensorflow:loss = 0.113809, step = 1601 (21.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.58066\n",
      "INFO:tensorflow:loss = 0.191873, step = 1701 (21.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.57146\n",
      "INFO:tensorflow:loss = 0.0320345, step = 1801 (21.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.56888\n",
      "INFO:tensorflow:loss = 0.109742, step = 1901 (21.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49145\n",
      "INFO:tensorflow:loss = 0.0163917, step = 2001 (22.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50205\n",
      "INFO:tensorflow:loss = 0.0707042, step = 2101 (22.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47625\n",
      "INFO:tensorflow:loss = 0.00893635, step = 2201 (22.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45056\n",
      "INFO:tensorflow:loss = 0.00801308, step = 2301 (22.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43068\n",
      "INFO:tensorflow:loss = 0.0125416, step = 2401 (22.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50705\n",
      "INFO:tensorflow:loss = 0.00628485, step = 2501 (22.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51915\n",
      "INFO:tensorflow:loss = 0.107391, step = 2601 (22.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.42761\n",
      "INFO:tensorflow:loss = 0.00865931, step = 2701 (22.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34014\n",
      "INFO:tensorflow:loss = 0.0112387, step = 2801 (23.041 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2862 into tensorboard/model.ckpt.\n",
      "WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING:tensorflow:From <ipython-input-52-82d13ba8809b>:19: string_to_index (from tensorflow.contrib.lookup.lookup_ops) is deprecated and will be removed after 2017-01-07.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to index_table_from_tensor and call the lookup method of the returned table.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-15-22:15:38\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/model.ckpt-2862\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-22:15:46\n",
      "INFO:tensorflow:Saving dict for global step 2862: accuracy = 0.713906, global_step = 2862, loss = 1.32544\n",
      "INFO:tensorflow:Validation (step 2862): loss = 1.32544, accuracy = 0.713906, global_step = 2862\n",
      "INFO:tensorflow:global_step/sec: 3.21197\n",
      "INFO:tensorflow:loss = 0.00243095, step = 2901 (31.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50053\n",
      "INFO:tensorflow:loss = 0.00827473, step = 3001 (22.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.41919\n",
      "INFO:tensorflow:loss = 0.000371278, step = 3101 (22.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4262\n",
      "INFO:tensorflow:loss = 0.0421663, step = 3201 (22.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50794\n",
      "INFO:tensorflow:loss = 0.00540271, step = 3301 (22.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4192\n",
      "INFO:tensorflow:loss = 0.0793265, step = 3401 (22.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50405\n",
      "INFO:tensorflow:loss = 0.0598924, step = 3501 (22.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49734\n",
      "INFO:tensorflow:loss = 0.00148575, step = 3601 (22.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.25447\n",
      "INFO:tensorflow:loss = 0.0456021, step = 3701 (23.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44854\n",
      "INFO:tensorflow:loss = 0.0226605, step = 3801 (22.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.41286\n",
      "INFO:tensorflow:loss = 3.1348e-06, step = 3901 (22.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29291\n",
      "INFO:tensorflow:loss = 0.0224636, step = 4001 (23.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52766\n",
      "INFO:tensorflow:loss = 0.0152915, step = 4101 (22.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47509\n",
      "INFO:tensorflow:loss = 0.0397582, step = 4201 (22.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.41422\n",
      "INFO:tensorflow:loss = 0.00179347, step = 4301 (22.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34546\n",
      "INFO:tensorflow:loss = 0.0139394, step = 4401 (23.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4581\n",
      "INFO:tensorflow:loss = 0.0238139, step = 4501 (22.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.40016\n",
      "INFO:tensorflow:loss = 0.000200202, step = 4601 (22.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.38714\n",
      "INFO:tensorflow:loss = 0.000499818, step = 4701 (22.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44993\n",
      "INFO:tensorflow:loss = 0.0724267, step = 4801 (22.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.41203\n",
      "INFO:tensorflow:loss = 0.00123003, step = 4901 (22.665 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into tensorboard/model.ckpt.\n",
      "WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n",
      "INFO:tensorflow:Loss for final step: 0.00704398.\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING:tensorflow:From <ipython-input-52-82d13ba8809b>:19: string_to_index (from tensorflow.contrib.lookup.lookup_ops) is deprecated and will be removed after 2017-01-07.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to index_table_from_tensor and call the lookup method of the returned table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-06-15-22:23:49\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-22:23:57\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.74625, global_step = 5000, loss = 1.50571\n",
      "WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.74624997, 'global_step': 5000, 'loss': 1.5057149}, [])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run experiment \n",
    "learn_runner.run(generate_experiment_fn(), '/tmp/outputdir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-52-82d13ba8809b>:19: string_to_index (from tensorflow.contrib.lookup.lookup_ops) is deprecated and will be removed after 2017-01-07.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to index_table_from_tensor and call the lookup method of the returned table.\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/model.ckpt-5000\n",
      "\n",
      "sentence: this is a great movie\n",
      "bad review: 0.0516589 good review: 0.948341\n",
      "----------\n",
      "sentence: this is a good movie but isnt the best\n",
      "bad review: 0.643403 good review: 0.356597\n",
      "----------\n",
      "sentence: this is a ok movie\n",
      "bad review: 0.897275 good review: 0.102725\n",
      "----------\n",
      "sentence: this movie sucks\n",
      "bad review: 0.999967 good review: 3.27559e-05\n",
      "----------\n",
      "sentence: this movie sucks but isnt the worst\n",
      "bad review: 0.999969 good review: 3.08964e-05\n",
      "----------\n",
      "sentence: its not that bad\n",
      "bad review: 0.938954 good review: 0.0610457\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "preds = estimator.predict(input_fn=my_test_input_fn, as_iterable=True)\n",
    "\n",
    "sentences = _get_csv_column(MY_TEST_INPUT, 'review')\n",
    "\n",
    "print()\n",
    "for p, s in zip(preds, sentences):\n",
    "    print('sentence:', s)\n",
    "    print('bad review:', p[0], 'good review:', p[1])\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "last_runtime": {
    "build_target": "//experimental/users/jamieas/transform_colab:notebook",
    "kind": "private"
   },
   "name": "Copy of CustomEstimator.ipynb",
   "provenance": [
    {
     "file_id": "0BwN-JPfIIHwgdFkwUTVIWTQwU00",
     "timestamp": 1496845355496
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
