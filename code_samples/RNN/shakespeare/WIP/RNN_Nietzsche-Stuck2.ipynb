{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/extend/estimators\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "import tensorflow.contrib.layers as tflayers\n",
    "\n",
    "# keras\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dense, LSTM, GRU, Activation\n",
    "from tensorflow.contrib.keras.python.keras.utils.data_utils import get_file\n",
    "\n",
    "# input data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# estimators\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "# estimator \"builder\"\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "# helpers\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# enable logs\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    #print(preds)\n",
    "    return np.argmax(preds)\n",
    "\n",
    "# THE MODEL\n",
    "def model_fn(features, targets, mode, params):\n",
    "    \"\"\"Model function for Estimator.\"\"\"\n",
    "    \n",
    "    # 1. Configure the model via TensorFlow operations\n",
    "    # First, build all the model, a good idea is using Keras or tf.layers\n",
    "    # since these are high-level API's\n",
    "    #lstm = GRU(128, input_shape=(params[\"maxlen\"], params[\"vocab_size\"]))(features)\n",
    "    #preds = Dense(params[\"vocab_size\"], activation='sigmoid')(lstm)\n",
    "    \n",
    "    # 0. Reformat input shape to become a sequence\n",
    "    lstm1 = GRU(128, input_shape=(params[\"maxlen\"], params[\"vocab_size\"]),\n",
    "                return_sequences=False)(features)\n",
    "    #lstm2 = GRU(128)(lstm1)\n",
    "    preds = Dense(params[\"vocab_size\"])(lstm1)\n",
    "    preds_softmax = Activation(\"softmax\")(preds)\n",
    "\n",
    "    # 2. Define the loss function for training/evaluation\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    \n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    if mode != learn.ModeKeys.INFER:\n",
    "        loss = tf.losses.softmax_cross_entropy(\n",
    "            onehot_labels=targets, logits=preds)\n",
    "\n",
    "    # 3. Define the training operation/optimizer\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == learn.ModeKeys.TRAIN:\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            optimizer=\"RMSProp\",\n",
    "        )\n",
    "\n",
    "    # 4. Generate predictions\n",
    "    predictions_dict = {\n",
    "      \"preds\": preds_softmax\n",
    "    }\n",
    "    \n",
    "    # 5. Define how you want to evaluate the model\n",
    "    metrics = {\n",
    "        \"accuracy\": tf.metrics.accuracy(tf.argmax(input=preds_softmax, axis=1), tf.argmax(input=targets, axis=1))\n",
    "    }\n",
    "    \n",
    "    # 6. Return predictions/loss/train_op/eval_metric_ops in ModelFnOps object\n",
    "    return model_fn_lib.ModelFnOps(\n",
    "      mode=mode,\n",
    "      predictions=predictions_dict,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data\n",
      "corpus length: 1115394\n",
      "total chars: 39\n",
      "nb sequences: 1115354\n",
      "Vectorization...\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Getting data')\n",
    "\n",
    "#path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "path = 'shakespeare.txt'\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 1\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.float32)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.float32)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_id': 0, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f48cb050c88>, '_keep_checkpoint_max': 5, '_evaluation_master': '', '_tf_random_seed': None, '_is_chief': True, '_num_ps_replicas': 0, '_environment': 'local', '_model_dir': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_save_summary_steps': 100, '_task_type': None, '_save_checkpoints_steps': None}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpsnevr3y3\n",
      "----------------------------------------\n",
      "Training\n",
      "----------------------------------------\n",
      "WARNING:tensorflow:From <ipython-input-7-0de7a2223bd3>:19: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-7-0de7a2223bd3>:19: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-7-0de7a2223bd3>:19: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/tensorflow/python/util/deprecation.py:248: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  equality = a == b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpsnevr3y3/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.64558, step = 1\n",
      "INFO:tensorflow:global_step/sec: 26.5339\n",
      "INFO:tensorflow:loss = 4.03005, step = 101 (3.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2854\n",
      "INFO:tensorflow:loss = 2.77961, step = 201 (3.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7679\n",
      "INFO:tensorflow:loss = 3.10089, step = 301 (3.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8403\n",
      "INFO:tensorflow:loss = 5.49769, step = 401 (3.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7837\n",
      "INFO:tensorflow:loss = 3.52534, step = 501 (3.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8704\n",
      "INFO:tensorflow:loss = 1.59166, step = 601 (3.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.789\n",
      "INFO:tensorflow:loss = 6.09143, step = 701 (3.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8786\n",
      "INFO:tensorflow:loss = 2.4158, step = 801 (3.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3595\n",
      "INFO:tensorflow:loss = 2.93907, step = 901 (3.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0323\n",
      "INFO:tensorflow:loss = 3.851, step = 1001 (3.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8611\n",
      "INFO:tensorflow:loss = 0.611839, step = 1101 (3.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.357\n",
      "INFO:tensorflow:loss = 2.95856, step = 1201 (3.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8971\n",
      "INFO:tensorflow:loss = 4.17606, step = 1301 (3.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2152\n",
      "INFO:tensorflow:loss = 4.62098, step = 1401 (3.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8972\n",
      "INFO:tensorflow:loss = 12.109, step = 1501 (3.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8362\n",
      "INFO:tensorflow:loss = 0.856251, step = 1601 (3.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6669\n",
      "INFO:tensorflow:loss = 5.55303, step = 1701 (3.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8359\n",
      "INFO:tensorflow:loss = 4.22769, step = 1801 (3.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.104\n",
      "INFO:tensorflow:loss = 1.79838, step = 1901 (3.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9153\n",
      "INFO:tensorflow:loss = 5.30141, step = 2001 (3.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4383\n",
      "INFO:tensorflow:loss = 1.5258, step = 2101 (3.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4042\n",
      "INFO:tensorflow:loss = 4.01015, step = 2201 (3.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4098\n",
      "INFO:tensorflow:loss = 5.74606, step = 2301 (3.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6994\n",
      "INFO:tensorflow:loss = 1.68145, step = 2401 (3.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3696\n",
      "INFO:tensorflow:loss = 4.82453, step = 2501 (3.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8929\n",
      "INFO:tensorflow:loss = 3.43846, step = 2601 (3.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4665\n",
      "INFO:tensorflow:loss = 2.55553, step = 2701 (3.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4363\n",
      "INFO:tensorflow:loss = 3.86818, step = 2801 (3.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1478\n",
      "INFO:tensorflow:loss = 5.41699, step = 2901 (3.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7145\n",
      "INFO:tensorflow:loss = 4.83035, step = 3001 (3.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5017\n",
      "INFO:tensorflow:loss = 8.22265, step = 3101 (3.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3713\n",
      "INFO:tensorflow:loss = 2.39176, step = 3201 (3.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5985\n",
      "INFO:tensorflow:loss = 2.68953, step = 3301 (3.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2421\n",
      "INFO:tensorflow:loss = 2.22034, step = 3401 (3.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5815\n",
      "INFO:tensorflow:loss = 3.14892, step = 3501 (3.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.143\n",
      "INFO:tensorflow:loss = 13.8441, step = 3601 (3.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5162\n",
      "INFO:tensorflow:loss = 3.48399, step = 3701 (3.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8807\n",
      "INFO:tensorflow:loss = 4.41308, step = 3801 (3.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7331\n",
      "INFO:tensorflow:loss = 2.75933, step = 3901 (3.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0074\n",
      "INFO:tensorflow:loss = 4.71359, step = 4001 (3.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1761\n",
      "INFO:tensorflow:loss = 6.20922, step = 4101 (3.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7613\n",
      "INFO:tensorflow:loss = 7.42886, step = 4201 (3.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8759\n",
      "INFO:tensorflow:loss = 5.37514, step = 4301 (3.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5513\n",
      "INFO:tensorflow:loss = 13.9273, step = 4401 (3.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1532\n",
      "INFO:tensorflow:loss = 6.04067, step = 4501 (3.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0404\n",
      "INFO:tensorflow:loss = 4.4146, step = 4601 (3.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3456\n",
      "INFO:tensorflow:loss = 5.5622, step = 4701 (3.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5725\n",
      "INFO:tensorflow:loss = 2.1977, step = 4801 (3.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4702\n",
      "INFO:tensorflow:loss = 3.58606, step = 4901 (3.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6982\n",
      "INFO:tensorflow:loss = 15.4288, step = 5001 (3.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7548\n",
      "INFO:tensorflow:loss = 4.57986, step = 5101 (3.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7088\n",
      "INFO:tensorflow:loss = 6.03905, step = 5201 (3.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1871\n",
      "INFO:tensorflow:loss = 0.596038, step = 5301 (3.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6075\n",
      "INFO:tensorflow:loss = 3.52885, step = 5401 (3.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6366\n",
      "INFO:tensorflow:loss = 0.497641, step = 5501 (3.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.6364\n",
      "INFO:tensorflow:loss = 2.15703, step = 5601 (3.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2636\n",
      "INFO:tensorflow:loss = 1.25765, step = 5701 (3.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6137\n",
      "INFO:tensorflow:loss = 10.8849, step = 5801 (3.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5661\n",
      "INFO:tensorflow:loss = 0.991155, step = 5901 (3.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.329\n",
      "INFO:tensorflow:loss = 2.25538, step = 6001 (3.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.654\n",
      "INFO:tensorflow:loss = 2.80958, step = 6101 (3.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.0092\n",
      "INFO:tensorflow:loss = 4.61165, step = 6201 (3.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.2773\n",
      "INFO:tensorflow:loss = 1.52782, step = 6301 (3.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5083\n",
      "INFO:tensorflow:loss = 4.04971, step = 6401 (3.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2241\n",
      "INFO:tensorflow:loss = 4.33619, step = 6501 (3.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4841\n",
      "INFO:tensorflow:loss = 1.95557, step = 6601 (3.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4218\n",
      "INFO:tensorflow:loss = 2.56419, step = 6701 (3.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.261\n",
      "INFO:tensorflow:loss = 1.37078, step = 6801 (3.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.3693\n",
      "INFO:tensorflow:loss = 4.31274, step = 6901 (3.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7096\n",
      "INFO:tensorflow:loss = 2.8041, step = 7001 (3.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5311\n",
      "INFO:tensorflow:loss = 4.65558, step = 7101 (3.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.1243\n",
      "INFO:tensorflow:loss = 3.10305, step = 7201 (3.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8737\n",
      "INFO:tensorflow:loss = 2.63041, step = 7301 (3.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.6751\n",
      "INFO:tensorflow:loss = 1.30979, step = 7401 (3.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8262\n",
      "INFO:tensorflow:loss = 4.16254, step = 7501 (3.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.2222\n",
      "INFO:tensorflow:loss = 2.52677, step = 7601 (3.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4587\n",
      "INFO:tensorflow:loss = 5.07622, step = 7701 (3.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6201\n",
      "INFO:tensorflow:loss = 7.21718, step = 7801 (3.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1965\n",
      "INFO:tensorflow:loss = 3.01447, step = 7901 (3.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8171\n",
      "INFO:tensorflow:loss = 2.93606, step = 8001 (3.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.305\n",
      "INFO:tensorflow:loss = 3.60068, step = 8101 (3.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6941\n",
      "INFO:tensorflow:loss = 1.13325, step = 8201 (3.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7305\n",
      "INFO:tensorflow:loss = 3.15776, step = 8301 (3.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.88607, step = 8401 (3.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2645\n",
      "INFO:tensorflow:loss = 3.29669, step = 8501 (3.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0021\n",
      "INFO:tensorflow:loss = 2.18847, step = 8601 (3.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7854\n",
      "INFO:tensorflow:loss = 3.34612, step = 8701 (3.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8074\n",
      "INFO:tensorflow:loss = 1.53164, step = 8801 (3.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6641\n",
      "INFO:tensorflow:loss = 6.73189, step = 8901 (3.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6922\n",
      "INFO:tensorflow:loss = 1.76937, step = 9001 (3.751 sec)\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 1\n",
    "STEPS = len(sentences)\n",
    "\n",
    "NUM_OUTPUTS_PRED = 500 # Number of test characters of text to generate after training the network\n",
    "\n",
    "# Set model params\n",
    "model_params = {\"learning_rate\": LEARNING_RATE, \"vocab_size\": len(chars), \"maxlen\": maxlen}\n",
    "\n",
    "# Instantiate Estimator\n",
    "nn = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params)\n",
    "\n",
    "# Score accuracy\n",
    "# Fit\n",
    "print('-' * 40)\n",
    "print(\"Training\")\n",
    "print('-' * 40)\n",
    "nn.fit(x=X, y=y, steps=STEPS, batch_size=BATCH_SIZE)\n",
    "\n",
    "# choose a random sentence\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "sentence = text[start_index: start_index + maxlen]\n",
    "\n",
    "# generate output using the RNN model\n",
    "original_sentence = sentence\n",
    "generated = sentence\n",
    "for i in range(NUM_OUTPUTS_PRED):\n",
    "    x = np.zeros((1, maxlen, len(chars)), dtype=np.float32)\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    p = None\n",
    "    for e in nn.predict(x):\n",
    "        if p is None: p = e[\"preds\"]\n",
    "    next_index = sample(p)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "print('\\n' * 10, '-' * 100)\n",
    "print('HERE')\n",
    "print(generated)\n",
    "print(original_sentence)\n",
    "print('-' * 100, '\\n' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
