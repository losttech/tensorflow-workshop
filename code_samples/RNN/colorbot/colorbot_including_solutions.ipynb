{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorbot\n",
    "\n",
    "**Special thanks to @MarkDaoust that helped us with this material**\n",
    "\n",
    "In order to have a better experience follow these steps:\n",
    "\n",
    "1. Just read all the notebook, try to understand what each part of the code is doing and get familiar with the implementation.\n",
    "2. For each exercise in this notebook make a copy of this notebook and try to implement what is expected. We suggest the following order for the exercises: HYPERPARAMETERS, EXPERIMENT, DATASET\n",
    "3. Troubles or doubts about the code/exercises? Ask the instructor about it or check colorbot_solutions.ipnyb for a possible implementation/instruction if available\n",
    "\n",
    "## Content of this notebook\n",
    "\n",
    "In this notebook you'll find a full implementation of a RNN model using the TensorFlow Estimators including comments and details about how to do it. \n",
    "\n",
    "Once you finish this notebook, you'll have a better understanding of:\n",
    "  * [TensorFlow Estimators](https://www.tensorflow.org/extend/estimators)\n",
    "  * [TensorFlow DataSets](https://github.com/tensorflow/tensorflow/tree/r1.2/tensorflow/contrib/data)\n",
    "  * [RNNs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "\n",
    "\n",
    "## What is colorbot?\n",
    "\n",
    "Colorbot is a RNN model that receives a word (sequence of characters) as input and learns to predict a rgb value that better represents this word. As a result we have a color generator!\n",
    "\n",
    "![colorbot in action](imgs/model_gif.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mDT8S9C9CYtr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested with TensorFlow 1.2.0\n",
      "Your TensorFlow version: 1.2.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "print('Tested with TensorFlow 1.2.0')\n",
    "print('Your TensorFlow version:', tf.__version__) \n",
    "\n",
    "# Feeding function for enqueue data\n",
    "from tensorflow.python.estimator.inputs.queues import feeding_functions as ff\n",
    "\n",
    "# Rnn common functions\n",
    "from tensorflow.contrib.learn.python.learn.estimators import rnn_common\n",
    "\n",
    "# Run an experiment\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "\n",
    "# Model builder\n",
    "from tensorflow.python.estimator import model_fn as model_fn_lib\n",
    "\n",
    "# Plot images with pyplot\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Helpers for data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UrAyWt23AtCM"
   },
   "outputs": [],
   "source": [
    "# Data files\n",
    "TRAIN_INPUT = 'data/train.csv'\n",
    "TEST_INPUT = 'data/test.csv'\n",
    "MY_TEST_INPUT = 'data/mytest.csv'\n",
    "\n",
    "# Parameters for training\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Parameters for data processing\n",
    "VOCAB_SIZE = 256\n",
    "CHARACTERS = [chr(i) for i in range(VOCAB_SIZE)]\n",
    "SEQUENCE_LENGTH_KEY = 'sequence_length'\n",
    "COLOR_NAME_KEY = 'color_name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0dlZ9C27M-bS"
   },
   "outputs": [],
   "source": [
    "# Returns the column values from a CSV file as a list\n",
    "def _get_csv_column(csv_file, column_name):\n",
    "    with open(csv_file, 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "        return df[column_name].tolist()\n",
    "\n",
    "# Plots a color image\n",
    "def _plot_rgb(rgb):\n",
    "    data = [[rgb]]\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(data, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input function\n",
    "\n",
    "Here we are defining the input pipeline using the [Dataset API](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data).\n",
    "\n",
    "One special operation that we're doing is called **group_by_window**, what this function does is to map each consecutive element in this dataset to a key using `key_func` and then groups the elements by key. It then applies `reduce_func` to at most `window_size` elements matching the same key. All except the final window for each key will contain `window_size` elements; the final window may be smaller.\n",
    "\n",
    "In the code below what we're doing is using the group_by_window to batch color names that have similar length together, this makes the code more efficient since the RNN will be unfolded (approximately) the same number of steps in each batch.\n",
    "\n",
    "![](imgs/batch_by_length.png)\n",
    "*Image from [Sequence Models and the RNN API (TensorFlow Dev Summit 2017)](https://www.youtube.com/watch?v=RIR_-Xlbp7s)*\n",
    "\n",
    "** *EXERCISE DATASET (first complete the EXERCISE EXPERIMENT: change the input function bellow so it will just use normal padded_batch instead sorting the batches. Then run each model using experiments and compare the efficiency (time, global_step/sec) using TensorBoard.\n",
    "hint: to compare the implementations using tensorboard just copy the model_dir folder of both executions to the same directory (the model dir should be different at each time you run the model) and point tensorboard to it with: tensorboard --logdir=path_to_model_dirs_par)* **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_fn(csv_file, batch_size, num_epochs=1, shuffle=True):\n",
    "    def _parse(line):\n",
    "        # each line: name, red, green, blue\n",
    "        # split line\n",
    "        items = tf.string_split([line],',').values\n",
    "\n",
    "        # get color (r, g, b)\n",
    "        color = tf.string_to_number(items[1:], out_type=tf.float32) / 255.0\n",
    "\n",
    "        # split color_name into a sequence of characters\n",
    "        color_name = tf.string_split([items[0]], '')\n",
    "        length = color_name.indices[-1, 1] + 1 # length = index of last char + 1\n",
    "        color_name = color_name.values\n",
    "        \n",
    "        return color, color_name, length\n",
    "\n",
    "    def _length_bin(length, cast_value=5, max_bin_id=10):\n",
    "        '''\n",
    "        Chooses a bin for a word given it's length.\n",
    "        The goal is to use group_by_window to group words\n",
    "        with the ~ same ~ length in the same bin.\n",
    "\n",
    "        Each bin will have the size of a batch, so it can train faster.\n",
    "        '''\n",
    "        bin_id = tf.cast(length / cast_value, dtype=tf.int64)\n",
    "        return tf.minimum(bin_id, max_bin_id)\n",
    "\n",
    "    def _pad_batch(ds, batch_size):\n",
    "        return ds.padded_batch(batch_size, \n",
    "                               padded_shapes=([None], [None], []),\n",
    "                               padding_values=(0.0, chr(0), tf.cast(0, tf.int64)))\n",
    "\n",
    "    def input_fn():\n",
    "        # https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data\n",
    "        dataset = (\n",
    "            tf.contrib.data.TextLineDataset(csv_file) # reading from the HD\n",
    "            .skip(1) # skip header\n",
    "            .repeat(num_epochs) # repeat dataset the number of epochs\n",
    "            .map(_parse) # parse text to variables\n",
    "            .group_by_window(key_func=lambda color, color_name, length: _length_bin(length), # choose a bin\n",
    "                             reduce_func=lambda key, ds: _pad_batch(ds, batch_size), # apply reduce funtion\n",
    "                             window_size=batch_size)\n",
    "        )\n",
    "        \n",
    "        # for our \"manual\" test we don't want to shuffle the data\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=100000)\n",
    "\n",
    "        # create iterator\n",
    "        color, color_name, length = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        features = {\n",
    "            COLOR_NAME_KEY: color_name,\n",
    "            SEQUENCE_LENGTH_KEY: length,\n",
    "        }\n",
    "\n",
    "        return features, color\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "m5UJyvW5P0Sy"
   },
   "outputs": [],
   "source": [
    "train_input_fn = get_input_fn(TRAIN_INPUT, BATCH_SIZE)\n",
    "test_input_fn = get_input_fn(TEST_INPUT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': array([4]), 'color_name': array([['l', 'i', 'o', 'n']], dtype=object)}\n",
      "[[ 0.09803922  0.45490196  0.82352942]]\n"
     ]
    }
   ],
   "source": [
    "x, y = get_input_fn(TRAIN_INPUT, 1)()\n",
    "\n",
    "with tf.Session() as s:\n",
    "    print(s.run(x))\n",
    "    print(s.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Estimator model\n",
    "\n",
    "![](imgs/colorbot_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "VxXAUrYN7TvR"
   },
   "outputs": [],
   "source": [
    "def get_model_fn(rnn_cell_sizes,\n",
    "                 label_dimension,\n",
    "                 dnn_layer_sizes=[],\n",
    "                 optimizer='SGD',\n",
    "                 learning_rate=0.01):\n",
    "    \n",
    "    def model_fn(features, labels, mode):\n",
    "        \n",
    "        color_name = features[COLOR_NAME_KEY]\n",
    "        sequence_length = tf.cast(features[SEQUENCE_LENGTH_KEY], dtype=tf.int32) # int64 -> int32\n",
    "        \n",
    "        # ----------- Preparing input --------------------\n",
    "        # Creating a tf constant to hold the map char -> index\n",
    "        # this is need to create the sparse tensor and after the one hot encode\n",
    "        mapping = tf.constant(CHARACTERS, name=\"mapping\")\n",
    "        table = tf.contrib.lookup.index_table_from_tensor(mapping, dtype=tf.string)\n",
    "        int_color_name = table.lookup(color_name)\n",
    "        \n",
    "        # representing colornames with one hot representation\n",
    "        color_name_onehot = tf.one_hot(int_color_name, depth=len(CHARACTERS) + 1)\n",
    "        \n",
    "        # ---------- RNN -------------------\n",
    "        # Each RNN layer will consist of a LSTM cell\n",
    "        rnn_layers = [tf.contrib.rnn.LSTMCell(size) for size in rnn_cell_sizes]\n",
    "        \n",
    "        # Construct the layers\n",
    "        multi_rnn_cell = tf.contrib.rnn.MultiRNNCell(rnn_layers)\n",
    "        \n",
    "        # Runs the RNN model dynamically\n",
    "        # more about it at: \n",
    "        # https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
    "                                                 inputs=color_name_onehot,\n",
    "                                                 sequence_length=sequence_length,\n",
    "                                                 dtype=tf.float32)\n",
    "\n",
    "        # Slice to keep only the last cell of the RNN\n",
    "        last_activations = rnn_common.select_last_activations(outputs,\n",
    "                                                              sequence_length)\n",
    "\n",
    "        # ------------ Dense layers -------------------\n",
    "        # Construct dense layers on top of the last cell of the RNN\n",
    "        for units in dnn_layer_sizes:\n",
    "            last_activations = tf.layers.dense(\n",
    "              last_activations, units, activation=tf.nn.relu)\n",
    "        \n",
    "        # Final dense layer for prediction\n",
    "        predictions = tf.layers.dense(last_activations, label_dimension)\n",
    "\n",
    "        # ----------- Loss and Optimizer ----------------\n",
    "        loss = None\n",
    "        train_op = None\n",
    "\n",
    "        if mode != tf.contrib.learn.ModeKeys.INFER:    \n",
    "            loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "    \n",
    "        if mode == tf.contrib.learn.ModeKeys.TRAIN:    \n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "              loss,\n",
    "              tf.contrib.framework.get_global_step(),\n",
    "              optimizer=optimizer,\n",
    "              learning_rate=learning_rate)\n",
    "        \n",
    "        return model_fn_lib.EstimatorSpec(mode,\n",
    "                                           predictions=predictions,\n",
    "                                           loss=loss,\n",
    "                                           train_op=train_op)\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** *EXERCISE HYPERPARAMETERS: try making changes to the model and see if you can improve the results.\n",
    "Run the original model, run yours and compare them using Tensorboard. What improvements do you see?  \n",
    "hint 0: change the type of RNNCell, maybe a GRUCell? Change the number of hidden layers, or add dnn layers.  \n",
    "hint 1: to compare the implementations using tensorboard just copy the model_dir folder of both executions to the same directory (the model dir should be different at each time you run the model) and point tensorboard to it with: tensorboard --logdir=path_to_model_dirs_par)* **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gUHR3Mzc7Tvb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_model_dir': 'colorbot', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "model_fn = get_model_fn(rnn_cell_sizes=[256, 128], # size of the hidden layers\n",
    "                        label_dimension=3, # since is RGB\n",
    "                        dnn_layer_sizes=[128], # size of units in the dense layers on top of the RNN\n",
    "                        optimizer='Adam', # changing optimizer to Adam\n",
    "                        learning_rate=0.01)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, model_dir='colorbot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning and Evaluating\n",
    "\n",
    "** *EXERCISE EXPERIMENT: The code below works, but we can use an experiment instead. Add a cell that runs an experiment instead of interacting directly with the estimator.  \n",
    "hint 0: you'll need to change the train_input_fn definition, think about it...  \n",
    "hint 1: the change is related with the for loop* **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DUZEKQrdGgZE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.372918, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 23 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0824605.\n",
      "Evaluating epoch 0\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-08-18:40:02\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-23\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-08-18:40:02\n",
      "INFO:tensorflow:Saving dict for global step 23: global_step = 23, loss = 0.0954898\n",
      "Training epoch 1\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-23\n",
      "INFO:tensorflow:Saving checkpoints for 24 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0994802, step = 24\n",
      "INFO:tensorflow:Saving checkpoints for 46 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0647639.\n",
      "Evaluating epoch 1\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-08-18:40:07\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-46\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-08-18:40:07\n",
      "INFO:tensorflow:Saving dict for global step 46: global_step = 46, loss = 0.102245\n",
      "Training epoch 2\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-46\n",
      "INFO:tensorflow:Saving checkpoints for 47 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0986986, step = 47\n",
      "INFO:tensorflow:Saving checkpoints for 69 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0927868.\n",
      "Evaluating epoch 2\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-08-18:40:12\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-69\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-08-18:40:13\n",
      "INFO:tensorflow:Saving dict for global step 69: global_step = 69, loss = 0.0812882\n",
      "Training epoch 3\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-69\n",
      "INFO:tensorflow:Saving checkpoints for 70 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0964924, step = 70\n",
      "INFO:tensorflow:Saving checkpoints for 92 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0761905.\n",
      "Evaluating epoch 3\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-08-18:40:18\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-92\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-08-18:40:18\n",
      "INFO:tensorflow:Saving dict for global step 92: global_step = 92, loss = 0.083149\n",
      "Training epoch 4\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-92\n",
      "INFO:tensorflow:Saving checkpoints for 93 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.098203, step = 93\n",
      "INFO:tensorflow:Saving checkpoints for 115 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0715288.\n",
      "Evaluating epoch 4\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-08-18:40:23\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-115\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-08-18:40:24\n",
      "INFO:tensorflow:Saving dict for global step 115: global_step = 115, loss = 0.0952814\n",
      "Training epoch 5\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-115\n",
      "INFO:tensorflow:Saving checkpoints for 116 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.10845, step = 116\n",
      "INFO:tensorflow:Saving checkpoints for 138 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0390269.\n",
      "Evaluating epoch 5\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-08-18:40:29\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-138\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-08-18:40:29\n",
      "INFO:tensorflow:Saving dict for global step 138: global_step = 138, loss = 0.0750029\n",
      "Training epoch 6\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-138\n",
      "INFO:tensorflow:Saving checkpoints for 139 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0918744, step = 139\n",
      "INFO:tensorflow:Saving checkpoints for 161 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.040798.\n",
      "Evaluating epoch 6\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-08-18:40:34\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-161\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-08-18:40:34\n",
      "INFO:tensorflow:Saving dict for global step 161: global_step = 161, loss = 0.0731551\n",
      "Training epoch 7\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-161\n",
      "INFO:tensorflow:Saving checkpoints for 162 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0924742, step = 162\n",
      "INFO:tensorflow:Saving checkpoints for 184 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0467871.\n",
      "Evaluating epoch 7\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-08-18:40:39\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-184\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-08-18:40:39\n",
      "INFO:tensorflow:Saving dict for global step 184: global_step = 184, loss = 0.0960772\n",
      "Training epoch 8\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-184\n",
      "INFO:tensorflow:Saving checkpoints for 185 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.11175, step = 185\n",
      "INFO:tensorflow:Saving checkpoints for 207 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0249051.\n",
      "Evaluating epoch 8\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-08-18:40:45\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-207\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-08-18:40:45\n",
      "INFO:tensorflow:Saving dict for global step 207: global_step = 207, loss = 0.0785817\n",
      "Training epoch 9\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-207\n",
      "INFO:tensorflow:Saving checkpoints for 208 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0906201, step = 208\n",
      "INFO:tensorflow:Saving checkpoints for 230 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.018581.\n",
      "Evaluating epoch 9\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-08-18:40:51\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-230\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-08-18:40:51\n",
      "INFO:tensorflow:Saving dict for global step 230: global_step = 230, loss = 0.0698065\n",
      "Training epoch 10\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-230\n",
      "INFO:tensorflow:Saving checkpoints for 231 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0878039, step = 231\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f5dc31db7fc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training epoch %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evaluating epoch %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps)\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    503\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    840\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    843\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 40\n",
    "for i in range(NUM_EPOCHS):\n",
    "    print('Training epoch %d' % i)\n",
    "    print('-' * 20)\n",
    "    estimator.train(input_fn=train_input_fn)\n",
    "    print('Evaluating epoch %d' % i)\n",
    "    print('-' * 20)\n",
    "    estimator.evaluate(input_fn = test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(estimator, input_file):\n",
    "    preds = estimator.predict(input_fn=get_input_fn(input_file, 1, shuffle=False))\n",
    "    color_names = _get_csv_column(input_file, 'name')\n",
    "\n",
    "    print()\n",
    "    for p, name in zip(preds, color_names):\n",
    "        color = tuple(map(int, p * 255))\n",
    "        print(name + ',', 'rgb:', color)\n",
    "        _plot_rgb(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-231\n",
      "orange, rgb: (197, 89, 73)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4Gya/4S4bwsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a570a4c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow orange, rgb: (195, 77, 66)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nArWkmvbGP/iwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a57226dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adfgasdgasd, rgb: (190, 96, 104)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqg+bEhnrEygAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a56ca03d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple blue, rgb: (68, 92, 190)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng5sAcCNomgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a5698e210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple red, rgb: (172, 57, 70)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nL+xhmuIFuqg0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a568ff450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple, rgb: (171, 92, 123)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC/h7mw0+lCuHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a5681b2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "water, rgb: (216, 176, 191)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAZB5oDwz7b0tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a567b71d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pink, rgb: (251, 171, 211)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4b/xBqBL/sbsfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a566d4550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock, rgb: (161, 59, 79)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAB7hJREFUeJzt3W2IXGcZxvH/lcRsC9m2SVbSRUPTYFGiSKpL8QVtMRGq\nH2KhVSuKG0iJEARB/RAICLYfbBVfPlTQEKWxBY0NSCKNaJO0CGKiC76EVNJNSsXEtNooobW0JXr7\nYc6GyTqzM7vn7JnbM9cPljkvz8zzHPZiZg5n7vMoIjAbtCWDHoAZOIiWhINoKTiIloKDaCk4iJaC\ng2gpOIiWgoNoKSwb9AC6GX3dSIyNXD3oYdg8PPuviy9ExOsX8ty0QRwbuZovb7xt0MOweZj81YE/\nL/S5/mi2FBxES8FBtBQcREvBQbQUHERLoVQQJa2S9Lik6eJx5Rxtr5F0VtKDZfq0Zir7jrgTOBIR\nNwFHivVu7gN+WbI/a6iyQfwIsLdY3gvc0amRpHcCa4BflOzPGqpsENdExPli+TlaYbuCpCXA14Ev\n9noxSdslTUmaevHSayWHZv9Pel7ik3QYuL7Drl3tKxERkjqVBO4ADkXEWUlz9hURu4HdADeuuM7l\nhUOkZxAjYnO3fZKelzQeEecljQN/69Ds3cD7JO0AVgDLJb0UEXN9n7QhU/ZHDweBSeD+4vHA7AYR\n8cmZZUlbgQmH0GYr+x3xfuCDkqaBzcU6kiYk7Sk7OBsepd4RI+ICsKnD9ingng7bHwIeKtOnNZOv\nrFgKDqKl4CBaCg6ipeAgWgoOoqXgIFoKDqKl4CBaCg6ipeAgWgoOoqWw6MVTkjZK+rWkk5L+KOnj\nZfq0ZqqjeOpl4NMR8VbgduBbkq4r2a81zKIXT0XE0xExXSz/ldavuBd06zJrrkUvnmon6RZgOXCm\nZL/WMHUUT828zjjwMDAZEf/p0mY7sB1gtW/SOVTqKJ5C0jXAY8CuiDg2R1+u4htSZT+aZ4qnoEvx\nlKTlwE+AH0TE/pL9WUPVUTz1MeD9wFZJvy/+Npbs1xpm0YunIuIR4JEy/Vjz+cqKpeAgWgoOoqXg\nIFoKDqKl4CBaCg6ipeAgWgoOoqXgIFoKDqKl4CBaCg6ipVBJECXdLumUpNOS/qeAStKIpH3F/uOS\n1lXRrzVH6SBKWgp8G/gQsAH4hKQNs5ptA/4ZEW8Cvgk8ULZfa5Yq3hFvAU5HxDMR8RrwI1rVfe3a\nq/32A5vUa/YfGypVBPENwF/a1s8W2zq2iYhLwEVg9ewX8hRowyvVyUpE7I6IiYiYGF22fNDDsRpV\nEcRzwNq29TcW2zq2kbQMuBa4UEHf1hBVBPG3wE2Sbiwq9u6mVd3Xrr3a7y7gaES4XNQuKzsXHxFx\nSdJngZ8DS4HvR8RJSfcCUxFxEPge8LCk08A/aIXV7LLSQQSIiEPAoVnbvtS2/Arw0Sr6smZKdbJi\nw8tBtBQcREvBQbQUHERLwUG0FBxES8FBtBQcREvBQbQUHERLwUG0FBxES6GuKr7PS3qqmIvviKQb\nqujXmqOuKr7fARMR8XZaxVNfLduvNUstVXwR8UREvFysHqNVTmB2WV1VfO22AT/rtMNVfMOrkl9o\n90vSp4AJ4NZO+z0F2vCqIoj9VPEhaTOtiSRvjYhXK+jXGqSWKj5JNwPfBbZERMeJI224lQ5iceeG\nmSq+PwE/nqnik7SlaPY1YAXwaDEX3+xyUxtydVXxdZ1q1wx8ZcWScBAtBQfRUnAQLQUH0VJwEC0F\nB9FScBAtBQfRUnAQLQUH0VJwEC0FB9FSqKWKr63dnZJC0kQV/Vpz1FXFh6RR4HPA8bJ9WvPUNRcf\nwH20JoN8pYI+rWFqqeKT9A5gbUQ8NtcLuYpveC36yYqkJcA3gC/0auu5+IZXHXPxjQJvA56U9Czw\nLuCgT1is3aJX8UXExYgYi4h1EbGO1p0etkTEVAV9W0PUVcVnNqdaqvhmbb+tij6tWXxlxVJwEC0F\nB9FScBAtBQfRUlBEztsQSnoRODXocSySMeCFQQ9iEbw5IkYX8sRab9Q5T6ciopFXXyRNNfHYJC34\nIoU/mi0FB9FSyBzE3YMewCJq6rEt+LjSnqzYcMn8jmhDJE0QJa2S9Lik6eJxZZd2/y7uw53+Xtx9\nTA03Imlfsf+4pHX1j3L++jiurZL+3vZ/uqfni0ZEij9a06LtLJZ3Ag90affSoMfa5/EsBc4A64Hl\nwB+ADbPa7AC+UyzfDewb9LgrOq6twIPzed0074i0Cq72Fst7gTsGOJYq9FNU1n7M+4FNklTjGBei\n32K5eckUxDURcb5Yfg5Y06XdVUWB1TFJmcPaz9Rwl9tE6wfGF4HVtYxu4fqd8u7OYjba/ZLWdth/\nhbqnQDsMXN9h1672lYgISd1O52+IiHOS1gNHJZ2IiDNVj9VK+Snww4h4VdJnaL3rf2CuJ9QaxJhj\nvhVJz0saj4jzksaBjjNURcS54vEZSU8CN9P6zpJNP1PDzbQ5K2kZcC1woZ7hLVjP44qI9mPYQx/T\nImf6aD4ITBbLk8CB2Q0krZQ0UiyPAe8FnqpthPPTc2o4rjzmu4CjUXzbT6yfKe/G21a30Kplmtug\nz8LazrRWA0eAaeAwsKrYPgHsKZbfA5ygdaZ2Atg26HH3OKYPA0/TesfeVWy7l1YVI8BVwKPAaeA3\nwPpBj7mi4/oKcLL4Pz0BvKXXa/rKiqWQ6aPZhpiDaCk4iJaCg2gpOIiWgoNoKTiIloKDaCn8F8Ea\nmuRWsjkZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a566700d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(estimator, MY_TEST_INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained model predictions\n",
    "\n",
    "In order to load the pre-trained model we can just create an estimator using the model_fn and use the model_dir that contains the pre-trained model files in this case it's 'pretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_model_dir': 'pretrained', '_save_summary_steps': 100}\n",
      "\n",
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from pretrained/model.ckpt-10020\n",
      "orange, rgb: (249, 89, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a5651f4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow orange, rgb: (243, 99, 40)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6DXjpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a56589790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adfgasdgasd, rgb: (172, 152, 103)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEzqbIk87DbcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a5667a290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple blue, rgb: (56, 50, 214)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nz3Ca7+jP2mcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a566dc350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple red, rgb: (168, 20, 69)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n35rRPjkC2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a5663de90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple, rgb: (133, 49, 193)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBropkeQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a56dbc990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "water, rgb: (148, 218, 240)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4qWA8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a566af1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pink, rgb: (247, 123, 182)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBd+eoC09gbgaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a5663dfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock, rgb: (111, 46, 57)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX6o7mrqz4oihAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a569ebd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_estimator = tf.estimator.Estimator(model_dir='pretrained', model_fn=model_fn)\n",
    "predict(pre_estimator, MY_TEST_INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Colorbot Solutions \n",
    "\n",
    "Here are the solutions to the exercises available at the colorbot notebook.\n",
    "\n",
    "In order to compare the models we encourage you to use Tensorboard and also use play_colorbot.py --model_dir=path_to_your_model to play with the models and check how it does with general words other than color words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE EXPERIMENT\n",
    "\n",
    "When using experiments you should make sure you repeat the datasets the number of epochs desired since the experiment will \"run the for loop for you\". Also, you can add a parameter to run a number of steps instead, it will run until the dataset ends or the number of steps.\n",
    "\n",
    "You can add this cell to your colorbot notebook and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# small important detail, to train properly with the experiment you need to\n",
    "# repeat the dataset the number of epochs desired\n",
    "train_input_fn = get_input_fn(TRAIN_INPUT, BATCH_SIZE, num_epochs=40)\n",
    "\n",
    "# create experiment\n",
    "def generate_experiment_fn(run_config, hparams):\n",
    "    estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
    "    return tf.contrib.learn.Experiment(\n",
    "        estimator,\n",
    "        train_input_fn=train_input_fn,\n",
    "        eval_input_fn=test_input_fn\n",
    "    )\n",
    "\n",
    "learn_runner.run(generate_experiment_fn, run_config=tf.contrib.learn.RunConfig(model_dir='model_dir'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE DATASET\n",
    "\n",
    "0. Run the colorbot experiment and notice the choosen model_dir\n",
    "1. Below is the input function definition,we don't need some of the auxiliar functions anymore\n",
    "2. Add this cell and then add the solution to the EXERCISE EXPERIMENT\n",
    "3. choose a different model_dir and run the cells\n",
    "4. Copy the model_dir of the two models to the same path\n",
    "5. tensorboard --logdir=path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_fn(csv_file, batch_size, num_epochs=1, shuffle=True):\n",
    "    def _parse(line):\n",
    "        # each line: name, red, green, blue\n",
    "        # split line\n",
    "        items = tf.string_split([line],',').values\n",
    "\n",
    "        # get color (r, g, b)\n",
    "        color = tf.string_to_number(items[1:], out_type=tf.float32) / 255.0\n",
    "\n",
    "        # split color_name into a sequence of characters\n",
    "        color_name = tf.string_split([items[0]], '')\n",
    "        length = color_name.indices[-1, 1] + 1 # length = index of last char + 1\n",
    "        color_name = color_name.values\n",
    "        return color, color_name, length\n",
    "\n",
    "    def input_fn():\n",
    "        # https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data\n",
    "        dataset = (\n",
    "            tf.contrib.data.TextLineDataset(csv_file) # reading from the HD\n",
    "            .skip(1) # skip header\n",
    "            .map(_parse) # parse text to variables\n",
    "            .padded_batch(batch_size, padded_shapes=([None], [None], []),\n",
    "                               padding_values=(0.0, chr(0), tf.cast(0, tf.int64)))\n",
    "            \n",
    "            .repeat(num_epochs) # repeat dataset the number of epochs\n",
    "        )\n",
    "        \n",
    "        # for our \"manual\" test we don't want to shuffle the data\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=100000)\n",
    "\n",
    "        # create iterator\n",
    "        color, color_name, length = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        features = {\n",
    "            COLOR_NAME_KEY: color_name,\n",
    "            SEQUENCE_LENGTH_KEY: length,\n",
    "        }\n",
    "\n",
    "        return features, color\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result you will see something like:\n",
    "\n",
    "![](imgs/dataset_exercise_sol.png)\n",
    "\n",
    "We called the original model \"sorted_batch\" and the model using the simplified input function as \"simple_batch\"\n",
    "\n",
    "Notice that both models have basically the same loss in the last step, but the \"sorted_batch\" model runs way faster , notice the `global_step/sec` metric, it measures how many steps the model executes per second. Since the \"sorted_batch\" has a larger `global_step/sec` it means it trains faster. \n",
    "\n",
    "If you don't belive me you can change Tensorboard to compare the models in a \"relative\" way, this will compare the models over time. See result below.\n",
    "\n",
    "![](imgs/dataset_exercise_relative_sol.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE HYPERPARAMETERS\n",
    "\n",
    "This one is more personal, what you see will depends on what you change in the model.\n",
    "Below is a very simple example we just changed the model to use a GRUCell, just in case..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_fn(rnn_cell_sizes,\n",
    "                 label_dimension,\n",
    "                 dnn_layer_sizes=[],\n",
    "                 optimizer='SGD',\n",
    "                 learning_rate=0.01):\n",
    "    \n",
    "    def model_fn(features, labels, mode):\n",
    "        \n",
    "        color_name = features[COLOR_NAME_KEY]\n",
    "        sequence_length = tf.cast(features[SEQUENCE_LENGTH_KEY], dtype=tf.int32) # int64 -> int32\n",
    "        \n",
    "        # ----------- Preparing input --------------------\n",
    "        # Creating a tf constant to hold the map char -> index\n",
    "        # this is need to create the sparse tensor and after the one hot encode\n",
    "        mapping = tf.constant(CHARACTERS, name=\"mapping\")\n",
    "        table = tf.contrib.lookup.index_table_from_tensor(mapping, dtype=tf.string)\n",
    "        int_color_name = table.lookup(color_name)\n",
    "        \n",
    "        # representing colornames with one hot representation\n",
    "        color_name_onehot = tf.one_hot(int_color_name, depth=len(CHARACTERS) + 1)\n",
    "        \n",
    "        # ---------- RNN -------------------\n",
    "        # Each RNN layer will consist of a GRU cell\n",
    "        rnn_layers = [tf.contrib.rnn.GRUCell(size) for size in rnn_cell_sizes]\n",
    "        \n",
    "        # Construct the layers\n",
    "        multi_rnn_cell = tf.contrib.rnn.MultiRNNCell(rnn_layers)\n",
    "        \n",
    "        # Runs the RNN model dynamically\n",
    "        # more about it at: \n",
    "        # https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
    "                                                 inputs=color_name_onehot,\n",
    "                                                 sequence_length=sequence_length,\n",
    "                                                 dtype=tf.float32)\n",
    "\n",
    "        # Slice to keep only the last cell of the RNN\n",
    "        last_activations = rnn_common.select_last_activations(outputs,\n",
    "                                                              sequence_length)\n",
    "\n",
    "        # ------------ Dense layers -------------------\n",
    "        # Construct dense layers on top of the last cell of the RNN\n",
    "        for units in dnn_layer_sizes:\n",
    "            last_activations = tf.layers.dense(\n",
    "              last_activations, units, activation=tf.nn.relu)\n",
    "        \n",
    "        # Final dense layer for prediction\n",
    "        predictions = tf.layers.dense(last_activations, label_dimension)\n",
    "\n",
    "        # ----------- Loss and Optimizer ----------------\n",
    "        loss = None\n",
    "        train_op = None\n",
    "\n",
    "        if mode != tf.contrib.learn.ModeKeys.INFER:    \n",
    "            loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "    \n",
    "        if mode == tf.contrib.learn.ModeKeys.TRAIN:    \n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "              loss,\n",
    "              tf.contrib.framework.get_global_step(),\n",
    "              optimizer=optimizer,\n",
    "              learning_rate=learning_rate)\n",
    "        \n",
    "        return model_fn_lib.EstimatorSpec(mode,\n",
    "                                           predictions=predictions,\n",
    "                                           loss=loss,\n",
    "                                           train_op=train_op)\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "last_runtime": {
    "build_target": "//experimental/users/jamieas/transform_colab:notebook",
    "kind": "private"
   },
   "name": "Copy of CustomEstimator.ipynb",
   "provenance": [
    {
     "file_id": "0BwN-JPfIIHwgdFkwUTVIWTQwU00",
     "timestamp": 1496845355496
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
