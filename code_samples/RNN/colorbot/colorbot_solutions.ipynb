{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorbot Solutions \n",
    "\n",
    "Here are the solutions to the exercises available at the colorbot notebook.\n",
    "\n",
    "In order to compare the models we encourage you to use Tensorboard and also use play_colorbot.py --model_dir=path_to_your_model to play with the models and check how it does with general words other than color words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE EXPERIMENT\n",
    "\n",
    "When using experiments you should make sure you repeat the datasets the number of epochs desired since the experiment will \"run the for loop for you\". Also, you can add a parameter to run a number of steps instead, it will run until the dataset ends or the number of steps.\n",
    "\n",
    "You can add this cell to your colorbot notebook and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small important detail, to train properly with the experiment you need to\n",
    "# repeat the dataset the number of epochs desired\n",
    "train_input_fn = get_input_fn(TRAIN_INPUT, BATCH_SIZE, num_epochs=40)\n",
    "\n",
    "# create experiment\n",
    "def generate_experiment_fn(run_config, hparams):\n",
    "    estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
    "    return tf.contrib.learn.Experiment(\n",
    "        estimator,\n",
    "        train_input_fn=train_input_fn,\n",
    "        eval_input_fn=test_input_fn\n",
    "    )\n",
    "\n",
    "learn_runner.run(generate_experiment_fn, run_config=tf.contrib.learn.RunConfig(model_dir='model_dir'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE DATASET\n",
    "\n",
    "0. Run the colorbot experiment and notice the choosen model_dir\n",
    "1. Below is the input function definition,we don't need some of the auxiliar functions anymore\n",
    "2. Add this cell and then add the solution to the EXERCISE EXPERIMENT\n",
    "3. choose a different model_dir and run the cells\n",
    "4. Copy the model_dir of the two models to the same path\n",
    "5. tensorboard --logdir=path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_fn(csv_file, batch_size, num_epochs=1, shuffle=True):\n",
    "    def _parse(line):\n",
    "        # each line: name, red, green, blue\n",
    "        # split line\n",
    "        items = tf.string_split([line],',').values\n",
    "\n",
    "        # get color (r, g, b)\n",
    "        color = tf.string_to_number(items[1:], out_type=tf.float32) / 255.0\n",
    "\n",
    "        # split color_name into a sequence of characters\n",
    "        color_name = tf.string_split([items[0]], '')\n",
    "        length = color_name.indices[-1, 1] + 1 # length = index of last char + 1\n",
    "        color_name = color_name.values\n",
    "        return color, color_name, length\n",
    "\n",
    "    def input_fn():\n",
    "        # https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data\n",
    "        dataset = (\n",
    "            tf.contrib.data.TextLineDataset(csv_file) # reading from the HD\n",
    "            .skip(1) # skip header\n",
    "            .map(_parse) # parse text to variables\n",
    "            .padded_batch(batch_size, padded_shapes=([None], [None], []),\n",
    "                               padding_values=(0.0, chr(0), tf.cast(0, tf.int64)))\n",
    "            \n",
    "            .repeat(num_epochs) # repeat dataset the number of epochs\n",
    "        )\n",
    "        \n",
    "        # for our \"manual\" test we don't want to shuffle the data\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=100000)\n",
    "\n",
    "        # create iterator\n",
    "        color, color_name, length = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        features = {\n",
    "            COLOR_NAME_KEY: color_name,\n",
    "            SEQUENCE_LENGTH_KEY: length,\n",
    "        }\n",
    "\n",
    "        return features, color\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result you will see something like:\n",
    "\n",
    "![](imgs/dataset_exercise_sol.png)\n",
    "\n",
    "We called the original model \"sorted_batch\" and the model using the simplified input function as \"simple_batch\"\n",
    "\n",
    "Notice that both models have basically the same loss in the last step, but the \"sorted_batch\" model runs way faster , notice the `global_step/sec` metric, it measures how many steps the model executes per second. Since the \"sorted_batch\" has a larger `global_step/sec` it means it trains faster. \n",
    "\n",
    "If you don't belive me you can change Tensorboard to compare the models in a \"relative\" way, this will compare the models over time. See result below.\n",
    "\n",
    "![](imgs/dataset_exercise_relative_sol.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE HYPERPARAMETERS\n",
    "\n",
    "This one is more personal, what you see will depends on what you change in the model.\n",
    "Below is a very simple example we just changed the model to use a GRUCell, just in case..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_fn(rnn_cell_sizes,\n",
    "                 label_dimension,\n",
    "                 dnn_layer_sizes=[],\n",
    "                 optimizer='SGD',\n",
    "                 learning_rate=0.01):\n",
    "    \n",
    "    def model_fn(features, labels, mode):\n",
    "        \n",
    "        color_name = features[COLOR_NAME_KEY]\n",
    "        sequence_length = tf.cast(features[SEQUENCE_LENGTH_KEY], dtype=tf.int32) # int64 -> int32\n",
    "        \n",
    "        # ----------- Preparing input --------------------\n",
    "        # Creating a tf constant to hold the map char -> index\n",
    "        # this is need to create the sparse tensor and after the one hot encode\n",
    "        mapping = tf.constant(CHARACTERS, name=\"mapping\")\n",
    "        table = tf.contrib.lookup.index_table_from_tensor(mapping, dtype=tf.string)\n",
    "        int_color_name = table.lookup(color_name)\n",
    "        \n",
    "        # representing colornames with one hot representation\n",
    "        color_name_onehot = tf.one_hot(int_color_name, depth=len(CHARACTERS) + 1)\n",
    "        \n",
    "        # ---------- RNN -------------------\n",
    "        # Each RNN layer will consist of a GRU cell\n",
    "        rnn_layers = [tf.nn.rnn_cell.GRUCell(size) for size in rnn_cell_sizes]\n",
    "        \n",
    "        # Construct the layers\n",
    "        multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "        \n",
    "        # Runs the RNN model dynamically\n",
    "        # more about it at: \n",
    "        # https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
    "                                                 inputs=color_name_onehot,\n",
    "                                                 sequence_length=sequence_length,\n",
    "                                                 dtype=tf.float32)\n",
    "\n",
    "        # Slice to keep only the last cell of the RNN\n",
    "        last_activations = rnn_common.select_last_activations(outputs,\n",
    "                                                              sequence_length)\n",
    "\n",
    "        # ------------ Dense layers -------------------\n",
    "        # Construct dense layers on top of the last cell of the RNN\n",
    "        for units in dnn_layer_sizes:\n",
    "            last_activations = tf.layers.dense(\n",
    "              last_activations, units, activation=tf.nn.relu)\n",
    "        \n",
    "        # Final dense layer for prediction\n",
    "        predictions = tf.layers.dense(last_activations, label_dimension)\n",
    "\n",
    "        # ----------- Loss and Optimizer ----------------\n",
    "        loss = None\n",
    "        train_op = None\n",
    "\n",
    "        if mode != tf.estimator.ModeKeys.PREDICT:    \n",
    "            loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "    \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:    \n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "              loss,\n",
    "              tf.contrib.framework.get_global_step(),\n",
    "              optimizer=optimizer,\n",
    "              learning_rate=learning_rate)\n",
    "        \n",
    "        return model_fn_lib.EstimatorSpec(mode,\n",
    "                                           predictions=predictions,\n",
    "                                           loss=loss,\n",
    "                                           train_op=train_op)\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the tensorboard comparison of a model using a GRUCell called \"gru\" and a model using LSTMCell called \"simple_batch\".\n",
    "\n",
    "![](imgs/hyperparameters_exercise_sol.png)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "last_runtime": {
    "build_target": "//experimental/users/jamieas/transform_colab:notebook",
    "kind": "private"
   },
   "name": "Copy of CustomEstimator.ipynb",
   "provenance": [
    {
     "file_id": "0BwN-JPfIIHwgdFkwUTVIWTQwU00",
     "timestamp": 1496845355496
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
