{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Data Example: Automobile dataset\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please make sure that version >= 1.2:\n",
      "1.2.0-rc1\n",
      "@monteirom: I made changes so it also works with 1.1.0 that is the current pip install version\n",
      "@monteirom: The lines that were changed have @1.2 as comment\n"
     ]
    }
   ],
   "source": [
    "# We're using pandas to read the CSV file. This is easy for small datasets, but for large and complex datasets,\n",
    "# tensorflow parsing and processing functions are more powerful\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "print('please make sure that version >= 1.2:')\n",
    "print(tf.__version__)\n",
    "print('@monteirom: I made changes so it also works with 1.1.0 that is the current pip install version')\n",
    "print('@monteirom: The lines that were changed have @1.2 as comment')\n",
    "\n",
    "# Layers that will define the features\n",
    "#\n",
    "# real_value_column: real values, float32\n",
    "# sparse_column_with_hash_bucket: Use this when your sparse features are in string or integer format, \n",
    "#                                 but you don't have a vocab file that maps each value to an integer ID. \n",
    "#                                 output_id = Hash(input_feature_string) % bucket_size\n",
    "# sparse_column_with_keys: Look up logic is as follows: \n",
    "#                          lookup_id = index_of_feature_in_keys if feature in keys else default_value.\n",
    "#                          You should use this when you know the vocab file for the feature\n",
    "# one_hot_column: Creates an _OneHotColumn for a one-hot or multi-hot repr in a DNN.\n",
    "#                 The input can be a _SparseColumn which is created by `sparse_column_with_*`\n",
    "#                 or crossed_column functions\n",
    "from tensorflow.contrib.layers import real_valued_column, sparse_column_with_keys, sparse_column_with_hash_bucket\n",
    "from tensorflow.contrib.layers import one_hot_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Please Download\n",
    "\n",
    "**https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\n",
    "And move it to data/**\n",
    "\n",
    "**So: data/imports-85.data is expected to exist!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The CSV file does not have a header, so we have to fill in column names.\n",
    "names = [\n",
    "    'symboling', \n",
    "    'normalized-losses', \n",
    "    'make', \n",
    "    'fuel-type', \n",
    "    'aspiration',\n",
    "    'num-of-doors',\n",
    "    'body-style',\n",
    "    'drive-wheels',\n",
    "    'engine-location',\n",
    "    'wheel-base',\n",
    "    'length',\n",
    "    'width',\n",
    "    'height',\n",
    "    'curb-weight',\n",
    "    'engine-type',\n",
    "    'num-of-cylinders',\n",
    "    'engine-size',\n",
    "    'fuel-system',\n",
    "    'bore',\n",
    "    'stroke',\n",
    "    'compression-ratio',\n",
    "    'horsepower',\n",
    "    'peak-rpm',\n",
    "    'city-mpg',\n",
    "    'highway-mpg',\n",
    "    'price',\n",
    "]\n",
    "\n",
    "# We also have to specify dtypes.\n",
    "dtypes = {\n",
    "    'symboling': np.int32, \n",
    "    'normalized-losses': np.float32, \n",
    "    'make': str, \n",
    "    'fuel-type': str, \n",
    "    'aspiration': str,\n",
    "    'num-of-doors': str,\n",
    "    'body-style': str,\n",
    "    'drive-wheels': str,\n",
    "    'engine-location': str,\n",
    "    'wheel-base': np.float32,\n",
    "    'length': np.float32,\n",
    "    'width': np.float32,\n",
    "    'height': np.float32,\n",
    "    'curb-weight': np.float32,\n",
    "    'engine-type': str,\n",
    "    'num-of-cylinders': str,\n",
    "    'engine-size': np.float32,\n",
    "    'fuel-system': str,\n",
    "    'bore': np.float32,\n",
    "    'stroke': np.float32,\n",
    "    'compression-ratio': np.float32,\n",
    "    'horsepower': np.float32,\n",
    "    'peak-rpm': np.float32,\n",
    "    'city-mpg': np.float32,\n",
    "    'highway-mpg': np.float32,\n",
    "    'price': np.float32,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the file.\n",
    "df = pd.read_csv('data/imports-85.data', names=names, dtype=dtypes, na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some rows don't have price data, we can't use those.\n",
    "df = df.dropna(axis='rows', how='any', subset=['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NaN\n",
    "\n",
    "There are many approaches possibles for NaN values in the data, here we just changing it to \" \" or 0 depending of the data type. This is the simplest way, but for sure is not the best in most cases, so in practice you should try some other ways to use the NaN data. Some approaches are:\n",
    "\n",
    "* use the mean of the row\n",
    "* use the mean of the column\n",
    "* if/else substituion (e.g if a lot of NaN do this, else do this other thing)\n",
    "* ...\n",
    "* google others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in continuous columns with zeros instead of NaN.\n",
    "float_columns = [k for k,v in dtypes.items() if v == np.float32]\n",
    "df[float_columns] = df[float_columns].fillna(value=0., axis='columns')\n",
    "\n",
    "# Fill missing values in continuous columns with '' instead of NaN (NaN mixed with strings is very bad for us).\n",
    "string_columns = [k for k,v in dtypes.items() if v == str]\n",
    "df[string_columns] = df[string_columns].fillna(value='', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have too many variables let's just use some of them\n",
    "df = df[['num-of-doors','num-of-cylinders', 'horsepower', 'make', 'price', 'length', 'height', 'width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 168.8 after: -0.438314\n"
     ]
    }
   ],
   "source": [
    "# Since we're possibly dealing with parameters of different units and scales. We'll need to rescale our data.\n",
    "# There are two main ways to do it: \n",
    "# * Normalization, which scales all numeric variables in the range [0,1].\n",
    "#   Example:\n",
    "# * Standardization, it will then transform it to have zero mean and unit variance.\n",
    "#   Example: \n",
    "# Which is better? It deppends of your data and your features.\n",
    "# But one disadvantage of normalization over standardization is that it loses \n",
    "# some information in the data. Since normalization loses more info it can make harder\n",
    "# for gradient descent to converse, so we'll use standardization.\n",
    "# In practice: please analyse your data and see what gives you better results.\n",
    "\n",
    "def std(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "before = df.length[0]\n",
    "df.length = std(df.length)\n",
    "df.width = std(df.width)\n",
    "df.height = std(df.height)\n",
    "df.horsepower = std(df.horsepower)\n",
    "\n",
    "after = df.length[0]\n",
    "print('before:', before, 'after:', after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating training data from testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_SIZE = 160\n",
    "TEST_DATA_SIZE = 10\n",
    "\n",
    "LABEL = 'price'\n",
    "\n",
    "# Split the data into a training set, eval set and test set\n",
    "training_data = df[:TRAINING_DATA_SIZE]\n",
    "eval_data = df[TRAINING_DATA_SIZE: TRAINING_DATA_SIZE + TEST_DATA_SIZE]\n",
    "test_data = df[TRAINING_DATA_SIZE + TEST_DATA_SIZE:]\n",
    "\n",
    "# Separate input features from labels\n",
    "training_label = training_data.pop(LABEL)\n",
    "eval_label = eval_data.pop(LABEL)\n",
    "test_label = test_data.pop(LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# Make input function for training: \n",
    "#   num_epochs=None -> will cycle through input data forever\n",
    "#   shuffle=True -> randomize order of input data\n",
    "training_input_fn = tf.estimator.inputs.pandas_input_fn(x=training_data,\n",
    "                                                        y=training_label,\n",
    "                                                        batch_size=BATCH_SIZE,\n",
    "                                                        shuffle=True,\n",
    "                                                        num_epochs=None)\n",
    "\n",
    "# Make input function for evaluation:\n",
    "# shuffle=False -> do not randomize input data\n",
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(x=eval_data,\n",
    "                                                    y=eval_label,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False)\n",
    "\n",
    "# Make input function for testing:\n",
    "# shuffle=False -> do not randomize input data\n",
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(x=test_data,\n",
    "                                                    y=test_label,\n",
    "                                                    batch_size=1,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Linear Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Describe how the model should interpret the inputs. The names of the feature columns have to match the names\n",
    "# of the series in the dataframe.\n",
    "\n",
    "# @1.2.0 tf.feature_column.numeric_column -> tf.contrib.layers.real_valued_column\n",
    "horsepower = real_valued_column('horsepower')\n",
    "width = real_valued_column('width')\n",
    "height = real_valued_column('height')\n",
    "length = real_valued_column('length')\n",
    "\n",
    "# @1.2.0 tf.feature_column.categorical_column_with_hash_bucket -> tf.contrib.layers.sparse_column_with_hash_bucket\n",
    "make = sparse_column_with_hash_bucket('make', 50)\n",
    "\n",
    "# @1.2.0 tf.feature_column.categorical_column_with_vocabulary_list -> tf.contrib.layers.sparse_column_with_keys\n",
    "fuel_type = sparse_column_with_keys('fuel-type', keys=['diesel', 'gas'])\n",
    "num_of_doors = sparse_column_with_keys('num-of-doors', keys=['two', 'four'])\n",
    "num_of_cylinders = sparse_column_with_keys('num-of-cylinders', ['eight', 'five', 'four', 'six', 'three', 'twelve', 'two'])\n",
    "\n",
    "linear_features = [horsepower, make, num_of_doors, num_of_cylinders, length, width, height]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_session_config': None, '_model_dir': 'tensorboard/linear_regressor/', '_master': '', '_tf_random_seed': None, '_environment': 'local', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_task_type': None, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faf67544b70>, '_save_summary_steps': 100, '_evaluation_master': '', '_is_chief': True}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.contrib.learn.LinearRegressor(feature_columns=linear_features, model_dir='tensorboard/linear_regressor/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into tensorboard/linear_regressor/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.59493e+08, step = 1\n",
      "INFO:tensorflow:global_step/sec: 513.702\n",
      "INFO:tensorflow:loss = 2.42048e+08, step = 101 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 744.834\n",
      "INFO:tensorflow:loss = 2.35011e+08, step = 201 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 687.575\n",
      "INFO:tensorflow:loss = 2.44327e+08, step = 301 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 823.258\n",
      "INFO:tensorflow:loss = 1.79146e+08, step = 401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 824.485\n",
      "INFO:tensorflow:loss = 2.55799e+08, step = 501 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 752.257\n",
      "INFO:tensorflow:loss = 2.96889e+08, step = 601 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 832.816\n",
      "INFO:tensorflow:loss = 3.09307e+08, step = 701 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 718.056\n",
      "INFO:tensorflow:loss = 2.83337e+08, step = 801 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.19\n",
      "INFO:tensorflow:loss = 2.10819e+08, step = 901 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 726.727\n",
      "INFO:tensorflow:loss = 2.04816e+08, step = 1001 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.972\n",
      "INFO:tensorflow:loss = 2.82682e+08, step = 1101 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.84\n",
      "INFO:tensorflow:loss = 2.09374e+08, step = 1201 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 768.883\n",
      "INFO:tensorflow:loss = 2.12449e+08, step = 1301 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 797.953\n",
      "INFO:tensorflow:loss = 1.92286e+08, step = 1401 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 773.69\n",
      "INFO:tensorflow:loss = 3.47359e+08, step = 1501 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 827.859\n",
      "INFO:tensorflow:loss = 2.94114e+08, step = 1601 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 743.422\n",
      "INFO:tensorflow:loss = 3.01521e+08, step = 1701 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.342\n",
      "INFO:tensorflow:loss = 2.10661e+08, step = 1801 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 711.548\n",
      "INFO:tensorflow:loss = 2.28232e+08, step = 1901 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.583\n",
      "INFO:tensorflow:loss = 2.49248e+08, step = 2001 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.353\n",
      "INFO:tensorflow:loss = 1.88631e+08, step = 2101 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 766.686\n",
      "INFO:tensorflow:loss = 2.5245e+08, step = 2201 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 843.11\n",
      "INFO:tensorflow:loss = 2.74482e+08, step = 2301 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 797.668\n",
      "INFO:tensorflow:loss = 3.02005e+08, step = 2401 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.467\n",
      "INFO:tensorflow:loss = 2.83143e+08, step = 2501 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 748.361\n",
      "INFO:tensorflow:loss = 2.65891e+08, step = 2601 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 707.099\n",
      "INFO:tensorflow:loss = 1.98249e+08, step = 2701 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 722.949\n",
      "INFO:tensorflow:loss = 2.67378e+08, step = 2801 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.043\n",
      "INFO:tensorflow:loss = 2.40542e+08, step = 2901 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 855.335\n",
      "INFO:tensorflow:loss = 2.32458e+08, step = 3001 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 827.752\n",
      "INFO:tensorflow:loss = 2.22932e+08, step = 3101 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 823.763\n",
      "INFO:tensorflow:loss = 2.85029e+08, step = 3201 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 886.22\n",
      "INFO:tensorflow:loss = 2.4638e+08, step = 3301 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 844.936\n",
      "INFO:tensorflow:loss = 2.72305e+08, step = 3401 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.667\n",
      "INFO:tensorflow:loss = 2.84096e+08, step = 3501 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.814\n",
      "INFO:tensorflow:loss = 1.99117e+08, step = 3601 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 771.2\n",
      "INFO:tensorflow:loss = 2.14304e+08, step = 3701 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 798.976\n",
      "INFO:tensorflow:loss = 3.32135e+08, step = 3801 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.718\n",
      "INFO:tensorflow:loss = 2.27205e+08, step = 3901 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.634\n",
      "INFO:tensorflow:loss = 2.03773e+08, step = 4001 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.16\n",
      "INFO:tensorflow:loss = 2.15381e+08, step = 4101 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.065\n",
      "INFO:tensorflow:loss = 2.63055e+08, step = 4201 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 674.845\n",
      "INFO:tensorflow:loss = 2.20646e+08, step = 4301 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.045\n",
      "INFO:tensorflow:loss = 3.02877e+08, step = 4401 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.865\n",
      "INFO:tensorflow:loss = 2.75835e+08, step = 4501 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 711.414\n",
      "INFO:tensorflow:loss = 2.20396e+08, step = 4601 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 738.189\n",
      "INFO:tensorflow:loss = 2.86457e+08, step = 4701 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.309\n",
      "INFO:tensorflow:loss = 2.37476e+08, step = 4801 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.468\n",
      "INFO:tensorflow:loss = 2.08786e+08, step = 4901 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.955\n",
      "INFO:tensorflow:loss = 1.92465e+08, step = 5001 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 715.902\n",
      "INFO:tensorflow:loss = 2.23654e+08, step = 5101 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.612\n",
      "INFO:tensorflow:loss = 2.53477e+08, step = 5201 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.031\n",
      "INFO:tensorflow:loss = 2.66573e+08, step = 5301 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 755.733\n",
      "INFO:tensorflow:loss = 2.77477e+08, step = 5401 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.653\n",
      "INFO:tensorflow:loss = 3.05158e+08, step = 5501 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.346\n",
      "INFO:tensorflow:loss = 2.8148e+08, step = 5601 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.741\n",
      "INFO:tensorflow:loss = 2.33417e+08, step = 5701 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 725.72\n",
      "INFO:tensorflow:loss = 1.87216e+08, step = 5801 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.661\n",
      "INFO:tensorflow:loss = 1.3973e+08, step = 5901 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.231\n",
      "INFO:tensorflow:loss = 3.39514e+08, step = 6001 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.049\n",
      "INFO:tensorflow:loss = 2.48877e+08, step = 6101 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.538\n",
      "INFO:tensorflow:loss = 2.49429e+08, step = 6201 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 726.021\n",
      "INFO:tensorflow:loss = 2.78524e+08, step = 6301 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.588\n",
      "INFO:tensorflow:loss = 2.63528e+08, step = 6401 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 768.71\n",
      "INFO:tensorflow:loss = 2.81293e+08, step = 6501 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.739\n",
      "INFO:tensorflow:loss = 2.44084e+08, step = 6601 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 755.37\n",
      "INFO:tensorflow:loss = 2.50055e+08, step = 6701 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 752.313\n",
      "INFO:tensorflow:loss = 2.21139e+08, step = 6801 (0.133 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 774.118\n",
      "INFO:tensorflow:loss = 3.46903e+08, step = 6901 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 742.067\n",
      "INFO:tensorflow:loss = 3.03337e+08, step = 7001 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 737.658\n",
      "INFO:tensorflow:loss = 2.33171e+08, step = 7101 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.162\n",
      "INFO:tensorflow:loss = 2.02141e+08, step = 7201 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.51\n",
      "INFO:tensorflow:loss = 3.23866e+08, step = 7301 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 748.617\n",
      "INFO:tensorflow:loss = 2.31643e+08, step = 7401 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.476\n",
      "INFO:tensorflow:loss = 2.89519e+08, step = 7501 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 802.441\n",
      "INFO:tensorflow:loss = 2.23578e+08, step = 7601 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 838.834\n",
      "INFO:tensorflow:loss = 2.81537e+08, step = 7701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 841.294\n",
      "INFO:tensorflow:loss = 1.60254e+08, step = 7801 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.338\n",
      "INFO:tensorflow:loss = 3.09894e+08, step = 7901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 849.904\n",
      "INFO:tensorflow:loss = 2.2752e+08, step = 8001 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 837.425\n",
      "INFO:tensorflow:loss = 2.81988e+08, step = 8101 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.826\n",
      "INFO:tensorflow:loss = 2.47757e+08, step = 8201 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 736.863\n",
      "INFO:tensorflow:loss = 1.83806e+08, step = 8301 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 752.277\n",
      "INFO:tensorflow:loss = 2.35405e+08, step = 8401 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 779.909\n",
      "INFO:tensorflow:loss = 2.49566e+08, step = 8501 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 792.817\n",
      "INFO:tensorflow:loss = 2.83184e+08, step = 8601 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 770.227\n",
      "INFO:tensorflow:loss = 2.14609e+08, step = 8701 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 786.916\n",
      "INFO:tensorflow:loss = 2.05047e+08, step = 8801 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 764.332\n",
      "INFO:tensorflow:loss = 2.36374e+08, step = 8901 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.398\n",
      "INFO:tensorflow:loss = 2.206e+08, step = 9001 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 723.33\n",
      "INFO:tensorflow:loss = 2.28052e+08, step = 9101 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 841.887\n",
      "INFO:tensorflow:loss = 2.89942e+08, step = 9201 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.547\n",
      "INFO:tensorflow:loss = 2.20093e+08, step = 9301 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 850.308\n",
      "INFO:tensorflow:loss = 1.75145e+08, step = 9401 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.639\n",
      "INFO:tensorflow:loss = 2.48838e+08, step = 9501 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.603\n",
      "INFO:tensorflow:loss = 1.56434e+08, step = 9601 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.764\n",
      "INFO:tensorflow:loss = 2.46945e+08, step = 9701 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.973\n",
      "INFO:tensorflow:loss = 2.20785e+08, step = 9801 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 830.713\n",
      "INFO:tensorflow:loss = 2.54528e+08, step = 9901 (0.120 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into tensorboard/linear_regressor/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.51601e+08.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegressor(params={'joint_weights': False, 'gradient_clip_norm': None, 'feature_columns': [_RealValuedColumn(column_name='horsepower', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _SparseColumnHashed(column_name='make', is_integerized=False, bucket_size=50, lookup_config=None, combiner='sum', dtype=tf.string), _SparseColumnKeys(column_name='num-of-doors', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=('two', 'four'), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string), _SparseColumnKeys(column_name='num-of-cylinders', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=('eight', 'five', 'four', 'six', 'three', 'twelve', 'two'), num_oov_buckets=0, vocab_size=7, default_value=-1), combiner='sum', dtype=tf.string), _RealValuedColumn(column_name='length', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='width', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='height', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)], 'optimizer': None, 'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x7faf67544860>})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(input_fn=training_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-15-14:01:39\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/linear_regressor/model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-14:01:39\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 2.03146e+08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'global_step': 10000, 'loss': 2.0314605e+08}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/python/util/deprecation.py:347: calling LinearRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.linear) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/linear_regressor/model.ckpt-10000\n",
      "prediction: 142.403 real value: 10698.0\n",
      "prediction: 159.54 real value: 9988.0\n",
      "prediction: 160.006 real value: 10898.0\n",
      "prediction: 159.54 real value: 11248.0\n",
      "prediction: 262.848 real value: 16558.0\n",
      "prediction: 262.848 real value: 15998.0\n",
      "prediction: 251.596 real value: 15690.0\n",
      "prediction: 251.596 real value: 15750.0\n",
      "prediction: 58.2873 real value: 7775.0\n",
      "prediction: 88.861 real value: 7975.0\n"
     ]
    }
   ],
   "source": [
    "preds = list(regressor.predict(input_fn=eval_input_fn))\n",
    "\n",
    "for i in range(TEST_DATA_SIZE):\n",
    "    print('prediction:', preds[i], 'real value:', test_label.iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a DNN Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @1.2.0 tf.feature_column.indicator_column -> tf.contrib.layers.one_hot_column(tf.contrib.layers.sparse_column_with_keys(...))\n",
    "dnn_features = [\n",
    "    #numerical features\n",
    "    length, width, height, horsepower,    \n",
    "    # densify categorical features:\n",
    "    one_hot_column(make),\n",
    "    one_hot_column(num_of_doors)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_session_config': None, '_model_dir': 'tensorboard/DNN_regressor/', '_master': '', '_tf_random_seed': None, '_environment': 'local', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_task_type': None, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faf6408c9e8>, '_save_summary_steps': 100, '_evaluation_master': '', '_is_chief': True}\n"
     ]
    }
   ],
   "source": [
    "dnnregressor = tf.contrib.learn.DNNRegressor(feature_columns=dnn_features,\n",
    "                                             hidden_units=[50, 30, 10], model_dir='tensorboard/DNN_regressor/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into tensorboard/DNN_regressor/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.90802e+08, step = 1\n",
      "INFO:tensorflow:global_step/sec: 643.468\n",
      "INFO:tensorflow:loss = 1.1641e+07, step = 101 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 694.261\n",
      "INFO:tensorflow:loss = 7.98193e+06, step = 201 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 747.178\n",
      "INFO:tensorflow:loss = 3.06143e+06, step = 301 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.46\n",
      "INFO:tensorflow:loss = 4.55193e+06, step = 401 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 804.846\n",
      "INFO:tensorflow:loss = 4.13768e+06, step = 501 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 834.797\n",
      "INFO:tensorflow:loss = 4.86764e+06, step = 601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 740.98\n",
      "INFO:tensorflow:loss = 4.57349e+06, step = 701 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.291\n",
      "INFO:tensorflow:loss = 3.10496e+06, step = 801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 755.382\n",
      "INFO:tensorflow:loss = 4.67391e+06, step = 901 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.709\n",
      "INFO:tensorflow:loss = 3.29688e+06, step = 1001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.289\n",
      "INFO:tensorflow:loss = 4.17016e+06, step = 1101 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 742.823\n",
      "INFO:tensorflow:loss = 2.59178e+06, step = 1201 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.648\n",
      "INFO:tensorflow:loss = 5.13116e+06, step = 1301 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.064\n",
      "INFO:tensorflow:loss = 2.73089e+06, step = 1401 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.622\n",
      "INFO:tensorflow:loss = 2.7186e+06, step = 1501 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.466\n",
      "INFO:tensorflow:loss = 4.57346e+06, step = 1601 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.247\n",
      "INFO:tensorflow:loss = 3.98322e+06, step = 1701 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.013\n",
      "INFO:tensorflow:loss = 3.03508e+06, step = 1801 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.101\n",
      "INFO:tensorflow:loss = 5.12813e+06, step = 1901 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.105\n",
      "INFO:tensorflow:loss = 4.6744e+06, step = 2001 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.092\n",
      "INFO:tensorflow:loss = 3.57615e+06, step = 2101 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 846.508\n",
      "INFO:tensorflow:loss = 2.10253e+06, step = 2201 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.051\n",
      "INFO:tensorflow:loss = 3.35572e+06, step = 2301 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 829.184\n",
      "INFO:tensorflow:loss = 2.67412e+06, step = 2401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 729.485\n",
      "INFO:tensorflow:loss = 1.82536e+06, step = 2501 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 734.258\n",
      "INFO:tensorflow:loss = 2.79449e+06, step = 2601 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 807.086\n",
      "INFO:tensorflow:loss = 5.17955e+06, step = 2701 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.419\n",
      "INFO:tensorflow:loss = 5.65098e+06, step = 2801 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 887.304\n",
      "INFO:tensorflow:loss = 5.58609e+06, step = 2901 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.772\n",
      "INFO:tensorflow:loss = 3.50584e+06, step = 3001 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.663\n",
      "INFO:tensorflow:loss = 2.62402e+06, step = 3101 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 686.328\n",
      "INFO:tensorflow:loss = 2.59574e+06, step = 3201 (0.147 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-e5b06bef6748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdnnregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             instructions)\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    291\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m       \u001b[0msummary_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSummaryWriterCache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    503\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    840\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    843\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dnnregressor.fit(input_fn=training_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-15-00:11:52\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp5u7roxz9/model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-00:11:52\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 1.54887e+07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'global_step': 10000, 'loss': 15488682.0}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnregressor.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/python/util/deprecation.py:347: calling DNNRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp5u7roxz9/model.ckpt-10000\n",
      "prediction: 9597.67 real value: 10698.0\n",
      "prediction: 11866.2 real value: 9988.0\n",
      "prediction: 11514.2 real value: 10898.0\n",
      "prediction: 11866.2 real value: 11248.0\n",
      "prediction: 23688.1 real value: 16558.0\n",
      "prediction: 23688.1 real value: 15998.0\n",
      "prediction: 22791.1 real value: 15690.0\n",
      "prediction: 22791.1 real value: 15750.0\n",
      "prediction: 4272.87 real value: 7775.0\n",
      "prediction: 6275.6 real value: 7975.0\n"
     ]
    }
   ],
   "source": [
    "preds = list(dnnregressor.predict(input_fn=eval_input_fn))\n",
    "\n",
    "for i in range(TEST_DATA_SIZE):\n",
    "    print('prediction:', preds[i], 'real value:', test_label.iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @1.2.0 experiment_fn(run_config, params) - > experiment_fn(output_dir)\n",
    "def experiment_fn(output_dir):\n",
    "    # This function makes an Experiment, containing an Estimator and inputs for training and evaluation.\n",
    "    # You can use params and config here to customize the Estimator depending on the cluster or to use\n",
    "    # hyperparameter tuning.\n",
    "\n",
    "    # Collect information for training\n",
    "    # @1.2.0 config=run_config -> ''\n",
    "    return tf.contrib.learn.Experiment(estimator=tf.contrib.learn.LinearRegressor(\n",
    "                                     feature_columns=linear_features, model_dir=output_dir),\n",
    "                                     train_input_fn=training_input_fn,\n",
    "                                     train_steps=10000,\n",
    "                                     eval_input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_session_config': None, '_model_dir': '/tmp/output_dir', '_master': '', '_tf_random_seed': None, '_environment': 'local', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_task_type': None, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faf2c6dc5f8>, '_save_summary_steps': 100, '_evaluation_master': '', '_is_chief': True}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:268: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/output_dir/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.53779e+08, step = 1\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-15-00:13:35\n",
      "INFO:tensorflow:Restoring parameters from /tmp/output_dir/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-00:13:35\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 2.08159e+08\n",
      "INFO:tensorflow:Validation (step 1): loss = 2.08159e+08, global_step = 1\n",
      "INFO:tensorflow:global_step/sec: 54.6108\n",
      "INFO:tensorflow:loss = 3.2995e+08, step = 101 (1.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.199\n",
      "INFO:tensorflow:loss = 2.2434e+08, step = 201 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.823\n",
      "INFO:tensorflow:loss = 2.70825e+08, step = 301 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.326\n",
      "INFO:tensorflow:loss = 2.6304e+08, step = 401 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.905\n",
      "INFO:tensorflow:loss = 2.07089e+08, step = 501 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.526\n",
      "INFO:tensorflow:loss = 2.40862e+08, step = 601 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.318\n",
      "INFO:tensorflow:loss = 2.4237e+08, step = 701 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.001\n",
      "INFO:tensorflow:loss = 1.96818e+08, step = 801 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.254\n",
      "INFO:tensorflow:loss = 2.08855e+08, step = 901 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.583\n",
      "INFO:tensorflow:loss = 2.83313e+08, step = 1001 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.998\n",
      "INFO:tensorflow:loss = 3.63846e+08, step = 1101 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.892\n",
      "INFO:tensorflow:loss = 2.27487e+08, step = 1201 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.153\n",
      "INFO:tensorflow:loss = 1.95032e+08, step = 1301 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.272\n",
      "INFO:tensorflow:loss = 2.15183e+08, step = 1401 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.015\n",
      "INFO:tensorflow:loss = 2.63166e+08, step = 1501 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.721\n",
      "INFO:tensorflow:loss = 2.94977e+08, step = 1601 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.031\n",
      "INFO:tensorflow:loss = 2.07383e+08, step = 1701 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.855\n",
      "INFO:tensorflow:loss = 2.41123e+08, step = 1801 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.033\n",
      "INFO:tensorflow:loss = 2.24982e+08, step = 1901 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.881\n",
      "INFO:tensorflow:loss = 2.31737e+08, step = 2001 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.01\n",
      "INFO:tensorflow:loss = 2.37991e+08, step = 2101 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.816\n",
      "INFO:tensorflow:loss = 1.94863e+08, step = 2201 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.928\n",
      "INFO:tensorflow:loss = 2.36104e+08, step = 2301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.532\n",
      "INFO:tensorflow:loss = 2.42888e+08, step = 2401 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.561\n",
      "INFO:tensorflow:loss = 2.06083e+08, step = 2501 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.19\n",
      "INFO:tensorflow:loss = 2.10886e+08, step = 2601 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.82\n",
      "INFO:tensorflow:loss = 2.36597e+08, step = 2701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.239\n",
      "INFO:tensorflow:loss = 2.64082e+08, step = 2801 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.252\n",
      "INFO:tensorflow:loss = 2.7465e+08, step = 2901 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.216\n",
      "INFO:tensorflow:loss = 3.03645e+08, step = 3001 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.783\n",
      "INFO:tensorflow:loss = 2.82896e+08, step = 3101 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.608\n",
      "INFO:tensorflow:loss = 2.05005e+08, step = 3201 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.04795e+08, step = 3301 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.621\n",
      "INFO:tensorflow:loss = 2.34377e+08, step = 3401 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.705\n",
      "INFO:tensorflow:loss = 2.8409e+08, step = 3501 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.064\n",
      "INFO:tensorflow:loss = 2.64078e+08, step = 3601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.578\n",
      "INFO:tensorflow:loss = 1.93784e+08, step = 3701 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.774\n",
      "INFO:tensorflow:loss = 2.8074e+08, step = 3801 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.669\n",
      "INFO:tensorflow:loss = 2.33637e+08, step = 3901 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.921\n",
      "INFO:tensorflow:loss = 1.72349e+08, step = 4001 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.449\n",
      "INFO:tensorflow:loss = 2.2439e+08, step = 4101 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.478\n",
      "INFO:tensorflow:loss = 3.11015e+08, step = 4201 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.359\n",
      "INFO:tensorflow:loss = 3.30783e+08, step = 4301 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.685\n",
      "INFO:tensorflow:loss = 1.86487e+08, step = 4401 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.766\n",
      "INFO:tensorflow:loss = 2.14433e+08, step = 4501 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.857\n",
      "INFO:tensorflow:loss = 1.76995e+08, step = 4601 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.425\n",
      "INFO:tensorflow:loss = 2.38683e+08, step = 4701 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.707\n",
      "INFO:tensorflow:loss = 2.83825e+08, step = 4801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.829\n",
      "INFO:tensorflow:loss = 2.53666e+08, step = 4901 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.946\n",
      "INFO:tensorflow:loss = 2.04523e+08, step = 5001 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.178\n",
      "INFO:tensorflow:loss = 2.86669e+08, step = 5101 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.332\n",
      "INFO:tensorflow:loss = 2.7821e+08, step = 5201 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.092\n",
      "INFO:tensorflow:loss = 2.59791e+08, step = 5301 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.003\n",
      "INFO:tensorflow:loss = 2.47141e+08, step = 5401 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.106\n",
      "INFO:tensorflow:loss = 2.37231e+08, step = 5501 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.993\n",
      "INFO:tensorflow:loss = 2.72222e+08, step = 5601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.965\n",
      "INFO:tensorflow:loss = 2.79429e+08, step = 5701 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.171\n",
      "INFO:tensorflow:loss = 3.34573e+08, step = 5801 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.233\n",
      "INFO:tensorflow:loss = 3.56468e+08, step = 5901 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.368\n",
      "INFO:tensorflow:loss = 2.97041e+08, step = 6001 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.584\n",
      "INFO:tensorflow:loss = 2.29266e+08, step = 6101 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.962\n",
      "INFO:tensorflow:loss = 2.10434e+08, step = 6201 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.391\n",
      "INFO:tensorflow:loss = 1.9858e+08, step = 6301 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.808\n",
      "INFO:tensorflow:loss = 3.40392e+08, step = 6401 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.701\n",
      "INFO:tensorflow:loss = 1.35302e+08, step = 6501 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.52\n",
      "INFO:tensorflow:loss = 2.45073e+08, step = 6601 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.151\n",
      "INFO:tensorflow:loss = 1.8786e+08, step = 6701 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.783\n",
      "INFO:tensorflow:loss = 2.59138e+08, step = 6801 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.139\n",
      "INFO:tensorflow:loss = 2.56774e+08, step = 6901 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.202\n",
      "INFO:tensorflow:loss = 2.22381e+08, step = 7001 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.518\n",
      "INFO:tensorflow:loss = 3.19742e+08, step = 7101 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.642\n",
      "INFO:tensorflow:loss = 1.45798e+08, step = 7201 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.489\n",
      "INFO:tensorflow:loss = 2.8065e+08, step = 7301 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.284\n",
      "INFO:tensorflow:loss = 3.20594e+08, step = 7401 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.923\n",
      "INFO:tensorflow:loss = 2.86083e+08, step = 7501 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.777\n",
      "INFO:tensorflow:loss = 3.02958e+08, step = 7601 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.444\n",
      "INFO:tensorflow:loss = 2.35591e+08, step = 7701 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.848\n",
      "INFO:tensorflow:loss = 2.33625e+08, step = 7801 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.736\n",
      "INFO:tensorflow:loss = 2.14244e+08, step = 7901 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.138\n",
      "INFO:tensorflow:loss = 2.29226e+08, step = 8001 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.767\n",
      "INFO:tensorflow:loss = 3.2403e+08, step = 8101 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.772\n",
      "INFO:tensorflow:loss = 2.40912e+08, step = 8201 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.843\n",
      "INFO:tensorflow:loss = 2.55732e+08, step = 8301 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.67\n",
      "INFO:tensorflow:loss = 2.01069e+08, step = 8401 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.5\n",
      "INFO:tensorflow:loss = 2.51314e+08, step = 8501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.806\n",
      "INFO:tensorflow:loss = 2.33035e+08, step = 8601 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.854\n",
      "INFO:tensorflow:loss = 2.13737e+08, step = 8701 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.588\n",
      "INFO:tensorflow:loss = 2.20099e+08, step = 8801 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.643\n",
      "INFO:tensorflow:loss = 2.17736e+08, step = 8901 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.195\n",
      "INFO:tensorflow:loss = 3.29561e+08, step = 9001 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.331\n",
      "INFO:tensorflow:loss = 2.18982e+08, step = 9101 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.163\n",
      "INFO:tensorflow:loss = 2.73778e+08, step = 9201 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.112\n",
      "INFO:tensorflow:loss = 1.85688e+08, step = 9301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.984\n",
      "INFO:tensorflow:loss = 2.32726e+08, step = 9401 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.21\n",
      "INFO:tensorflow:loss = 2.143e+08, step = 9501 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.697\n",
      "INFO:tensorflow:loss = 2.24054e+08, step = 9601 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.808\n",
      "INFO:tensorflow:loss = 3.07036e+08, step = 9701 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.613\n",
      "INFO:tensorflow:loss = 2.25359e+08, step = 9801 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.992\n",
      "INFO:tensorflow:loss = 2.78171e+08, step = 9901 (0.205 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/output_dir/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.36605e+08.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-15-00:13:58\n",
      "INFO:tensorflow:Restoring parameters from /tmp/output_dir/model.ckpt-10000\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-00:13:59\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 2.03137e+08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'global_step': 10000, 'loss': 2.0313659e+08}, [])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "# @1.2.0 tf.contrib.learn.learn_runner(exp, run_config=tf.contrib.learn.RunConfig(model_dir=\"/tmp/output_dir\")\n",
    "# -> tf.contrib.learn.python.learn.learm_runner.run(exp, output_dir='/tmp/output_dir')\n",
    "shutil.rmtree(\"/tmp/output_dir\", ignore_errors=True)\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "learn_runner.run(experiment_fn, output_dir='/tmp/output_dir')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
