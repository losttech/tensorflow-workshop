{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Data Example: Automobile dataset\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please make sure that version >= 1.2:\n",
      "1.2.0-rc1\n",
      "@monteirom: I made changes so it also works with 1.1.0 that is the current pip install version\n",
      "@monteirom: The lines that were changed have @1.2 as comment\n"
     ]
    }
   ],
   "source": [
    "# We're using pandas to read the CSV file. This is easy for small datasets, but for large and complex datasets,\n",
    "# tensorflow parsing and processing functions are more powerful\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "print('please make sure that version >= 1.2:')\n",
    "print(tf.__version__)\n",
    "print('@monteirom: I made changes so it also works with 1.1.0 that is the current pip install version')\n",
    "print('@monteirom: The lines that were changed have @1.2 as comment')\n",
    "\n",
    "# Layers that will define the features\n",
    "#\n",
    "# real_value_column: real values, float32\n",
    "# sparse_column_with_hash_bucket: Use this when your sparse features are in string or integer format, \n",
    "#                                 but you don't have a vocab file that maps each value to an integer ID. \n",
    "#                                 output_id = Hash(input_feature_string) % bucket_size\n",
    "# sparse_column_with_keys: Look up logic is as follows: \n",
    "#                          lookup_id = index_of_feature_in_keys if feature in keys else default_value.\n",
    "#                          You should use this when you know the vocab file for the feature\n",
    "# one_hot_column: Creates an _OneHotColumn for a one-hot or multi-hot repr in a DNN.\n",
    "#                 The input can be a _SparseColumn which is created by `sparse_column_with_*`\n",
    "#                 or crossed_column functions\n",
    "from tensorflow.contrib.layers import real_valued_column, sparse_column_with_keys, sparse_column_with_hash_bucket\n",
    "from tensorflow.contrib.layers import one_hot_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Please Download\n",
    "\n",
    "**https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\n",
    "And move it to data/**\n",
    "\n",
    "**So: data/imports-85.data is expected to exist!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The CSV file does not have a header, so we have to fill in column names.\n",
    "names = [\n",
    "    'symboling', \n",
    "    'normalized-losses', \n",
    "    'make', \n",
    "    'fuel-type', \n",
    "    'aspiration',\n",
    "    'num-of-doors',\n",
    "    'body-style',\n",
    "    'drive-wheels',\n",
    "    'engine-location',\n",
    "    'wheel-base',\n",
    "    'length',\n",
    "    'width',\n",
    "    'height',\n",
    "    'curb-weight',\n",
    "    'engine-type',\n",
    "    'num-of-cylinders',\n",
    "    'engine-size',\n",
    "    'fuel-system',\n",
    "    'bore',\n",
    "    'stroke',\n",
    "    'compression-ratio',\n",
    "    'horsepower',\n",
    "    'peak-rpm',\n",
    "    'city-mpg',\n",
    "    'highway-mpg',\n",
    "    'price',\n",
    "]\n",
    "\n",
    "# We also have to specify dtypes.\n",
    "dtypes = {\n",
    "    'symboling': np.int32, \n",
    "    'normalized-losses': np.float32, \n",
    "    'make': str, \n",
    "    'fuel-type': str, \n",
    "    'aspiration': str,\n",
    "    'num-of-doors': str,\n",
    "    'body-style': str,\n",
    "    'drive-wheels': str,\n",
    "    'engine-location': str,\n",
    "    'wheel-base': np.float32,\n",
    "    'length': np.float32,\n",
    "    'width': np.float32,\n",
    "    'height': np.float32,\n",
    "    'curb-weight': np.float32,\n",
    "    'engine-type': str,\n",
    "    'num-of-cylinders': str,\n",
    "    'engine-size': np.float32,\n",
    "    'fuel-system': str,\n",
    "    'bore': np.float32,\n",
    "    'stroke': np.float32,\n",
    "    'compression-ratio': np.float32,\n",
    "    'horsepower': np.float32,\n",
    "    'peak-rpm': np.float32,\n",
    "    'city-mpg': np.float32,\n",
    "    'highway-mpg': np.float32,\n",
    "    'price': np.float32,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the file.\n",
    "df = pd.read_csv('data/imports-85.data', names=names, dtype=dtypes, na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some rows don't have price data, we can't use those.\n",
    "df = df.dropna(axis='rows', how='any', subset=['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NaN\n",
    "\n",
    "There are many approaches possibles for NaN values in the data, here we just changing it to \" \" or 0 depending of the data type. This is the simplest way, but for sure is not the best in most cases, so in practice you should try some other ways to use the NaN data. Some approaches are:\n",
    "\n",
    "* use the mean of the row\n",
    "* use the mean of the column\n",
    "* if/else substituion (e.g if a lot of NaN do this, else do this other thing)\n",
    "* ...\n",
    "* google others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in continuous columns with zeros instead of NaN.\n",
    "float_columns = [k for k,v in dtypes.items() if v == np.float32]\n",
    "df[float_columns] = df[float_columns].fillna(value=0., axis='columns')\n",
    "\n",
    "# Fill missing values in continuous columns with '' instead of NaN (NaN mixed with strings is very bad for us).\n",
    "string_columns = [k for k,v in dtypes.items() if v == str]\n",
    "df[string_columns] = df[string_columns].fillna(value='', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have too many variables let's just use some of them\n",
    "df = df[['num-of-doors','num-of-cylinders', 'horsepower', 'make', 'price', 'length', 'height', 'width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 168.8 after: -0.438314\n"
     ]
    }
   ],
   "source": [
    "# Since we're possibly dealing with parameters of different units and scales. We'll need to rescale our data.\n",
    "# There are two main ways to do it: \n",
    "# * Normalization, which scales all numeric variables in the range [0,1].\n",
    "#   Example:\n",
    "# * Standardization, it will then transform it to have zero mean and unit variance.\n",
    "#   Example: \n",
    "# Which is better? It deppends of your data and your features.\n",
    "# But one disadvantage of normalization over standardization is that it loses \n",
    "# some information in the data. Since normalization loses more info it can make harder\n",
    "# for gradient descent to converse, so we'll use standardization.\n",
    "# In practice: please analyse your data and see what gives you better results.\n",
    "\n",
    "def std(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "before = df.length[0]\n",
    "df.length = std(df.length)\n",
    "df.width = std(df.width)\n",
    "df.height = std(df.height)\n",
    "df.horsepower = std(df.horsepower)\n",
    "\n",
    "after = df.length[0]\n",
    "print('before:', before, 'after:', after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating training data from testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_SIZE = 160\n",
    "TEST_DATA_SIZE = 10\n",
    "\n",
    "LABEL = 'price'\n",
    "\n",
    "# Split the data into a training set, eval set and test set\n",
    "training_data = df[:TRAINING_DATA_SIZE]\n",
    "eval_data = df[TRAINING_DATA_SIZE: TRAINING_DATA_SIZE + TEST_DATA_SIZE]\n",
    "test_data = df[TRAINING_DATA_SIZE + TEST_DATA_SIZE:]\n",
    "\n",
    "# Separate input features from labels\n",
    "training_label = training_data.pop(LABEL)\n",
    "eval_label = eval_data.pop(LABEL)\n",
    "test_label = test_data.pop(LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# Make input function for training: \n",
    "#   num_epochs=None -> will cycle through input data forever\n",
    "#   shuffle=True -> randomize order of input data\n",
    "training_input_fn = tf.estimator.inputs.pandas_input_fn(x=training_data,\n",
    "                                                        y=training_label,\n",
    "                                                        batch_size=BATCH_SIZE,\n",
    "                                                        shuffle=True,\n",
    "                                                        num_epochs=None)\n",
    "\n",
    "# Make input function for evaluation:\n",
    "# shuffle=False -> do not randomize input data\n",
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(x=eval_data,\n",
    "                                                    y=eval_label,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False)\n",
    "\n",
    "# Make input function for testing:\n",
    "# shuffle=False -> do not randomize input data\n",
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(x=test_data,\n",
    "                                                    y=test_label,\n",
    "                                                    batch_size=1,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Linear Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Describe how the model should interpret the inputs. The names of the feature columns have to match the names\n",
    "# of the series in the dataframe.\n",
    "\n",
    "# @1.2.0 tf.feature_column.numeric_column -> tf.contrib.layers.real_valued_column\n",
    "horsepower = real_valued_column('horsepower')\n",
    "width = real_valued_column('width')\n",
    "height = real_valued_column('height')\n",
    "length = real_valued_column('length')\n",
    "\n",
    "# @1.2.0 tf.feature_column.categorical_column_with_hash_bucket -> tf.contrib.layers.sparse_column_with_hash_bucket\n",
    "make = sparse_column_with_hash_bucket('make', 50)\n",
    "\n",
    "# @1.2.0 tf.feature_column.categorical_column_with_vocabulary_list -> tf.contrib.layers.sparse_column_with_keys\n",
    "fuel_type = sparse_column_with_keys('fuel-type', keys=['diesel', 'gas'])\n",
    "num_of_doors = sparse_column_with_keys('num-of-doors', keys=['two', 'four'])\n",
    "num_of_cylinders = sparse_column_with_keys('num-of-cylinders', ['eight', 'five', 'four', 'six', 'three', 'twelve', 'two'])\n",
    "\n",
    "linear_features = [horsepower, make, num_of_doors, num_of_cylinders, length, width, height]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_session_config': None, '_model_dir': 'tensorboard/linear_regressor/', '_master': '', '_tf_random_seed': None, '_environment': 'local', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_task_type': None, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faf67544b70>, '_save_summary_steps': 100, '_evaluation_master': '', '_is_chief': True}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.contrib.learn.LinearRegressor(feature_columns=linear_features, model_dir='tensorboard/linear_regressor/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/linear_regressor/model.ckpt-10000\n",
      "INFO:tensorflow:Saving checkpoints for 10001 into tensorboard/linear_regressor/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3649e+08, step = 10001\n",
      "INFO:tensorflow:global_step/sec: 487.666\n",
      "INFO:tensorflow:loss = 2.64713e+08, step = 10101 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.038\n",
      "INFO:tensorflow:loss = 1.71841e+08, step = 10201 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 753.477\n",
      "INFO:tensorflow:loss = 2.28382e+08, step = 10301 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 843.912\n",
      "INFO:tensorflow:loss = 2.27272e+08, step = 10401 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 792.461\n",
      "INFO:tensorflow:loss = 2.5155e+08, step = 10501 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 792.853\n",
      "INFO:tensorflow:loss = 2.94792e+08, step = 10601 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 797.68\n",
      "INFO:tensorflow:loss = 2.52011e+08, step = 10701 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 827.651\n",
      "INFO:tensorflow:loss = 2.28872e+08, step = 10801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.689\n",
      "INFO:tensorflow:loss = 2.59033e+08, step = 10901 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 834.32\n",
      "INFO:tensorflow:loss = 3.01536e+08, step = 11001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.106\n",
      "INFO:tensorflow:loss = 2.44482e+08, step = 11101 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 765.947\n",
      "INFO:tensorflow:loss = 2.9846e+08, step = 11201 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.784\n",
      "INFO:tensorflow:loss = 2.94663e+08, step = 11301 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 824.534\n",
      "INFO:tensorflow:loss = 2.41443e+08, step = 11401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 866.56\n",
      "INFO:tensorflow:loss = 2.65833e+08, step = 11501 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 909.636\n",
      "INFO:tensorflow:loss = 1.94989e+08, step = 11601 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 888.274\n",
      "INFO:tensorflow:loss = 2.45184e+08, step = 11701 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 880.437\n",
      "INFO:tensorflow:loss = 2.53462e+08, step = 11801 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 836.163\n",
      "INFO:tensorflow:loss = 1.96561e+08, step = 11901 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 850.22\n",
      "INFO:tensorflow:loss = 2.0783e+08, step = 12001 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 829.03\n",
      "INFO:tensorflow:loss = 2.19988e+08, step = 12101 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 856.974\n",
      "INFO:tensorflow:loss = 1.87884e+08, step = 12201 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.78\n",
      "INFO:tensorflow:loss = 1.96885e+08, step = 12301 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 842.492\n",
      "INFO:tensorflow:loss = 3.23267e+08, step = 12401 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.834\n",
      "INFO:tensorflow:loss = 2.04225e+08, step = 12501 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 734.003\n",
      "INFO:tensorflow:loss = 2.56797e+08, step = 12601 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 845.667\n",
      "INFO:tensorflow:loss = 2.59135e+08, step = 12701 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 818.819\n",
      "INFO:tensorflow:loss = 2.6101e+08, step = 12801 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 692.346\n",
      "INFO:tensorflow:loss = 2.12495e+08, step = 12901 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 732.3\n",
      "INFO:tensorflow:loss = 2.53228e+08, step = 13001 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 883.856\n",
      "INFO:tensorflow:loss = 2.74027e+08, step = 13101 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 901.377\n",
      "INFO:tensorflow:loss = 2.85378e+08, step = 13201 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.314\n",
      "INFO:tensorflow:loss = 2.07587e+08, step = 13301 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.604\n",
      "INFO:tensorflow:loss = 1.90748e+08, step = 13401 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.16\n",
      "INFO:tensorflow:loss = 2.55649e+08, step = 13501 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.372\n",
      "INFO:tensorflow:loss = 1.76534e+08, step = 13601 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 913.223\n",
      "INFO:tensorflow:loss = 2.04736e+08, step = 13701 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 795.664\n",
      "INFO:tensorflow:loss = 3.35833e+08, step = 13801 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.953\n",
      "INFO:tensorflow:loss = 1.93106e+08, step = 13901 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.618\n",
      "INFO:tensorflow:loss = 1.59751e+08, step = 14001 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.342\n",
      "INFO:tensorflow:loss = 2.39024e+08, step = 14101 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 797.44\n",
      "INFO:tensorflow:loss = 2.57495e+08, step = 14201 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 760.112\n",
      "INFO:tensorflow:loss = 1.8934e+08, step = 14301 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 715.349\n",
      "INFO:tensorflow:loss = 2.56141e+08, step = 14401 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 762.918\n",
      "INFO:tensorflow:loss = 2.07191e+08, step = 14501 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.793\n",
      "INFO:tensorflow:loss = 1.92391e+08, step = 14601 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.904\n",
      "INFO:tensorflow:loss = 2.04549e+08, step = 14701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.384\n",
      "INFO:tensorflow:loss = 3.23016e+08, step = 14801 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 724.549\n",
      "INFO:tensorflow:loss = 2.3303e+08, step = 14901 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.871\n",
      "INFO:tensorflow:loss = 2.5306e+08, step = 15001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 810.273\n",
      "INFO:tensorflow:loss = 2.1004e+08, step = 15101 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 859.49\n",
      "INFO:tensorflow:loss = 1.9931e+08, step = 15201 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.195\n",
      "INFO:tensorflow:loss = 2.72383e+08, step = 15301 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 789.58\n",
      "INFO:tensorflow:loss = 1.85116e+08, step = 15401 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 762.767\n",
      "INFO:tensorflow:loss = 2.95402e+08, step = 15501 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 713.743\n",
      "INFO:tensorflow:loss = 2.45418e+08, step = 15601 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 597.107\n",
      "INFO:tensorflow:loss = 2.48227e+08, step = 15701 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.462\n",
      "INFO:tensorflow:loss = 4.23105e+08, step = 15801 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.802\n",
      "INFO:tensorflow:loss = 2.0276e+08, step = 15901 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.797\n",
      "INFO:tensorflow:loss = 2.72434e+08, step = 16001 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.111\n",
      "INFO:tensorflow:loss = 3.06792e+08, step = 16101 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 692.25\n",
      "INFO:tensorflow:loss = 1.6977e+08, step = 16201 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 715.072\n",
      "INFO:tensorflow:loss = 1.74598e+08, step = 16301 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 740.773\n",
      "INFO:tensorflow:loss = 2.69238e+08, step = 16401 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 718.917\n",
      "INFO:tensorflow:loss = 2.07609e+08, step = 16501 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.956\n",
      "INFO:tensorflow:loss = 2.33665e+08, step = 16601 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 734.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.88454e+08, step = 16701 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 711.329\n",
      "INFO:tensorflow:loss = 2.66716e+08, step = 16801 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.028\n",
      "INFO:tensorflow:loss = 2.40482e+08, step = 16901 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 551.129\n",
      "INFO:tensorflow:loss = 1.71491e+08, step = 17001 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.47\n",
      "INFO:tensorflow:loss = 2.43472e+08, step = 17101 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 740.87\n",
      "INFO:tensorflow:loss = 3.72998e+08, step = 17201 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.003\n",
      "INFO:tensorflow:loss = 1.76391e+08, step = 17301 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 887.008\n",
      "INFO:tensorflow:loss = 2.03636e+08, step = 17401 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 886.531\n",
      "INFO:tensorflow:loss = 2.03204e+08, step = 17501 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 849.691\n",
      "INFO:tensorflow:loss = 2.10635e+08, step = 17601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 723.69\n",
      "INFO:tensorflow:loss = 2.1184e+08, step = 17701 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 761.203\n",
      "INFO:tensorflow:loss = 2.77344e+08, step = 17801 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 805.298\n",
      "INFO:tensorflow:loss = 3.10556e+08, step = 17901 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 776.499\n",
      "INFO:tensorflow:loss = 1.80064e+08, step = 18001 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 726.984\n",
      "INFO:tensorflow:loss = 2.6132e+08, step = 18101 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.102\n",
      "INFO:tensorflow:loss = 2.71631e+08, step = 18201 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 734.272\n",
      "INFO:tensorflow:loss = 2.65901e+08, step = 18301 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.165\n",
      "INFO:tensorflow:loss = 2.62825e+08, step = 18401 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 548.97\n",
      "INFO:tensorflow:loss = 1.92312e+08, step = 18501 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 711.498\n",
      "INFO:tensorflow:loss = 1.81039e+08, step = 18601 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 584.093\n",
      "INFO:tensorflow:loss = 2.24824e+08, step = 18701 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.242\n",
      "INFO:tensorflow:loss = 2.72645e+08, step = 18801 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.417\n",
      "INFO:tensorflow:loss = 2.22061e+08, step = 18901 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 761.179\n",
      "INFO:tensorflow:loss = 3.13355e+08, step = 19001 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 791.381\n",
      "INFO:tensorflow:loss = 2.17411e+08, step = 19101 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 733.634\n",
      "INFO:tensorflow:loss = 1.44224e+08, step = 19201 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 786.583\n",
      "INFO:tensorflow:loss = 3.02453e+08, step = 19301 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.41\n",
      "INFO:tensorflow:loss = 2.98873e+08, step = 19401 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 563.124\n",
      "INFO:tensorflow:loss = 2.10761e+08, step = 19501 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.107\n",
      "INFO:tensorflow:loss = 3.01292e+08, step = 19601 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.241\n",
      "INFO:tensorflow:loss = 2.41969e+08, step = 19701 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 755.899\n",
      "INFO:tensorflow:loss = 2.53078e+08, step = 19801 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 753.018\n",
      "INFO:tensorflow:loss = 2.43982e+08, step = 19901 (0.133 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into tensorboard/linear_regressor/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.35494e+08.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegressor(params={'joint_weights': False, 'gradient_clip_norm': None, 'feature_columns': [_RealValuedColumn(column_name='horsepower', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _SparseColumnHashed(column_name='make', is_integerized=False, bucket_size=50, lookup_config=None, combiner='sum', dtype=tf.string), _SparseColumnKeys(column_name='num-of-doors', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=('two', 'four'), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string), _SparseColumnKeys(column_name='num-of-cylinders', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=('eight', 'five', 'four', 'six', 'three', 'twelve', 'two'), num_oov_buckets=0, vocab_size=7, default_value=-1), combiner='sum', dtype=tf.string), _RealValuedColumn(column_name='length', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='width', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='height', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)], 'optimizer': None, 'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x7faf67544860>})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(input_fn=training_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-15-14:06:27\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/linear_regressor/model.ckpt-20000\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-14:06:27\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 2.01072e+08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'global_step': 20000, 'loss': 2.0107243e+08}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/python/util/deprecation.py:347: calling LinearRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.linear) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/linear_regressor/model.ckpt-20000\n",
      "prediction: 201.656 real value: 10698.0\n",
      "prediction: 225.959 real value: 9988.0\n",
      "prediction: 226.609 real value: 10898.0\n",
      "prediction: 225.959 real value: 11248.0\n",
      "prediction: 372.34 real value: 16558.0\n",
      "prediction: 372.34 real value: 15998.0\n",
      "prediction: 356.334 real value: 15690.0\n",
      "prediction: 356.334 real value: 15750.0\n",
      "prediction: 82.5563 real value: 7775.0\n",
      "prediction: 125.895 real value: 7975.0\n"
     ]
    }
   ],
   "source": [
    "preds = list(regressor.predict(input_fn=eval_input_fn))\n",
    "\n",
    "for i in range(TEST_DATA_SIZE):\n",
    "    print('prediction:', preds[i], 'real value:', test_label.iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a DNN Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @1.2.0 tf.feature_column.indicator_column -> tf.contrib.layers.one_hot_column(tf.contrib.layers.sparse_column_with_keys(...))\n",
    "dnn_features = [\n",
    "    #numerical features\n",
    "    length, width, height, horsepower,    \n",
    "    # densify categorical features:\n",
    "    one_hot_column(make),\n",
    "    one_hot_column(num_of_doors)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_session_config': None, '_model_dir': 'tensorboard/DNN_regressor/', '_master': '', '_tf_random_seed': None, '_environment': 'local', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_task_type': None, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faf2418a630>, '_save_summary_steps': 100, '_evaluation_master': '', '_is_chief': True}\n"
     ]
    }
   ],
   "source": [
    "dnnregressor = tf.contrib.learn.DNNRegressor(feature_columns=dnn_features,\n",
    "                                             hidden_units=[50, 30, 10], model_dir='tensorboard/DNN_regressor/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/DNN_regressor/model.ckpt-10000\n",
      "INFO:tensorflow:Saving checkpoints for 10001 into tensorboard/DNN_regressor/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.0062e+06, step = 10001\n",
      "INFO:tensorflow:global_step/sec: 410.865\n",
      "INFO:tensorflow:loss = 1.80712e+06, step = 10101 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.046\n",
      "INFO:tensorflow:loss = 1.08074e+06, step = 10201 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.219\n",
      "INFO:tensorflow:loss = 2.16673e+06, step = 10301 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.175\n",
      "INFO:tensorflow:loss = 1.27043e+06, step = 10401 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.612\n",
      "INFO:tensorflow:loss = 1.73635e+06, step = 10501 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 542.977\n",
      "INFO:tensorflow:loss = 2.44349e+06, step = 10601 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.278\n",
      "INFO:tensorflow:loss = 1.72678e+06, step = 10701 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 539.579\n",
      "INFO:tensorflow:loss = 1.73575e+06, step = 10801 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 569.43\n",
      "INFO:tensorflow:loss = 1.84625e+06, step = 10901 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.667\n",
      "INFO:tensorflow:loss = 1.40508e+06, step = 11001 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.118\n",
      "INFO:tensorflow:loss = 1.85724e+06, step = 11101 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.727\n",
      "INFO:tensorflow:loss = 2.04939e+06, step = 11201 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.254\n",
      "INFO:tensorflow:loss = 1.54183e+06, step = 11301 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.349\n",
      "INFO:tensorflow:loss = 2.96649e+06, step = 11401 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.249\n",
      "INFO:tensorflow:loss = 1.07737e+06, step = 11501 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.923\n",
      "INFO:tensorflow:loss = 1.58026e+06, step = 11601 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.207\n",
      "INFO:tensorflow:loss = 1.63373e+06, step = 11701 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 553.665\n",
      "INFO:tensorflow:loss = 1.67285e+06, step = 11801 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.318\n",
      "INFO:tensorflow:loss = 2.56106e+06, step = 11901 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.954\n",
      "INFO:tensorflow:loss = 2.04174e+06, step = 12001 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 594.491\n",
      "INFO:tensorflow:loss = 1.0685e+06, step = 12101 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.315\n",
      "INFO:tensorflow:loss = 1.78378e+06, step = 12201 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 562.286\n",
      "INFO:tensorflow:loss = 1.23437e+06, step = 12301 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.133\n",
      "INFO:tensorflow:loss = 2.01861e+06, step = 12401 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.574\n",
      "INFO:tensorflow:loss = 1.09678e+06, step = 12501 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.196\n",
      "INFO:tensorflow:loss = 1.14881e+06, step = 12601 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.272\n",
      "INFO:tensorflow:loss = 1.36226e+06, step = 12701 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.907\n",
      "INFO:tensorflow:loss = 2.27906e+06, step = 12801 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.592\n",
      "INFO:tensorflow:loss = 2.18078e+06, step = 12901 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.854\n",
      "INFO:tensorflow:loss = 1.40007e+06, step = 13001 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 737.43\n",
      "INFO:tensorflow:loss = 2.25306e+06, step = 13101 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 592.39\n",
      "INFO:tensorflow:loss = 1.57321e+06, step = 13201 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.36\n",
      "INFO:tensorflow:loss = 1.337e+06, step = 13301 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.066\n",
      "INFO:tensorflow:loss = 1.90416e+06, step = 13401 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.916\n",
      "INFO:tensorflow:loss = 1.59448e+06, step = 13501 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.586\n",
      "INFO:tensorflow:loss = 1.50297e+06, step = 13601 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.333\n",
      "INFO:tensorflow:loss = 977750.0, step = 13701 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 605.422\n",
      "INFO:tensorflow:loss = 1.60281e+06, step = 13801 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.328\n",
      "INFO:tensorflow:loss = 1.32841e+06, step = 13901 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 553.949\n",
      "INFO:tensorflow:loss = 1.47141e+06, step = 14001 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 586.639\n",
      "INFO:tensorflow:loss = 1.13979e+06, step = 14101 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.641\n",
      "INFO:tensorflow:loss = 1.33312e+06, step = 14201 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.422\n",
      "INFO:tensorflow:loss = 1.53774e+06, step = 14301 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 560.841\n",
      "INFO:tensorflow:loss = 1.06281e+06, step = 14401 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.239\n",
      "INFO:tensorflow:loss = 1.69983e+06, step = 14501 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.997\n",
      "INFO:tensorflow:loss = 1.39271e+06, step = 14601 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.628\n",
      "INFO:tensorflow:loss = 1.33658e+06, step = 14701 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.686\n",
      "INFO:tensorflow:loss = 1.97745e+06, step = 14801 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.198\n",
      "INFO:tensorflow:loss = 2.8141e+06, step = 14901 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.434\n",
      "INFO:tensorflow:loss = 1.37871e+06, step = 15001 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.412\n",
      "INFO:tensorflow:loss = 1.20593e+06, step = 15101 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.193\n",
      "INFO:tensorflow:loss = 1.2813e+06, step = 15201 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.498\n",
      "INFO:tensorflow:loss = 1.52284e+06, step = 15301 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.252\n",
      "INFO:tensorflow:loss = 987623.0, step = 15401 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.002\n",
      "INFO:tensorflow:loss = 1.78134e+06, step = 15501 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 550.2\n",
      "INFO:tensorflow:loss = 946898.0, step = 15601 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.34\n",
      "INFO:tensorflow:loss = 1.30809e+06, step = 15701 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.768\n",
      "INFO:tensorflow:loss = 1.01661e+06, step = 15801 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.967\n",
      "INFO:tensorflow:loss = 1.40305e+06, step = 15901 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.016\n",
      "INFO:tensorflow:loss = 1.28881e+06, step = 16001 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.41307e+06, step = 16101 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.964\n",
      "INFO:tensorflow:loss = 1.54385e+06, step = 16201 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.662\n",
      "INFO:tensorflow:loss = 1.04547e+06, step = 16301 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.729\n",
      "INFO:tensorflow:loss = 1.81635e+06, step = 16401 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 582.786\n",
      "INFO:tensorflow:loss = 1.21318e+06, step = 16501 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.806\n",
      "INFO:tensorflow:loss = 1.47087e+06, step = 16601 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.247\n",
      "INFO:tensorflow:loss = 1.60473e+06, step = 16701 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.227\n",
      "INFO:tensorflow:loss = 1.88488e+06, step = 16801 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.102\n",
      "INFO:tensorflow:loss = 823697.0, step = 16901 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.488\n",
      "INFO:tensorflow:loss = 1.53954e+06, step = 17001 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.418\n",
      "INFO:tensorflow:loss = 1.45857e+06, step = 17101 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.527\n",
      "INFO:tensorflow:loss = 1.20414e+06, step = 17201 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.855\n",
      "INFO:tensorflow:loss = 1.10563e+06, step = 17301 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.098\n",
      "INFO:tensorflow:loss = 1.16531e+06, step = 17401 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.136\n",
      "INFO:tensorflow:loss = 1.83771e+06, step = 17501 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.275\n",
      "INFO:tensorflow:loss = 1.2754e+06, step = 17601 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.058\n",
      "INFO:tensorflow:loss = 1.27058e+06, step = 17701 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.446\n",
      "INFO:tensorflow:loss = 1.44957e+06, step = 17801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.338\n",
      "INFO:tensorflow:loss = 1.98533e+06, step = 17901 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.397\n",
      "INFO:tensorflow:loss = 858066.0, step = 18001 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.736\n",
      "INFO:tensorflow:loss = 850435.0, step = 18101 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.529\n",
      "INFO:tensorflow:loss = 1.273e+06, step = 18201 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 566.567\n",
      "INFO:tensorflow:loss = 1.62966e+06, step = 18301 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.578\n",
      "INFO:tensorflow:loss = 1.72546e+06, step = 18401 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.907\n",
      "INFO:tensorflow:loss = 1.30249e+06, step = 18501 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.351\n",
      "INFO:tensorflow:loss = 1.84526e+06, step = 18601 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.428\n",
      "INFO:tensorflow:loss = 1.73231e+06, step = 18701 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.415\n",
      "INFO:tensorflow:loss = 2.00656e+06, step = 18801 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.629\n",
      "INFO:tensorflow:loss = 1.18067e+06, step = 18901 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.333\n",
      "INFO:tensorflow:loss = 984653.0, step = 19001 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.585\n",
      "INFO:tensorflow:loss = 1.61887e+06, step = 19101 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.934\n",
      "INFO:tensorflow:loss = 1.08504e+06, step = 19201 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.185\n",
      "INFO:tensorflow:loss = 1.70321e+06, step = 19301 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 556.179\n",
      "INFO:tensorflow:loss = 1.43427e+06, step = 19401 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.564\n",
      "INFO:tensorflow:loss = 1.31241e+06, step = 19501 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 565.256\n",
      "INFO:tensorflow:loss = 1.19668e+06, step = 19601 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.1\n",
      "INFO:tensorflow:loss = 1.06076e+06, step = 19701 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 554.526\n",
      "INFO:tensorflow:loss = 1.44967e+06, step = 19801 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.585\n",
      "INFO:tensorflow:loss = 1.31894e+06, step = 19901 (0.205 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into tensorboard/DNN_regressor/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.37584e+06.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(params={'hidden_units': [50, 30, 10], 'embedding_lr_multipliers': None, 'dropout': None, 'feature_columns': (_RealValuedColumn(column_name='length', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='width', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='height', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='horsepower', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _OneHotColumn(sparse_id_column=_SparseColumnHashed(column_name='make', is_integerized=False, bucket_size=50, lookup_config=None, combiner='sum', dtype=tf.string)), _OneHotColumn(sparse_id_column=_SparseColumnKeys(column_name='num-of-doors', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=('two', 'four'), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string))), 'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x7faf24e85ef0>, 'activation_fn': <function relu at 0x7faf731a3048>, 'gradient_clip_norm': None, 'optimizer': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnregressor.fit(input_fn=training_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-15-14:09:38\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/DNN_regressor/model.ckpt-20000\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-14:09:39\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 1.54576e+07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'global_step': 20000, 'loss': 15457560.0}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnregressor.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/python/util/deprecation.py:347: calling DNNRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Restoring parameters from tensorboard/DNN_regressor/model.ckpt-20000\n",
      "prediction: 8559.48 real value: 10698.0\n",
      "prediction: 10046.9 real value: 9988.0\n",
      "prediction: 9907.54 real value: 10898.0\n",
      "prediction: 10046.9 real value: 11248.0\n",
      "prediction: 24726.5 real value: 16558.0\n",
      "prediction: 24726.5 real value: 15998.0\n",
      "prediction: 20584.9 real value: 15690.0\n",
      "prediction: 20584.9 real value: 15750.0\n",
      "prediction: 3707.19 real value: 7775.0\n",
      "prediction: 5748.44 real value: 7975.0\n"
     ]
    }
   ],
   "source": [
    "preds = list(dnnregressor.predict(input_fn=eval_input_fn))\n",
    "\n",
    "for i in range(TEST_DATA_SIZE):\n",
    "    print('prediction:', preds[i], 'real value:', test_label.iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @1.2.0 experiment_fn(run_config, params) - > experiment_fn(output_dir)\n",
    "def experiment_fn(output_dir):\n",
    "    # This function makes an Experiment, containing an Estimator and inputs for training and evaluation.\n",
    "    # You can use params and config here to customize the Estimator depending on the cluster or to use\n",
    "    # hyperparameter tuning.\n",
    "\n",
    "    # Collect information for training\n",
    "    # @1.2.0 config=run_config -> ''\n",
    "    return tf.contrib.learn.Experiment(estimator=tf.contrib.learn.LinearRegressor(\n",
    "                                     feature_columns=linear_features, model_dir=output_dir),\n",
    "                                     train_input_fn=training_input_fn,\n",
    "                                     train_steps=10000,\n",
    "                                     eval_input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_session_config': None, '_model_dir': '/tmp/output_dir', '_master': '', '_tf_random_seed': None, '_environment': 'local', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_task_type': None, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faf2c6dc5f8>, '_save_summary_steps': 100, '_evaluation_master': '', '_is_chief': True}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:268: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/output_dir/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.53779e+08, step = 1\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-15-00:13:35\n",
      "INFO:tensorflow:Restoring parameters from /tmp/output_dir/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-00:13:35\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 2.08159e+08\n",
      "INFO:tensorflow:Validation (step 1): loss = 2.08159e+08, global_step = 1\n",
      "INFO:tensorflow:global_step/sec: 54.6108\n",
      "INFO:tensorflow:loss = 3.2995e+08, step = 101 (1.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.199\n",
      "INFO:tensorflow:loss = 2.2434e+08, step = 201 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.823\n",
      "INFO:tensorflow:loss = 2.70825e+08, step = 301 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.326\n",
      "INFO:tensorflow:loss = 2.6304e+08, step = 401 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.905\n",
      "INFO:tensorflow:loss = 2.07089e+08, step = 501 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.526\n",
      "INFO:tensorflow:loss = 2.40862e+08, step = 601 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.318\n",
      "INFO:tensorflow:loss = 2.4237e+08, step = 701 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.001\n",
      "INFO:tensorflow:loss = 1.96818e+08, step = 801 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.254\n",
      "INFO:tensorflow:loss = 2.08855e+08, step = 901 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.583\n",
      "INFO:tensorflow:loss = 2.83313e+08, step = 1001 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.998\n",
      "INFO:tensorflow:loss = 3.63846e+08, step = 1101 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.892\n",
      "INFO:tensorflow:loss = 2.27487e+08, step = 1201 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.153\n",
      "INFO:tensorflow:loss = 1.95032e+08, step = 1301 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.272\n",
      "INFO:tensorflow:loss = 2.15183e+08, step = 1401 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.015\n",
      "INFO:tensorflow:loss = 2.63166e+08, step = 1501 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.721\n",
      "INFO:tensorflow:loss = 2.94977e+08, step = 1601 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.031\n",
      "INFO:tensorflow:loss = 2.07383e+08, step = 1701 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.855\n",
      "INFO:tensorflow:loss = 2.41123e+08, step = 1801 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.033\n",
      "INFO:tensorflow:loss = 2.24982e+08, step = 1901 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.881\n",
      "INFO:tensorflow:loss = 2.31737e+08, step = 2001 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.01\n",
      "INFO:tensorflow:loss = 2.37991e+08, step = 2101 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.816\n",
      "INFO:tensorflow:loss = 1.94863e+08, step = 2201 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.928\n",
      "INFO:tensorflow:loss = 2.36104e+08, step = 2301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.532\n",
      "INFO:tensorflow:loss = 2.42888e+08, step = 2401 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.561\n",
      "INFO:tensorflow:loss = 2.06083e+08, step = 2501 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.19\n",
      "INFO:tensorflow:loss = 2.10886e+08, step = 2601 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.82\n",
      "INFO:tensorflow:loss = 2.36597e+08, step = 2701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.239\n",
      "INFO:tensorflow:loss = 2.64082e+08, step = 2801 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.252\n",
      "INFO:tensorflow:loss = 2.7465e+08, step = 2901 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.216\n",
      "INFO:tensorflow:loss = 3.03645e+08, step = 3001 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.783\n",
      "INFO:tensorflow:loss = 2.82896e+08, step = 3101 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.608\n",
      "INFO:tensorflow:loss = 2.05005e+08, step = 3201 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.04795e+08, step = 3301 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.621\n",
      "INFO:tensorflow:loss = 2.34377e+08, step = 3401 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.705\n",
      "INFO:tensorflow:loss = 2.8409e+08, step = 3501 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.064\n",
      "INFO:tensorflow:loss = 2.64078e+08, step = 3601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.578\n",
      "INFO:tensorflow:loss = 1.93784e+08, step = 3701 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.774\n",
      "INFO:tensorflow:loss = 2.8074e+08, step = 3801 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.669\n",
      "INFO:tensorflow:loss = 2.33637e+08, step = 3901 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.921\n",
      "INFO:tensorflow:loss = 1.72349e+08, step = 4001 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.449\n",
      "INFO:tensorflow:loss = 2.2439e+08, step = 4101 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.478\n",
      "INFO:tensorflow:loss = 3.11015e+08, step = 4201 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.359\n",
      "INFO:tensorflow:loss = 3.30783e+08, step = 4301 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.685\n",
      "INFO:tensorflow:loss = 1.86487e+08, step = 4401 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.766\n",
      "INFO:tensorflow:loss = 2.14433e+08, step = 4501 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.857\n",
      "INFO:tensorflow:loss = 1.76995e+08, step = 4601 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.425\n",
      "INFO:tensorflow:loss = 2.38683e+08, step = 4701 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.707\n",
      "INFO:tensorflow:loss = 2.83825e+08, step = 4801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.829\n",
      "INFO:tensorflow:loss = 2.53666e+08, step = 4901 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.946\n",
      "INFO:tensorflow:loss = 2.04523e+08, step = 5001 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.178\n",
      "INFO:tensorflow:loss = 2.86669e+08, step = 5101 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.332\n",
      "INFO:tensorflow:loss = 2.7821e+08, step = 5201 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.092\n",
      "INFO:tensorflow:loss = 2.59791e+08, step = 5301 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.003\n",
      "INFO:tensorflow:loss = 2.47141e+08, step = 5401 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.106\n",
      "INFO:tensorflow:loss = 2.37231e+08, step = 5501 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.993\n",
      "INFO:tensorflow:loss = 2.72222e+08, step = 5601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.965\n",
      "INFO:tensorflow:loss = 2.79429e+08, step = 5701 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.171\n",
      "INFO:tensorflow:loss = 3.34573e+08, step = 5801 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.233\n",
      "INFO:tensorflow:loss = 3.56468e+08, step = 5901 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.368\n",
      "INFO:tensorflow:loss = 2.97041e+08, step = 6001 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.584\n",
      "INFO:tensorflow:loss = 2.29266e+08, step = 6101 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.962\n",
      "INFO:tensorflow:loss = 2.10434e+08, step = 6201 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.391\n",
      "INFO:tensorflow:loss = 1.9858e+08, step = 6301 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.808\n",
      "INFO:tensorflow:loss = 3.40392e+08, step = 6401 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.701\n",
      "INFO:tensorflow:loss = 1.35302e+08, step = 6501 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.52\n",
      "INFO:tensorflow:loss = 2.45073e+08, step = 6601 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.151\n",
      "INFO:tensorflow:loss = 1.8786e+08, step = 6701 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.783\n",
      "INFO:tensorflow:loss = 2.59138e+08, step = 6801 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.139\n",
      "INFO:tensorflow:loss = 2.56774e+08, step = 6901 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.202\n",
      "INFO:tensorflow:loss = 2.22381e+08, step = 7001 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.518\n",
      "INFO:tensorflow:loss = 3.19742e+08, step = 7101 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.642\n",
      "INFO:tensorflow:loss = 1.45798e+08, step = 7201 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.489\n",
      "INFO:tensorflow:loss = 2.8065e+08, step = 7301 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.284\n",
      "INFO:tensorflow:loss = 3.20594e+08, step = 7401 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.923\n",
      "INFO:tensorflow:loss = 2.86083e+08, step = 7501 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.777\n",
      "INFO:tensorflow:loss = 3.02958e+08, step = 7601 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.444\n",
      "INFO:tensorflow:loss = 2.35591e+08, step = 7701 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.848\n",
      "INFO:tensorflow:loss = 2.33625e+08, step = 7801 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.736\n",
      "INFO:tensorflow:loss = 2.14244e+08, step = 7901 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.138\n",
      "INFO:tensorflow:loss = 2.29226e+08, step = 8001 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.767\n",
      "INFO:tensorflow:loss = 3.2403e+08, step = 8101 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.772\n",
      "INFO:tensorflow:loss = 2.40912e+08, step = 8201 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.843\n",
      "INFO:tensorflow:loss = 2.55732e+08, step = 8301 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.67\n",
      "INFO:tensorflow:loss = 2.01069e+08, step = 8401 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.5\n",
      "INFO:tensorflow:loss = 2.51314e+08, step = 8501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.806\n",
      "INFO:tensorflow:loss = 2.33035e+08, step = 8601 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.854\n",
      "INFO:tensorflow:loss = 2.13737e+08, step = 8701 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.588\n",
      "INFO:tensorflow:loss = 2.20099e+08, step = 8801 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.643\n",
      "INFO:tensorflow:loss = 2.17736e+08, step = 8901 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.195\n",
      "INFO:tensorflow:loss = 3.29561e+08, step = 9001 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.331\n",
      "INFO:tensorflow:loss = 2.18982e+08, step = 9101 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.163\n",
      "INFO:tensorflow:loss = 2.73778e+08, step = 9201 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.112\n",
      "INFO:tensorflow:loss = 1.85688e+08, step = 9301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.984\n",
      "INFO:tensorflow:loss = 2.32726e+08, step = 9401 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.21\n",
      "INFO:tensorflow:loss = 2.143e+08, step = 9501 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.697\n",
      "INFO:tensorflow:loss = 2.24054e+08, step = 9601 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.808\n",
      "INFO:tensorflow:loss = 3.07036e+08, step = 9701 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.613\n",
      "INFO:tensorflow:loss = 2.25359e+08, step = 9801 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.992\n",
      "INFO:tensorflow:loss = 2.78171e+08, step = 9901 (0.205 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/output_dir/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.36605e+08.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-15-00:13:58\n",
      "INFO:tensorflow:Restoring parameters from /tmp/output_dir/model.ckpt-10000\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-15-00:13:59\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 2.03137e+08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'global_step': 10000, 'loss': 2.0313659e+08}, [])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "# @1.2.0 tf.contrib.learn.learn_runner(exp, run_config=tf.contrib.learn.RunConfig(model_dir=\"/tmp/output_dir\")\n",
    "# -> tf.contrib.learn.python.learn.learm_runner.run(exp, output_dir='/tmp/output_dir')\n",
    "shutil.rmtree(\"/tmp/output_dir\", ignore_errors=True)\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "learn_runner.run(experiment_fn, output_dir='/tmp/output_dir')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
